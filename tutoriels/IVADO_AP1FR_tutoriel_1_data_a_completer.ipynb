{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCQs5y60YyRv"
   },
   "source": [
    "# IVADO/Mila École d'apprentissage profond\n",
    "# 4e édition (automne 2019)\n",
    "# Tutoriel: Les données\n",
    "\n",
    "## Auteurs: \n",
    "\n",
    "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
    "\n",
    "Francis Grégoire <francis.gregoire@mila.quebec>\n",
    "\n",
    "## Traducteur:\n",
    "\n",
    "Andrew Williams <williams.andrew1305@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fsFqgdJZ2Mh"
   },
   "source": [
    "# Préface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGZRSQojc5zc"
   },
   "source": [
    "L'objectif de ce tutoriel est de souligner l'importance de comprendre les données sur lesquelles un projet d'apprentissage automatique (AA) est défini. Cette compréhension vous aidera à envisager les actions utiles à réaliser avant d'entraîner vos modèles d'apprentissage automatique. Ce tutoriel sert d'introduction douce à l'exploration des données et couvre les choses de base que tout praticien de l'apprentissage automatique devrait savoir.\n",
    "\n",
    "**Note: le but de ce tutoriel est d'être une introduction. Ainsi, nous proposons des solutions simples à nos exercices. En pratique, vous devriez utiliser des techniques plus avancées pour entraîner vos modèles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tn7fGc3PgWUy"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8dhsflQg4MB"
   },
   "source": [
    "Dans ce tutoriel, nous utiliserons l'ensemble de données [CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10). Il s'agit d'une collection d'images en couleurs 32 x 32 réparties dans 10 classes différentes. Les 10 classes (indexées) différentes sont les suivantes :\n",
    "\n",
    "0. avion ;\n",
    "1. automobile ;\n",
    "2. oiseau ;\n",
    "3. chat ;\n",
    "4. cerf ;\n",
    "5. chien ;\n",
    "6. grenouille ;\n",
    "7. cheval ;\n",
    "8. bateau ;\n",
    "9. camion.\n",
    "\n",
    "La tâche qui nous intéresse dans ce tutoriel est une tâche de classification d'images. C'est-à-dire que nous sommes intéressés à trouver, pour une image donnée, la classe à laquelle elle appartient. Nous utiliserons [PyTorch](https://pytorch.org/) comme cadre d'apprentissage automatique.\n",
    "\n",
    "À ce stade, toutes les fonctions et les méthodes PyTorch connexes seront fournies et utilisées telles quelles. Ceci est parce que ce tutoriel n'est pas conçu pour apprendre PyTorch, mais plutôt pour se concentrer sur la compréhension des données et des concepts de base de l'apprentissage automatique. Dans les tutoriels suivants, vous apprendrez comment développer, entraîner et évaluer des modèles sur différents types de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUgpszup1kCy"
   },
   "source": [
    "# Téléchargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fjpnx7t81vKD"
   },
   "source": [
    "Dans cette section, nous fournissons une fonction permettant de télécharger l'ensemble de données CIFAR-10. Elle prend en entrée deux arguments :\n",
    "- **path** : répertoire dans lequel l'ensemble de données téléchargées sera sauvegardé.\n",
    "- **train_flag** : indicateur booléen précisant s'il faut télécharger les données de l'ensemble d'entraînement (`train_flag=True`) ou de l'ensemble d'évaluation (`train_flag=False`).\n",
    "\n",
    "Il retourne deux éléments:\n",
    "- **imgs** : tableau numpy représentant les images téléchargées de taille N x 32 x 32 x 3 où N est le nombre d'images.\n",
    "- **labels** : liste de N classes (indexées), chacune étant associée à une seule image.\n",
    "\n",
    "## Attention: \n",
    "Plusieurs fonctionnalités de Python peuvent être retrouvés dans des bibliothèques qu'il faut installer et ensuite \"importer\" pour utiliser. Certaines fonctionnalités reliés à l'apprentissage automatique nous seront utiles. Il est donc important de les télécharger avant de commencer avec la cellule suivante (~750MB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KctjRqgm2Fze"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def download_CIFAR10(path, train_flag):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "     path: répertoire dans lequel l'ensemble de données téléchargées sera sauvegardé.\n",
    "     train_flag: si ''True'', télécharger les données de l'ensemble d'entraînement, sinon\n",
    "        télécharger à partir de l'ensemble d'évaluation.\n",
    "        \n",
    "  Return (retour):\n",
    "     Un tuple de deux éléments (imgs, labels) où\n",
    "        imgs : un tableau numpy de forme N x 32 x 32 x 3 où N est le nombre d'images.\n",
    "        labels : liste de N classes (indexées), chacune étant associée à une seule image.\n",
    "  \n",
    "  \"\"\"\n",
    "  dataset = torchvision.datasets.CIFAR10(\n",
    "      root=path, train=train_flag, download=True\n",
    "  )\n",
    "  imgs, labels = dataset.data, dataset.targets\n",
    "  return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRY0tkh79h48"
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Téléchargez l'ensemble de données d'entraînement de CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "30NO1znU3eDK",
    "outputId": "17ddefc8-9e76-43a6-ba98-d949dc9d76b5"
   },
   "outputs": [],
   "source": [
    "imgs, labels = ... # à compléter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9RrkHB3-anO"
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Téléchargez l'ensemble de données d'évaluation de CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPQBZhzl3qZp"
   },
   "outputs": [],
   "source": [
    "test_imgs, test_labels = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nbcM9SC-8MX"
   },
   "source": [
    "# ensemble de données de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yY2fanet_dMf"
   },
   "source": [
    "Dans la section précédente, des fonctions ont été fournies pour télécharger les ensembles de données **d'entraînement** et **d'évaluation**. Comme vous l'avez appris dans ce cours, nous avons normalement besoin de trois ensembles de données dans un projet d'apprentissage automatique, à savoir les ensembles d'entraînement, de **validation** et d'évaluation. Malheureusement, l'ensemble de données CIFAR-10 ne contient pas d'ensemble de données de validation prétraitées natif, nous devons donc en **créer** un par échantillonnage à partir de l'ensemble de données **d'entraînement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLxTIkNeCHA3"
   },
   "source": [
    "Dans cette section, nous fournissons une fonction permettant de créer un ensemble de données de validation à partir de l'ensemble de données d'entraînement original. Elle prend en entrée cinq arguments :\n",
    "- **imgs** : tableau numpy représentant l'ensemble d'images à partir duquel le partitionnement est effectué.\n",
    "- **labels** : étiquettes associées à l'ensemble d'images fourni.\n",
    "- **valid_ratio** (facultatif) : partie des données qui seront utilisées pour l'ensemble de validation. Valeur par défaut : `0.1`.\n",
    "- **shuffle** ( facultatif ) : si les données doivent être mélangées ou non avant que le partitionnement ne soit effectué. Valeur par défaut : \"True\".\n",
    "- **seed** ( facultatif ) : graine du générateur aléatoire. Valeur par défaut : `1234`.\n",
    "\n",
    "Elle fournit en sortie 4 éléments, qui sont :\n",
    "- **train_imgs** : tableau numpy représentant les images de l'ensemble d'entraînement après que le partitionnement soit fait.\n",
    "- **train_labels** : étiquettes associées aux images de l'ensemble d'entraînement.\n",
    "- **valid_imgs** : tableau numpy représentant les images de l'ensemble de validation après que le partitionnement soit fait.\n",
    "- **valid_labels** : étiquettes associées aux images de l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_LYjCXrEql1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def partition_dataset(imgs, labels, valid_ratio=0.1, shuffle=True, seed=1234):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "     imgs: tableau numpy représentant l'ensemble d'images à partir duquel \n",
    "        le partitionnement est fait.\n",
    "     labels: les étiquettes associées aux images fournies.\n",
    "     valid_ratio (facultatif) : la partie des données qui sera utilisée dans\n",
    "        le jeu de validation. Valeur par défaut : 0.1.\n",
    "     shuffle (facultatif) : permet de mélanger ou non les données. Par défaut : True.\n",
    "     seed (facultatif) : la graine du générateur aléatoire numpy : Valeur par défaut : 1234.\n",
    "        \n",
    "  Return (retour):\n",
    "     Un tuple de 4 éléments (train_imgs, train_labels, valid_imgs, valid_labels)\n",
    "     où :\n",
    "        train_imgs : un tableau numpy d'images pour l'ensemble d'entraînement.\n",
    "        train_labels : étiquettes associées aux images de l'ensemble d'entraînement.\n",
    "        valid_imgs : un tableau numpy d'images pour l'ensemble de validation.\n",
    "        valid_labels : étiquettes associées aux images de l'ensemble de validation.\n",
    "\n",
    "  \"\"\"\n",
    "  if shuffle:\n",
    "    np.random.seed(seed)  # Fixer la graine aléatoire de numpy.\n",
    "    indices = np.random.permutation(imgs.shape[0])\n",
    "  else:\n",
    "    indices = np.arange(imgs.shape[0])\n",
    "  \n",
    "  train_idx, valid_idx = np.split(\n",
    "      indices, \n",
    "      [int((1.0 - valid_ratio)*len(indices))]\n",
    "  )\n",
    "  train_imgs, valid_imgs = imgs[train_idx], imgs[valid_idx]\n",
    "  tgt = np.array(labels)\n",
    "  train_labels, valid_labels = tgt[train_idx].tolist(), tgt[valid_idx].tolist()\n",
    "  return train_imgs, train_labels, valid_imgs, valid_labels\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZ-K7scKNWo0"
   },
   "source": [
    "## Exercice\n",
    "\n",
    "En utilisant les paramètres par défaut, générer les ensembles de données d'entraînement et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "MYhh6Cb9ILc2",
    "outputId": "47f5194a-2e3e-438f-f5c2-22e947617545"
   },
   "outputs": [],
   "source": [
    "train_imgs, train_labels, valid_imgs, valid_labels = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6d3B5YMVNucn"
   },
   "source": [
    "# Visualisation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgUkFNKcPS8I"
   },
   "source": [
    "C'est toujours une bonne pratique de visualiser les données avec lesquelles nous travaillons. En particulier, la visualisation de la distribution des données fournira des indications précieuses sur les données en question.\n",
    "\n",
    "Dans cette section, nous fournissons quelques fonctions permettant de visualiser les données d'images et de calculer la distribution des étiquettes au sein d'un ensemble de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ac8QuRoHhGql"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_image(image):\n",
    "  \"\"\"\n",
    "  Tracer une seule image.\n",
    "  \n",
    "  Args :\n",
    "     image : image à tracer.\n",
    "     \n",
    "  \"\"\"\n",
    "  plt.imshow(image)\n",
    "  plt.show()\n",
    "\n",
    "  \n",
    "def plot_random_images_from_dataset(images, n):\n",
    "  \"\"\"\n",
    "  Échantillonner au hasard n images d'un ensemble d'images et les tracer dans une grille.\n",
    "  \n",
    "  Args :\n",
    "     images: collection d'images à partir desquelles l'échantillonnage sera effectué.\n",
    "     n: le nombre d'images à échantillonner.\n",
    "     \n",
    "  \"\"\"\n",
    "  sampled_indices = np.random.choice(images.shape[0], n, False)\n",
    "  sampled_images = images[sampled_indices]\n",
    "  \n",
    "  sampled_images = np.transpose(sampled_images, (0, 3, 1, 2))\n",
    "  sampled_tensor = torch.Tensor(sampled_images)\n",
    "  \n",
    "  grid_tensor = torchvision.utils.make_grid(\n",
    "      sampled_tensor, normalize=True, range=(0, 255)\n",
    "  )\n",
    "  grid_tensor = np.transpose(grid_tensor.numpy(), (1, 2, 0))\n",
    "  \n",
    "  plot_image(grid_tensor)\n",
    "  \n",
    "  \n",
    "def plot_dataset_histogram(labels, title=\"Distribution d'étiquettes\"):\n",
    "  \"\"\"\n",
    "  Tracez l'histogramme/la distribution des étiquettes dans un ensemble de données.\n",
    "  \n",
    "  Args :\n",
    "     labels : collection d'étiquettes à partir desquelles la distribution est calculée.\n",
    "     \n",
    "  \"\"\"\n",
    "  _ = plt.hist(labels, bins=np.arange(11)-0.5, rwidth=0.85)\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Étiquette')\n",
    "  plt.ylabel('Fréquence')\n",
    "  plt.xticks(np.arange(10))\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVKSaRGphrBS"
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Utilisez les fonctions définies précédemment pour visualiser des échantillons provenant d'ensembles de données d'entraînement et de validation. Calculez également la distribution des étiquettes dans ces deux ensembles de données. Quelles conclusions pouvez-vous en tirer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cHN_c43Uu6U"
   },
   "outputs": [],
   "source": [
    "# tracer un échantillon donné à partir de l'ensemble des données d'entraînement et récupérer son étiquette\n",
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVSI7FQozT7Y"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53Y3if2UaZxm"
   },
   "outputs": [],
   "source": [
    "# tracer des échantillons aléatoires (par exemple, 16) à partir de l'ensemble des données d'entraînement\n",
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4MtyWh_0hPl"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZJ_maHlITUo"
   },
   "outputs": [],
   "source": [
    "# tracer la distribution des étiquettes de l'ensemble des données d'entraînement\n",
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whIHwKKB2FW_"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7Ygn8fsjXho"
   },
   "source": [
    "# Mélanger les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWmG02g-GrZF"
   },
   "source": [
    "Lorsque vous créez vos propres ensembles d'entraînement, de validation et d'évaluation, il est essentiel de **mélanger** l'ensemble de données d'origine pour répartir les données entre les ensembles d'entraînement, de validation et d'évaluation afin de s'assurer qu'elles sont plus représentatives de la **distribution globale des données**. Le brassage de votre ensemble de données réduira également les biais si vos données proviennent de sources différentes.\n",
    "\n",
    "Les ensembles de données CIFAR-10 téléchargés au début de ce tutoriel ont déjà été mélangés. Pour visualiser l'efficacité du brassage, supposons que vous receviez un ensemble de données et qu'après la division, vous observiez les distributions d'étiquettes suivantes.\n",
    "\n",
    "Quelles seront les conséquences de l'utilisation de ce fractionnement sur vos mesures de performance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "eqPnb5avjXzA",
    "outputId": "4f619282-b862-493f-a2b2-caf0d2eb2ea7"
   },
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(labels)\n",
    "sorted_imgs = imgs[sorted_idx]\n",
    "sorted_labels = [labels[i] for i in sorted_idx]\n",
    "\n",
    "_, sorted_train_labels, _, sorted_valid_labels = partition_dataset(sorted_imgs, sorted_labels,\n",
    "                                                                   valid_ratio=0.5, shuffle=False)\n",
    "plot_dataset_histogram(sorted_train_labels, \"distribution des étiquettes de l'ensemble d'entraînement\")\n",
    "plot_dataset_histogram(sorted_valid_labels, \"distribution des étiquettes de l'ensemble de validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N75a0RHI3OkF"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES-dzdF8jfaW"
   },
   "source": [
    "Ci-dessous, nous mélangeons les données et observons que les étiquettes sont uniformément réparties dans les ensembles d'entraînement/validation, ce qui est une propriété nécessaire pour effectuer un réglage d'hyperparamètres précis sur un ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "XwcyQ7zJja0x",
    "outputId": "fede2a2c-d189-44e7-8279-09d374ab8170"
   },
   "outputs": [],
   "source": [
    "_, shuffled_train_labels, _, shuffled_valid_labels = partition_dataset(\n",
    "    sorted_imgs, sorted_labels, valid_ratio=0.5, shuffle=True\n",
    ")\n",
    "\n",
    "plot_dataset_histogram(shuffled_train_labels, \"distribution des étiquettes de l'ensemble d'entraînement\")\n",
    "plot_dataset_histogram(shuffled_valid_labels, \"distribution des étiquettes de l'ensemble de validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TU25Ban6jiWe"
   },
   "source": [
    "# Lecteurs de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-D0nw531G1wn"
   },
   "source": [
    "Comme vous le verrez dans les prochains tutoriels, pour entraîner et évaluer les modèles d'apprentissage automatique, nous utilisons des **lecteurs de données (*data loaders*)**. Comme l'apprentissage automatique nécessite une utilisation intensive de la transformation des données, nous voulons des outils qui **transforment**, **mélangent** et **partitionnent** efficacement nos ensembles de données avec la possibilité d'utiliser des travailleurs multiprocesseurs. Un lecteur de données est un itérateur de données optimisé qui offre toutes ces fonctionnalités.\n",
    "\n",
    "Il y a quelques années, pour entraîner un modèle d'apprentissage profond sur une tâche donnée, nous avions besoin de coder notre propre lecteur de données. Heureusement, les cadres modernes d'apprentissage profond, tels que PyTorch et TensorFlow, ont introduit des lecteurs de données très efficaces dans leurs dernières versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wK1zZ2qanmol"
   },
   "source": [
    "## Exercice\n",
    "Nous présentons un exemple simple de préparation d'un lecteur de données à l'aide d'un petit sous-ensemble de notre ensemble d'entraînement. Pendant l'entraînement, la meilleure pratique consiste à mélanger les données au début de chaque **époque** (chaque répétition sur un ensemble de données entier est généralement appelée une époque). Ainsi, nous définissons normalement \"shuffle=True\" pour l'entraînement et \"shuffle=False\" pour l'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "DOrqUB8Fjif-",
    "outputId": "c39e9f23-0df9-419b-9ab4-0025ac7295fb"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def create_dataset(images, labels, n):\n",
    "  \"\"\"\n",
    "  Sélectionner les n premières images/étiquettes et créez un torch.utils.data.DataLoader.\n",
    "  \n",
    "  Args :\n",
    "     images : tableau numpy d'images.\n",
    "     labels : liste des étiquettes associées aux images.\n",
    "     n : le nombre d'images/étiquettes à sélectionner.\n",
    "        \n",
    "  Return (Retour) :\n",
    "     Un jeu de données du tenseur torch.utils.data.TensorDataset \n",
    "         à utiliser avec un torch.utils.data.DataLoader.\n",
    "     \n",
    "  \"\"\"\n",
    "  imgs = torch.tensor(images[:n], dtype=torch.float)\n",
    "  labels = torch.tensor(labels[:n], dtype=torch.long)\n",
    "  dataset = TensorDataset(imgs, labels)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "n = 100\n",
    "batch_size = 32\n",
    "train_dataset = create_dataset(train_imgs, train_labels, n)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "  print('Époque {}/{}:'.format(epoch+1, epochs))\n",
    "  for i, (x, y) in enumerate(train_dataloader):\n",
    "    print('   batch {}/{} de {} exemples.'.format(i+1, int(np.ceil(n/batch_size)), y.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7p5cEgevRLi"
   },
   "source": [
    "Nous voyons que nous pouvons facilement itérer sur l'ensemble de données créé pour un certain nombre d'époques avec une simple boucle `for`. A chaque itération, le lecteur de données retourne un mini lot de paires d'étiquettes d'entrée `(x, y)` de taille `batch_size`.\n",
    "\n",
    "En réglant `drop_last=False`, le dernier lot incomplet est conservé si la taille de l'ensemble de données n'est pas divisible par `batch_size`. Lors de l'entraînement d'un modèle, pour calculer la perte, nous faisons normalement la moyenne des pertes des exemples d'un mini lot. Ainsi, en ayant un mini lot de 4 exemples au lieu de 32, les exemples du dernier mini lot ont plus d'importance que les autres exemples de l'ensemble de données. En pratique, cela n'est pas préjudiciable car les exemples sont mélangés au début d'une époque. Par conséquent, à chaque époque, nous devrions avoir des exemples différents dans le dernier mini lot. Plus de détails sur ce sujet seront fournis dans les prochains jours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvwpEr_1iers"
   },
   "source": [
    "# L'entraînement avec les réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e32z51jvlgRJ"
   },
   "source": [
    "Dans cette section, nous fournissons des méthodes basées sur les réseaux de neurones qui seront utilisées par la suite comme des boîtes noires à des fins d'entraînement et d'évaluation. Ne vous inquiétez pas, dans les prochains tutoriels, vous apprendrez comment écrire de tels morceaux de code.\n",
    "\n",
    "Deux méthodes seront utilisées de manière intensive dans les sections suivantes. \n",
    "\n",
    "La première est la `training_on_dataset`, qui consiste à entraîner un modèle sur un ensemble de données donné. Elle prend en entrée les arguments suivants et retourne un **modèle entraîné** :\n",
    "- **imgs** : images sur lesquelles le modèle sera entraîné.\n",
    "- **labels** : étiquettes associées aux images fournies.\n",
    "- **eval_imgs** : images pour évaluer le modèle.\n",
    "- **eval_labels** : étiquettes associées aux images utilisées pour évaluer le modèle.\n",
    "- **epochs** : nombre d'époques pendant l'entraînement (nombre de fois à boucler sur l'ensemble des images/étiquettes).\n",
    "- **batch_size** (facultatif) : taille d'un mini-lot. Par défaut : `8`.\n",
    "- **lr** ( facultatif ) : taux d'apprentissage. Valeur par défaut : `1e-3`.\n",
    "- **seed** ( facultatif) : graine du générateur aléatoire. Valeur par défaut : `1234`.\n",
    "- **transformations** ( facultatif ) : transformations à appliquer sur les images pendant le processus d'entraînement. Valeur par défaut : `None`.\n",
    "- **label_weights** ( facultatif ) : poids d'importance associés à chaque étiquette. Valeur par défaut : `None` (tous les étiquettes sont traitées de la même manière).\n",
    "- **metrics** (facultatif) : métriques à surveiller pendant l'entraînement. Valeur par défaut : `None`.\n",
    "\n",
    "\n",
    "Dans cette section, nous fournissons des méthodes basées sur les réseaux de neurones qui seront utilisées par la suite comme des boîtes noires à des fins d'entraînement et d'évaluation. Ne vous inquiétez pas, dans les prochains tutoriels, vous apprendrez comment écrire de tels morceaux de code.\n",
    "\n",
    "Deux méthodes seront utilisées de manière intensive dans les sections suivantes. \n",
    "\n",
    "La première est la `training_on_dataset`, qui consiste à entraîner un modèle sur un ensemble de données donné. Elle prend en entrée les arguments suivants et retourne un **modèle entraîné** :\n",
    "- **imgs** : images sur lesquelles le modèle sera entraîné.\n",
    "- **labels** : étiquettes associées aux images fournies.\n",
    "- **eval_imgs** : images pour évaluer le modèle.\n",
    "- **eval_labels** : étiquettes associées aux images utilisées pour évaluer le modèle.\n",
    "- **epochs** : nombre d'époques pendant l'entraînement (nombre de fois à boucler sur l'ensemble des images/étiquettes).\n",
    "- **batch_size** (facultatif) : taille d'un mini-lot. Par défaut : `8`.\n",
    "- **lr** ( facultatif ) : taux d'apprentissage. Valeur par défaut : `1e-3`.\n",
    "- **seed** ( facultatif) : graine du générateur aléatoire. Valeur par défaut : `1234`.\n",
    "- **transformations** ( facultatif ) : transformations à appliquer sur les images pendant le processus d'entraînement. Valeur par défaut : `None`.\n",
    "- **label_weights** ( facultatif ) : poids d'importance associés à chaque étiquette. Valeur par défaut : `None` (tous les étiquettes sont traitées de la même manière).\n",
    "- **metrics** (facultatif) : métriques à surveiller pendant l'entraînement. Valeur par défaut : `None`.\n",
    "\n",
    "\n",
    "La deuxième est `evaluate_classes`, qui évalue un modèle entraîné sur un ensemble de données donné. Elle prend en entrée les arguments suivants et retourne la **performance d'évaluation** :\n",
    "- **net** : le modèle entraîné à évaluer.\n",
    "- **imgs** : images sur lesquelles le modèle sera évalué.\n",
    "- **labels** : étiquettes de vérité fondamentale associées aux images fournies pour le calcul des performances.\n",
    "- **batch_size** ( facultatif ) : taille d'un mini-lot. Valeur par défaut : `8`.\n",
    "- **metrics** ( facultatif ) : mesures de performance à calculer. Valeur par défaut : `None`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWaFOMsdo4Sj"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "classe_names = (\n",
    "    'plane', 'car', 'bird', 'cat', 'deer', \n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    ")\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculer le score d'exactitude.\n",
    "  \n",
    "  Args :\n",
    "     y_true : étiquettes de vérité de base.\n",
    "     y_pred : étiquettes prédites par un classificateur.\n",
    "     \n",
    "  Return (Retour) :\n",
    "     Score d'exactitude.     \n",
    "  \"\"\"\n",
    "  return metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculer le score F1.\n",
    "  \n",
    "  Args :\n",
    "     y_true : étiquettes de vérité de base.\n",
    "     y_pred : étiquettes prédites par un classificateur.\n",
    "     \n",
    "  Return (Retour) :\n",
    "     Score F1.\n",
    "     \n",
    "  \"\"\"\n",
    "  return metrics.f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "def plot_metric(train_values, valid_values, name=''):\n",
    "  \"\"\"\n",
    "  Tracer les valeurs d'une mesure de performance fournie sur des ensembles d'entraînement et de validation.\n",
    "  \n",
    "  Args :\n",
    "     train_values : valeurs de la mesure sur l'ensemble d'entraînement. \n",
    "     valid_values : valeurs de la mesure sur l'ensemble de validation.\n",
    "     name : nom de la mesure.\n",
    "  \"\"\"\n",
    "  x = range(len(train_values))\n",
    "  plt.plot(x, train_values, label='Entraînement')\n",
    "  plt.plot(x, valid_values, label='Validation')\n",
    "  plt.title(name)\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "class AugmentBasedDataset(Dataset):\n",
    "  \"\"\"Ensemble de données encapsulé pour l'augmentation des données.\"\"\"\n",
    "\n",
    "  def __init__(self, dataset, transform=None):\n",
    "    \"\"\"\n",
    "    Args :\n",
    "        ensemble de données : ensemble de données sur lequel on veut effectuer \n",
    "            une augmentation de données.\n",
    "        transform (exécutable, facultatif) : transformation facultative à \n",
    "            appliquer sur un échantillon.\n",
    "    \"\"\"\n",
    "    self.dataset = dataset\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img, label = self.dataset[idx]\n",
    "    if self.transform:\n",
    "        img = self.transform(img)\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKCGEYWIpW3n"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  \"\"\"CNN de base utilisé pour la classification des images.\"\"\"\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = x.view(-1, 16 * 5 * 5)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zm19z0tk1j8e"
   },
   "outputs": [],
   "source": [
    "def training_on_dataset(imgs, labels, eval_imgs, eval_labels,\n",
    "                        epochs, batch_size=8, lr=1e-3,\n",
    "                        seed=1234, transformations=None, label_weights=None,\n",
    "                        metrics=None, verbose=True):\n",
    "  \"\"\"\n",
    "  Fonction boîte noire pour entraîner un réseau de neurones \n",
    "  sur le jeu de données CIFAR-10.\n",
    "  \"\"\"\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  \n",
    "  # Données d'entraînement.\n",
    "  train_imgs = ((imgs/255.0) - 0.5) * 2.0  # Normaliser à [-1, 1].\n",
    "  train_imgs = np.transpose(train_imgs, (0, 3, 1, 2))\n",
    "  train_labels = np.array(labels)\n",
    "  \n",
    "  train_dataset = TensorDataset(\n",
    "      torch.from_numpy(train_imgs).float(), \n",
    "      torch.from_numpy(train_labels).long()\n",
    "  )\n",
    "  train_dataset = AugmentBasedDataset(train_dataset, transformations)\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # Données d'évaluation.\n",
    "  eval_imgs = ((eval_imgs/255.0) - 0.5) * 2.0 # Normaliser à [-1, 1].\n",
    "  eval_imgs = np.transpose(eval_imgs, (0, 3, 1, 2))\n",
    "  eval_labels = np.array(eval_labels)\n",
    "  \n",
    "  eval_dataset = TensorDataset(\n",
    "      torch.from_numpy(eval_imgs).float(), \n",
    "      torch.from_numpy(eval_labels).long()\n",
    "  )\n",
    "  eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  net = Net()\n",
    "  net = net.to(device)\n",
    "  if label_weights is not None:\n",
    "    label_weights = torch.tensor(label_weights).float()\n",
    "    label_weights = label_weights.to(device)\n",
    "  criterion = nn.CrossEntropyLoss(weight=label_weights)\n",
    "  optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "  \n",
    "  train_loss_values = []\n",
    "  eval_loss_values = []\n",
    "  train_metric_values = None\n",
    "  eval_metric_values = None\n",
    "  \n",
    "  if metrics is not None:\n",
    "    if isinstance(metrics, dict):\n",
    "      train_metric_values = {metric: [] for metric in metrics.keys()}\n",
    "      eval_metric_values = {metric: [] for metric in metrics.keys()}\n",
    "    elif isinstance(metrics, (list, tuple)):\n",
    "      train_metric_values = {metric: [] for metric in range(len(metrics))}\n",
    "      eval_metric_values = {metric: [] for metric in range(len(metrics))}\n",
    "    else:\n",
    "      metrics = [metrics]\n",
    "      train_metric_values = {metric: [] for metric in range(len(metrics))}\n",
    "      eval_metric_values = {metric: [] for metric in range(len(metrics))}\n",
    "\n",
    "  for epoch in range(epochs):  # Passer en boucle sur l'ensemble des données.\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    n_update = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in train_dataloader:\n",
    "      # Les données sont un tuple de (entrées, cibles).\n",
    "      inputs, targets = data\n",
    "      \n",
    "      if targets.numel() > 1:\n",
    "        y_true.extend(targets.flatten().tolist())\n",
    "      else:\n",
    "        y_true.append(targets.flatten().tolist())\n",
    "      \n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)       \n",
    "\n",
    "      # Réinitialiser les gradients des paramètres.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Propagation avant + propagation arrière + optimiser.\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Prédire l'étiquette.\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      if predicted.numel() > 1:\n",
    "        y_pred.extend(predicted.flatten().tolist())\n",
    "      else:\n",
    "        y_pred.append(predicted.flatten().tolist())\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      n_update += 1\n",
    "\n",
    "    # Sauvegarder et imprimer les statistiques à la fin de chaque époque d'entraînement.\n",
    "    train_loss = running_loss / n_update\n",
    "    train_loss_values.append(train_loss)\n",
    "    eval_loss, eval_true, eval_pred = evaluate_during_training(net, criterion, eval_dataloader)\n",
    "    eval_loss_values.append(eval_loss)\n",
    "    \n",
    "    if metrics is not None:\n",
    "      for metric in metrics.keys():\n",
    "        train_metric_values[metric].append(metrics[metric](y_true, y_pred))\n",
    "        eval_metric_values[metric].append(metrics[metric](eval_true, eval_pred))\n",
    "  \n",
    "    if verbose:\n",
    "      print(\"[Époque {}/{}] Perte d'entraînement: {:.3f} | Perte de validation: {:.3f}\" \n",
    "            .format(epoch + 1, epochs, train_loss, eval_loss)\n",
    "      )\n",
    "    running_loss = 0.0\n",
    "    n_update = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "  \n",
    "  if verbose:\n",
    "    plot_metric(train_loss_values, eval_loss_values, 'Perte')\n",
    "    if metrics is not None:\n",
    "      for metric in metrics.keys():\n",
    "        plot_metric(train_metric_values[metric], eval_metric_values[metric], metric)\n",
    "  \n",
    "  return net\n",
    "\n",
    "\n",
    "def evaluate_during_training(net, criterion, dataloader):\n",
    "  net.eval()\n",
    "  running_loss = 0.0\n",
    "  n_update = 0\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  for data in dataloader:\n",
    "    inputs, targets = data\n",
    "    if targets.numel() > 1:\n",
    "      y_true.extend(targets.flatten().tolist())\n",
    "    else:\n",
    "      y_true.append(targets.flatten().tolist())\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device) \n",
    "    with torch.no_grad():\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, targets)  \n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      if predicted.numel() > 1:\n",
    "        y_pred.extend(predicted.flatten().tolist())\n",
    "      else:\n",
    "        y_pred.append(predicted.flatten().tolist())\n",
    "      running_loss += loss.item()\n",
    "      n_update += 1\n",
    "  eval_loss = running_loss / n_update\n",
    "  return eval_loss, y_true, y_pred\n",
    "\n",
    "\n",
    "def evaluate_classes(net, imgs, labels, batch_size=8, metrics=None, verbose=True):\n",
    "  \"\"\"\n",
    "  Fonction boîte noire pour évaluer un réseau de neurones sur un ensemble de \n",
    "      données CIFAR-10.\n",
    "  \"\"\"\n",
    "  normalized_imgs = ((imgs/255.0) - 0.5) * 2.0 # Normaliser à [-1, 1].\n",
    "  normalized_imgs = np.transpose(normalized_imgs, (0, 3, 1, 2))\n",
    "  arr_labels = np.array(labels)\n",
    "  \n",
    "  dataset = TensorDataset(\n",
    "      torch.from_numpy(normalized_imgs).float(), \n",
    "      torch.from_numpy(arr_labels).long()\n",
    "  )\n",
    "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "  net = net.to(device)\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  class_correct = [0.0] * 10\n",
    "  class_total = [0.0] * 10\n",
    "  class_acc = [0.0] * 10\n",
    "  \n",
    "  metric_values = None\n",
    "  if not (metrics is None):\n",
    "    if isinstance(metrics, dict):\n",
    "      metric_values = {a: 0.0 for a in metrics.keys()}\n",
    "    elif isinstance(metrics, (list, tuple)):\n",
    "      metric_values = {a: 0.0 for a in range(len(metrics))}\n",
    "    else:\n",
    "      metrics = [metrics]\n",
    "      metric_values = {a: 0.0 for a in range(len(metrics))}\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in dataloader:\n",
    "      inputs, targets = data\n",
    "      \n",
    "      if targets.numel() > 1:\n",
    "        y_true.extend(targets.flatten().tolist())\n",
    "      else:\n",
    "        y_true.append(targets.flatten().tolist())\n",
    "        \n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      outputs = net(inputs)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      \n",
    "      if predicted.numel()>1:\n",
    "        y_pred.extend(predicted.flatten().tolist())\n",
    "      else:\n",
    "        y_pred.append(predicted.flatten().tolist())\n",
    "      \n",
    "      total += targets.size(0)\n",
    "      correct += (predicted == targets).sum().item()\n",
    "      \n",
    "      c = (predicted == targets).squeeze()\n",
    "      for i in range(targets.size(0)):\n",
    "        label = targets[i]\n",
    "        class_correct[label] += c[i].item()\n",
    "        class_total[label] += 1\n",
    "            \n",
    "    if not (metric_values is None):\n",
    "      for a in metric_values.keys():\n",
    "        metric_values[a] = metrics[a](y_true, y_pred)\n",
    "            \n",
    "  global_acc = correct / max(total, 1.0)\n",
    "  \n",
    "  if verbose:\n",
    "    if metrics is not None:\n",
    "      print(\"Évaluation sur l'ensemble des données de validation: \")\n",
    "      for a in metric_values.keys():\n",
    "        print('Mesure {}: {:.0%}'.format(a, metric_values[a]))\n",
    "\n",
    "  for i in range(10):\n",
    "    class_acc[i] = class_correct[i] / max(class_total[i], 1.0)\n",
    "    if verbose:\n",
    "      print('Exactitude de {:<5s} ({}): {:.0%}'\n",
    "            .format(classe_names[i], i, class_acc[i])\n",
    "           )\n",
    "    \n",
    "  return global_acc, class_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbYLAX2Ktt7H"
   },
   "source": [
    "# Quelle est la quantité de données nécessaires à l'entraînement ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txSjlglLvaC_"
   },
   "source": [
    "Dans cette section, nous étudions l'effet de la taille des données d'entraînement sur la performance finale de la tâche considérée. Nous explorons également une technique, appelée **augmentation des données**, pour augmenter artificiellement la taille d'un ensemble de données donné pendant le processus d'entraînement.\n",
    "\n",
    "Notez que nous gardons l'ensemble de données de validation fixe tout au long de ce tutoriel. C'est juste pour le but de ce tutoriel, car nous voulons que les différentes évaluations soient comparables. Dans les scénarios de la vie réelle, l'ensemble de données de validation ne doit jamais être plus grand que l'ensemble de données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MKcpyiQxl-6"
   },
   "source": [
    "## Entraînement avec seulement 1% des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eOm2bCVxy5mc"
   },
   "source": [
    "Commençons par considérer seulement 1% de nos données d'entraînement. La méthode suivante permet de sélectionner une partie des données d'un ensemble de données donné. Elle prend en entrée cinq arguments :\n",
    "- **imgs** : tableau numérique représentant l'ensemble d'images à partir duquel la sélection est effectuée.\n",
    "- **labels** : étiquettes associées à l'ensemble d'images fourni.\n",
    "- **ratio** (facultatif) : partie des données qui seront sélectionnées. Valeur par défaut : `0.1`.\n",
    "- **shuffle** ( facultatif ) : si les données doivent être mélangées ou non avant que la sélection ne soit effectuée. Valeur par défaut : `True`.\n",
    "- **seed** ( facultatif ) : graine du générateur aléatoire : Valeur par défaut : `1234`.\n",
    "\n",
    "Elle fournit en sortie 2 éléments :\n",
    "- **select_imgs** : tableau numpy des images sélectionnées.\n",
    "- **select_labels** : étiquettes associées aux images sélectionnées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "YKQZqtge0QoV",
    "outputId": "59aa3d6c-2514-46fa-82a3-7a2470f77c17"
   },
   "outputs": [],
   "source": [
    "def select_subset_from_dataset(imgs, labels, ratio=0.1, shuffle=True, seed=1234):\n",
    "  \"\"\"\n",
    "  Args :\n",
    "     imgs : tableau numpy représentant l'ensemble d'images à partir duquel \n",
    "        la sélection est faite.\n",
    "     labels : les étiquettes associées aux images fournies.\n",
    "     ratio (facultatif) : partie des données à sélectionner. \n",
    "         Valeur par défaut : 0,1.\n",
    "     shuffle (facultatif) : Permet de mélanger ou non les données. \n",
    "         Par défaut : True.\n",
    "     seed (facultatif) : semence du générateur aléatoire numpy : \n",
    "         Valeur par défaut : 1234.\n",
    "        \n",
    "  Return (retour) :\n",
    "     Un tuple de 2 éléments (select_imgs, select_labels)\n",
    "     où :\n",
    "        select_imgs : un tableau numpy des images sélectionnées.\n",
    "        select_labels : étiquettes associées aux images sélectionnées.\n",
    "      \n",
    "  \"\"\"\n",
    "  if shuffle:\n",
    "    np.random.seed(seed)  # Fixez la graine aléatoire de numpy.\n",
    "    indices = np.random.permutation(imgs.shape[0])\n",
    "  else:\n",
    "    indices = np.arange(imgs.shape[0])\n",
    "  idx, _ = np.split(indices, [int(ratio*len(indices))])\n",
    "  select_imgs = imgs[idx]\n",
    "  tgt = np.array(labels)\n",
    "  select_labels = tgt[idx].tolist()\n",
    "  return select_imgs, select_labels\n",
    "\n",
    "\n",
    "select_imgs, select_labels = select_subset_from_dataset(\n",
    "    train_imgs, train_labels, 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfbVmI7V4dxF"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Entraînez un modèle en utilisant les données sélectionnées et évaluez sa performance sur l'ensemble de données de validation. Les arguments suivants doivent être utilisés :\n",
    "- **epochs** : `5`.\n",
    "- **batch_size** : `32`.\n",
    "- **metrics** : `{'Exactitude' : accuracy}`.\n",
    "\n",
    "Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 834
    },
    "colab_type": "code",
    "id": "UglqJKbYvdpY",
    "outputId": "9ca664d7-7fb6-492f-c3c2-2ee3086686ea"
   },
   "outputs": [],
   "source": [
    "# Entraîner sur les données sélectionnées\n",
    "model = ... # à compléter.\n",
    "\n",
    "# Évaluer le modèle entraîné sur l'ensemble de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dcves3L8_nE"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wExcwcMc7c7_"
   },
   "source": [
    "### Exercice\n",
    "Dans l'exercice précédent, nous avons limité le nombre d'époques à \"5\". Dans cette section, nous vous demandons d'entraîner votre modèle en utilisant un nombre d'époques plus élevé (par exemple, `50`, `100`). Pour une comparaison équitable, vous devez conserver les arguments suivants :\n",
    "- **batch_size**: `32`.\n",
    "- **metrics**: `{'Exactitude': accuracy}`.\n",
    "- **eval_imgs**: `valid_imgs`.\n",
    "- **eval_labels**: `eval_labels`.\n",
    "\n",
    "Qu'observez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fBVuYOZ58VkD",
    "outputId": "88becb60-1daa-4b88-d549-26635a8704ed"
   },
   "outputs": [],
   "source": [
    "# Entraîner sur les données sélectionnées\n",
    "model = ... # à compléter.\n",
    "\n",
    "# Évaluer le modèle entraîné sur l'ensemble de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEMYRMeR8gA8"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYRPF8m5Ps7p"
   },
   "source": [
    "## Performance en fonction de la taille de l'ensemble de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ILOZAvjPzhB"
   },
   "source": [
    "Maintenant, nous entraînons le même modèle sur différents ratios de l'ensemble des données d'entraînement (par exemple, 10 % de l'ensemble des données d'entraînement) tout en gardant l'ensemble des données de validation fixe. Nous voulons observer l'impact de l'utilisation d'un ensemble de données d'entraînement plus important.\n",
    "\n",
    "La fonction suivante réalise cette étude à partir d'une liste de valeurs de ratios. Elle prend comme arguments :\n",
    "- **ratio_list** : liste des ratios à prendre en compte dans l'étude.\n",
    "- **epochs** (facultatif) : nombre d'époques d'entraînement. Par défaut : `5`.\n",
    "- **seed** (facultatif) : graine du générateur aléatoire : Valeur par défaut : `1234`.\n",
    "\n",
    "Cette fonction génère un graphique montrant la performance (en termes d'exactitude) en fonction du ratio des données utilisées pour l'entraînement du modèle.\n",
    "\n",
    "Il est important de noter qu'en fixant le nombre d'époques, plus la taille de l'ensemble d'entraînement augmente, plus nous effectuons de mises à jour des paramètres. Par conséquent, l'étude globale n'est pas tout à fait juste puisque nous n'entraînons pas le modèle sur un nombre fixe d'itérations. Cependant, notre objectif ici est d'évaluer la relation entre la performance d'un modèle et le nombre d'exemples dans l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylPD0is-Q7ay"
   },
   "outputs": [],
   "source": [
    "def performance_study(ratio_list, epochs=5, seed=1234):\n",
    "  \"\"\"\n",
    "  Args :\n",
    "     ratio_list : liste des numéros de ratio à prendre en compte.\n",
    "     epochs (facultatif) : nombre d'époques d'entraînement. Par défaut : 5.\n",
    "     seed (facultatif) : graine du générateur aléatoire numpy : Valeur par défaut : 1234.\n",
    "        \n",
    "  Return (retour) :\n",
    "     Cette méthode ne retourne rien, mais elle génère un graphique.\n",
    "      \n",
    "  \"\"\"\n",
    "  results = []\n",
    "  for ratio in ratio_list:\n",
    "    select_imgs, select_labels = select_subset_from_dataset(\n",
    "        train_imgs, train_labels, ratio\n",
    "    )\n",
    "    trained_model = training_on_dataset(\n",
    "        select_imgs, select_labels, valid_imgs, valid_labels,\n",
    "        epochs=epochs, batch_size=32,\n",
    "        seed=seed, verbose=False\n",
    "    )\n",
    "    acc, _ = evaluate_classes(\n",
    "        trained_model, valid_imgs, valid_labels, batch_size=32,\n",
    "        verbose=False\n",
    "    )\n",
    "    results.append(acc)\n",
    "  \n",
    "  print('Meilleure exactitude: {:.0%}'.format(max(results)))\n",
    "  plt.plot(ratio_list, results)\n",
    "  plt.title(\"Performance du modèle sur l'ensemble de validation\")\n",
    "  plt.xlabel(\"Ratio de l'ensemble d'entraînement\")\n",
    "  plt.ylabel('Exactitude')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDZLShKzgUMV"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Évaluez la performance en utilisant les ratios suivants : `0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0`. \n",
    "\n",
    "Vous pouvez choisir le nombre d'époques que vous souhaitez pour cette étude. Gardez simplement à l'esprit que plus le nombre est élevé, plus le temps nécessaire à l'entraînement/étude est long. Par conséquent, il est recommandé de ne pas dépasser `epochs=20` pour les besoins de ce tutoriel. Par défaut, il est fixé à `epochs=5`.\n",
    "\n",
    "Encore une fois, en ayant un nombre fixe d'époques, plus l'ensemble d'entraînement est grand, plus nous mettons à jour les paramètres du modèle.\n",
    "\n",
    "Quelle est votre conclusion ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jS-MkJ_rprdH"
   },
   "outputs": [],
   "source": [
    "ratio_list = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hOajcWPAxrC"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrrNv7Adnj27"
   },
   "source": [
    "Les paramètres des réseaux de neurones sont initialisés à des valeurs aléatoires. Si nous ne fixons pas une graine de modèle, les nombres aléatoires générés utilisés pour initialiser ces paramètres seront différents. Essayez de faire la même expérience avec une graine différente (par exemple, `graine=8761`) en utilisant le même nombre d'époques que dans l'exercice précédent. Obtenez-vous le même résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "accW_kKt5TEF",
    "outputId": "2b94f44e-8243-4621-d418-96b59b50dfb0"
   },
   "outputs": [],
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dFQG5ViqzM1"
   },
   "source": [
    "## Augmentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnD2tCAv2QWZ"
   },
   "source": [
    "Très souvent, on nous fournit un ensemble de données et il n'y a pas moyen d'en collecter davantage. Dans cette section, nous explorons rapidement la technique d'augmentation des données, qui consiste à modifier les images dans le jeu de données d'entraînement sans changer les étiquettes associées. Ce faisant, il est possible d'augmenter artificiellement le nombre d'images dans notre ensemble de données d'entraînement. Par exemple, nous pouvons penser aux opérations de renversement ou de recadrage/redimensionnement pour modifier une image dans l'ensemble de données sans modifier l'étiquette qui lui est associée. Par conséquent, en apprenant sur un plus grand nombre d'images, nous pouvons observer certains gains de performance et/ou une meilleure généralisation du modèle. Cependant, comme l'augmentation des données crée artificiellement de nouveaux exemples à partir de ceux qui existent déjà, l'hypothèse d'indépendance n'est pas respectée. Ainsi, nous ne devrions pas utiliser l'augmentation des données pour les ensemble de données de validation et d'évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PKpTId_3lGI"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Supposons que nous n'ayons accès qu'à 30 % de l'ensemble des données d'entraînement d'origine. Entraînez un modèle avec cette portion de données et évaluez-le sur l'ensemble de données de validation. À mesure que le nombre d'exemples augmente dans l'ensemble d'entraînement, nous pouvons envisager d'augmenter le nombre d'époques tout en gardant à l'esprit le problème du surapprentissage. Pour cet exercice, nous utiliserons les arguments suivants :\n",
    "- **epochs**: `15`.\n",
    "- **batch_size**: `32`.\n",
    "- **metrics**: `{'Exactitude': accuracy}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "6pBFLLmxrCC8",
    "outputId": "68cc7581-42b0-4464-e765-92cbabc1f36a"
   },
   "outputs": [],
   "source": [
    "# sélectionnez les données\n",
    "select_imgs, select_labels = ... # à compléter.\n",
    "\n",
    "# Entraînez sur les données sélectionnées\n",
    "model50 = ... # à compléter.\n",
    "\n",
    "# Évaluez sur l'ensemble de données de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UdeKH-JsrcPl"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Le code suivant définit une transformation, en utilisant le cadre PyTorch. Avec l'opération de recadrage aléatoire, un recadrage de taille aléatoire (0,7 à 1,0) de l'image originale est effectué et celle-ci est redimensionnée en une image 32 x 32. Les opérations de \"transformation\" sont appliquées aux images originales à chaque génération de mini lots. Cela laisse les images de votre ensemble de données inchangées, seules les images des mini lots sont copiées et transformées à chaque itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5h0bzG9rh_T"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Normalize((-1., -1., -1.), (2., 2., 2.)),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop((32, 32), scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "110l_poa5AUi"
   },
   "source": [
    "Cette fois, entraînez un nouveau modèle en utilisant la même architecture en appliquant une augmentation des données sur les 30% extraits de l'ensemble de données d'entraînement. Évaluez votre modèle et comparez vos résultats avec ceux de l'exercice précédent. Utilisez les arguments suivants :\n",
    "- **epochs**: `15`.\n",
    "- **batch_size**: `32`.\n",
    "- **metrics**: `{'Exactitude': accuracy}`.\n",
    "\n",
    "Notez que vous pouvez utiliser l'argument `transformations` de la méthode `training_on_dataset` pour effectuer une augmentation des données pendant l'entraînement.\n",
    "\n",
    "Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JHCgdzprnG9"
   },
   "outputs": [],
   "source": [
    "# Entraînement sur les données sélectionnées avec augmentation de données\n",
    "model50A = ... # à compléter.\n",
    "\n",
    "# Évaluez sur l'ensemble de données de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KP24gLYYIia_"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BRbANE0mjLY"
   },
   "source": [
    "# Ensembles de données non équilibrés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfpH0Cx1NA-z"
   },
   "source": [
    "## Qu'est-ce qu'un ensemble de données déséquilibré ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDuyTs_smng1"
   },
   "source": [
    "Jusqu'à présent, l'ensemble des données d'entraînement contenait à peu près le même nombre d'images pour chaque étiquette. Dans cette section, nous examinons l'impact d'entraîner des modèles sur un ensemble de données déséquilibré, ce qui se produit lorsque chaque classe ne constitue pas une portion égale de votre ensemble de données. \n",
    "\n",
    "La fonction suivante sélectionne une partie des données d'un ensemble de données donné tout en fournissant une distribution d'étiquettes définie. Elle prend en entrée six arguments :\n",
    "- **imgs** : tableau numpy représentant l'ensemble d'images à partir duquel la sélection est effectuée.\n",
    "- **labels** : étiquettes associées à l'ensemble d'images fourni.\n",
    "- **label_dist** : la distribution des étiquettes à sélectionner, représentée par un dict de `{label : value}`.\n",
    "- **ratio** (facultatif) : partie des données qui seront sélectionnées. Valeur par défaut : `0.1`.\n",
    "- **shuffle** ( facultatif ) : si les données doivent être mélangées ou non avant que la sélection ne soit effectuée. Valeur par défaut : `True`.\n",
    "- **seed** ( facultatif ) : graine du générateur aléatoire : Valeur par défaut : `1234`.\n",
    "\n",
    "Elle fournit en sortie 2 éléments :\n",
    "- **select_imgs** : un tableau numpy des images sélectionnées.\n",
    "- **select_labels** : étiquettes associées aux images sélectionnées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx4E8E5TLr2H"
   },
   "outputs": [],
   "source": [
    "def select_subset_from_dataset_with_label_dist(\n",
    "    imgs, labels, label_dist, ratio=0.1, shuffle=True, seed=1234):\n",
    "  \"\"\"\n",
    "  Args :\n",
    "     imgs : tableau numpy représentant l'ensemble d'images à partir duquel \n",
    "        la sélection est faite.\n",
    "     labels : les étiquettes associées aux images fournies.\n",
    "     label_dist : la distribution des étiquettes à sélectionner.\n",
    "     ratio ( facultatif ) : partie des données à sélectionner. Par défaut : 0.1.\n",
    "     shuffle ( facultatif) : Permet de mélanger ou non les données. \n",
    "         Par défaut : True.\n",
    "     seed ( facultatif ) : graine du générateur aléatoire numpy : \n",
    "         Par défaut : 1234.\n",
    "        \n",
    "  Return (retour) :\n",
    "     Un tuple de 2 éléments (select_imgs, select_labels)\n",
    "     où :\n",
    "        select_imgs : un tableau numpy des images sélectionnées.\n",
    "        select_labels : étiquettes associées aux images sélectionnées.\n",
    "      \n",
    "  \"\"\"\n",
    "  if isinstance(label_dist, (list, tuple)):\n",
    "    label_dist = {a:v for a,v in enumerate(label_dist)}\n",
    "  sum_dist = sum(label_dist.values())\n",
    "  for lab in label_dist.keys():\n",
    "    label_dist[lab] /= sum_dist\n",
    "    \n",
    "  tgts = np.array(labels)\n",
    "  num_indices = int(ratio*len(labels))\n",
    "  num_idx_lab = {a: int(label_dist[a]*num_indices) for a in label_dist.keys()}\n",
    "  \n",
    "  sel_ind = []\n",
    "  \n",
    "  if shuffle:\n",
    "    np.random.seed(seed)  # Fixez la graine aléatoire de numpy.\n",
    "\n",
    "  for a in num_idx_lab.keys():\n",
    "    idx = np.where(tgts==a)\n",
    "    idx = idx[0]\n",
    "    if shuffle:\n",
    "      idx = np.random.permutation(idx)\n",
    "    num = min(num_idx_lab[a], len(idx))\n",
    "    idx = idx[0:num]\n",
    "    sel_ind.extend(idx)\n",
    "    \n",
    "  if shuffle:\n",
    "    sel_ind = np.random.permutation(sel_ind)\n",
    "  else:\n",
    "    sel_ind.sort()\n",
    "    sel_ind = np.array(sel_ind)\n",
    "    \n",
    "  select_imgs = imgs[sel_ind, :]\n",
    "  select_labels = tgts[sel_ind].tolist()\n",
    "  \n",
    "  return select_imgs, select_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQO9ejo57_G1"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "En utilisant la fonction définie ci-dessus avec ses paramètres par défaut, extraire 30 % des données de l'ensemble de données d'entraînement original tout en fournissant la distribution d'étiquettes suivante :\n",
    "- **0**: `0.4`.\n",
    "- **1**: `0.1`.\n",
    "- **2**: `0.05`.\n",
    "- **3**: `0.01`.\n",
    "- **4**: `0.2`.\n",
    "- **5**: `0.14`.\n",
    "- **6**: `0.02`.\n",
    "- **7**: `0.005`.\n",
    "- **8**: `0.045`.\n",
    "- **9**: `0.03`.\n",
    "\n",
    "De plus, calculez l'histogramme de l'ensemble de données résultant.\n",
    "\n",
    "Notez que nous allons d'abord entraîner notre modèle sur un ensemble de données d'entraînement non équilibré, mais évaluez-le sur l'ensemble de validation équilibré que nous utilisons depuis le début de ce tutoriel. Nous construirons ensuite un ensemble de validation avec une distribution qui correspond à celle de l'ensemble d'entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "-irncrQq4MD-",
    "outputId": "f6cbe23a-3a3f-494c-b8e1-98f2a81d905f"
   },
   "outputs": [],
   "source": [
    "label_distribution = {\n",
    "    0: 0.4,\n",
    "    1: 0.1,\n",
    "    2: 0.05,\n",
    "    3: 0.01,\n",
    "    4: 0.2, \n",
    "    5: 0.14,\n",
    "    6: 0.02,\n",
    "    7: 0.005,\n",
    "    8: 0.045,\n",
    "    9: 0.03\n",
    "}\n",
    "\n",
    "# choisissez les données selon la distribution donnée\n",
    "select_imgs, select_labels = ... # à compléter.\n",
    "\n",
    "# tracer l'histogramme des étiquettes correspondantes\n",
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0Z9BMTZN36h"
   },
   "source": [
    "## L'exactitude est-elle une bonne mesure pour un ensemble de données déséquilibré ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47WPFK9zOaxz"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Entraînez un modèle en utilisant votre nouvel ensemble de données d'entraînement extraites et évaluez sa performance sur l'ensemble de données de validation. Utilisez les arguments suivants :\n",
    "- **epochs** : `15`.\n",
    "- **batch_size** : `32`.\n",
    "- **metrics** : `{'Exactitude': accuracy} `.\n",
    "\n",
    "Qu'observez-vous en termes de différences entre l'exactitude d'entraînement et l'exactitude de validation? Qu'observez-vous en ce qui concerne l'exactitude des étiquettes moins fréquentes ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxnLmJWo-Xze"
   },
   "outputs": [],
   "source": [
    "# Entraînement sur les données sélectionnées\n",
    "modelUnbal = ... # à compléter.\n",
    "\n",
    "# Évaluation sur l'ensemble de données de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NruL0f6L-Ps"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6XexaV-HRfqC"
   },
   "source": [
    "### Exercice\n",
    "Lorsque nous disposons d'un ensemble de données déséquilibré, le score F1 est généralement une mesure de performance recommandée car il peut être interprété comme une moyenne pondérée des [scores de précision et de rappel](https://fr.wikipedia.org/wiki/Pr%C3%A9cision_et_rappel).\n",
    "\n",
    "Entraînez un modèle en utilisant l'ensemble de données d'entraînement extraites et évaluez ses performances sur l'ensemble de données de validation. Utilisez les mêmes arguments que pour le dernier exercice, mais ajoutez le score F1 :\n",
    "- **epochs** : `15`.\n",
    "- **batch_size** : `32`.\n",
    "- **metrics** : `{'Exactitude': accuracy, 'F1' : f1_score}`.\n",
    "\n",
    "Quelles différences observez-vous en termes de mesure des performances entre les ensembles de données d'entraînement et de validation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Z44t-ro_Df0"
   },
   "outputs": [],
   "source": [
    "# Entraînement sur les données sélectionnées\n",
    "modelUnbal = ... # à compléter.\n",
    "\n",
    "# Évaluation sur l'ensemble de données de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6q7fPgwjmGWi"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7-qY_oH23sh"
   },
   "source": [
    "### Exercice\n",
    "Imaginez maintenant que l'ensemble de validation soit aussi déséquilibré que l'ensemble d'entraînement. L'observation faite précédemment est-elle toujours valable ?\n",
    "\n",
    "Pour répondre à cette question, extrayez 30 % de l'ensemble de données de validation original avec la distribution d'étiquettes ci-dessus et utilisez-le comme nouvel ensemble de validation pour cet exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "lOAV8z1y7vqt",
    "outputId": "20bb3970-1f9f-4713-e401-b70c38bd86b8"
   },
   "outputs": [],
   "source": [
    "# sélectionner 30 % de l'ensemble de validation avec la distribution fournie\n",
    "# des étiquettes\n",
    "unb_valid_imgs, unb_valid_labels = ... # à compléter.\n",
    "\n",
    "\n",
    "# entraînement avec des ensembles d'entraînement et de validation non équilibrés\n",
    "modelUnbal = ... # à compléter.\n",
    "\n",
    "# Évaluer sur l'ensemble de validation non-équilibré\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3CbcmNLO4mQ"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdwjfGNmTST_"
   },
   "source": [
    "## Gestion des ensembles de données déséquilibrés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vz8TGOohTcJ_"
   },
   "source": [
    "Une façon d'atténuer l'effet d'un ensemble de données déséquilibré pendant le processus d'entraînement est de pénaliser le modèle lorsqu'il fait des erreurs de classification sur des classes moins fréquentes. Un moyen d'y parvenir est d'attribuer des poids d'importance aux étiquettes qui sont inversement proportionnels à leur densité dans l'ensemble de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3iJ_-vWVG9Y"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Calculez les poids d'importance de chaque étiquette en utilisant la distribution des étiquettes fournie à la section précédente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiS2HFH9IbNe"
   },
   "outputs": [],
   "source": [
    "label_weights = ... # à compléter.\n",
    "\n",
    "for i, w in enumerate(label_weights):\n",
    "  print(\"Poids d'importance pour {:<5s} ({}): {:.1f}\".format(classe_names[i], i, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntkItzYLVN8I"
   },
   "source": [
    "### Exercice\n",
    "\n",
    "En utilisant les poids d'importance calculés ci-dessus, entraînez un modèle en utilisant l'ensemble de données d'entraînement extraites et évaluez sa performance sur l'ensemble de données de validation d'origine. Afin d'obtenir des comparaisons équitables, utilisez les mêmes arguments que dans l'exercice précédent :\n",
    "- **epochs** : `15`.\n",
    "- **batch_size** : `32`.\n",
    "- **metrics** : `{'Exactitude': accuracy, 'F1': f1_score}`.\n",
    "\n",
    "Notez que les poids d'importance peuvent être transmis à la méthode d'entraînement en utilisant l'argument `label_weights`.\n",
    "\n",
    "Qu'observez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACbafl1BGgTw"
   },
   "outputs": [],
   "source": [
    "# Entraînement sur les données sélectionnées\n",
    "modelUnbal2 = ... # à compléter.\n",
    "\n",
    "# Évaluation sur l'ensemble de données de validation\n",
    "_ = ... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5w8vbPPmaV6"
   },
   "source": [
    "... # à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4QJ0cBCe483"
   },
   "source": [
    "# Reproductibilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfk8gF1pG8oo"
   },
   "source": [
    "Nous avons vu qu'il y a place pour beaucoup de hasard dans les expériences d'apprentissage automatique, en particulier durant:\n",
    "- la division d'un ensemble de données original en ensembles d'entraînement/validation/évaluation.\n",
    "- l'initialisation des paramètres d'un modèle.\n",
    "- la division d'un ensemble d'entraînement en lots pour entraîner un modèle.\n",
    "\n",
    "Par conséquent, nous obtenons normalement des résultats différents chaque fois que nous menons la même expérience. Pour permettre la reproductibilité de vos résultats, il est nécessaire de fixer la **graine aléatoire** avant de créer chaque ensemble de données et chaque modèle. Par conséquent, pour être reproductible, il est préférable de fixer manuellement les éléments suivants:\n",
    "\n",
    "1. Générateur de nombres pseudo-aléatoires en python à une valeur fixe :\n",
    "```\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "```\n",
    "\n",
    "2. Générateur de nombres pseudo-aléatoires NumPy à une valeur fixe :\n",
    "```\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "```\n",
    "\n",
    "3. Générateur de nombres pseudo-aléatoires PyTorch à une valeur fixe pour tous les appareils (CPU et GPU) :\n",
    "```\n",
    "import torch\n",
    "torch.manual_seed(seed_value)\n",
    "```\n",
    "\n",
    "4. Générateur de nombres pseudo-aléatoires PyTorch à une valeur fixe pour le(s) GPU :\n",
    "```\n",
    "import torch\n",
    "torch.cuda.manual_seed(seed_value)  # Current GPU.\n",
    "torch.cuda.manual_seed_all(seed_value)  # All GPUs.\n",
    "```\n",
    "\n",
    "5. Algorithmes CuDNN (une extension de CUDA pour l'apprentissage profond) pour être déterministe dans PyTorch:\n",
    "```\n",
    "import torch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "```\n",
    "\n",
    "Notez que les algorithmes déterministes peuvent rendre les calculs considérablement plus lents. Bien que la fixation manuelle des graines aléatoires aide à la reproductibilité, des résultats complètement reproductibles ne sont pas garantis pour toutes les versions de PyTorch et les différentes plateformes, dispositifs ou pilotes (*drivers*).\n",
    "\n",
    "De plus, il y a plus de hasard lors du réglage des hyperparamètres ou de l'utilisation de plusieurs GPU en parallèle, mais cela dépasse la portée de ce tutoriel.\n",
    "\n",
    "Enfin, une bonne pratique, mise en œuvre dans Scikit-Learn, consiste à créer un objet RandomState local au lieu d'utiliser l'objet RandomState global et de le passer à chaque module en utilisant le caractère aléatoire. Cependant, l'API Pytorch ne le permet pas, et pour l'instant, il est recommandé d'utiliser des générateur de nombres pseudo-aléatoires globaux.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IVADO AP1FR tutoriel 1 data - exercise",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
