{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mipSoOVlavkb",
    "lines_to_next_cell": 0
   },
   "source": [
    "# IVADO/MILA ÉCOLE D'APPRENTISSAGE PROFOND\n",
    "\n",
    "# 4e édition (automne 2019)\n",
    "\n",
    "# Tutoriel sur les données catégorielles avec perceptron multicouche (MLP)\n",
    "\n",
    "## Auteurs :\n",
    "\n",
    "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
    "\n",
    "Gaétan Marceau Caron <gaetan.marceau.caron@mila.quebec>\n",
    "\n",
    "## Traducteur: \n",
    "\n",
    "Andrew Williams <andrew.williams@umomntreal.ca>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLHwvggEZERd",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Préface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKNGtQkkohiM",
    "lines_to_next_cell": 0
   },
   "source": [
    "Ce tutoriel présente les aspects pratiques de l'apprentissage profond par la réalisation d'un projet simple de bout en bout. Nous utiliserons la bibliothèque d'apprentissage profond <a href=\"https://pytorch.org/\"> `PyTorch`</a>, qui est bien connue pour sa facilité d'utilisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOD70vdvvtin",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nq9FwFVnQihX",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Chargement de bibliothèques et utilisation de GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reCpBfp1Qcrt",
    "lines_to_next_cell": 0
   },
   "source": [
    "Avant de commencer, nous installons les bibliothèques nécessaires pour le tutoriel à l'aide de pip. Pour ce faire, exécutez la cellule suivante en la sélectionnant et en utilisant `shift+Enter`. Cette étape peut prendre quelques minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "c5AlBPjnvzNh",
    "outputId": "48285c9a-dbd0-4585-e493-c089116ae91e"
   },
   "outputs": [],
   "source": [
    "!pip install 'torch==1.1.0' 'torchvision==0.3.0' 'Pillow==4.3.0' 'matplotlib==3.0.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djF9gjzLwsDB",
    "lines_to_next_cell": 0
   },
   "source": [
    "Maintenant, importez tous les modules que nous allons utiliser pour ce tutoriel en exécutant la cellule suivante :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "w9LnNnxBw0wC",
    "outputId": "2423e91f-ab6a-4ad2-db83-948e14bf0f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de torch:  1.6.0\n",
      "GPU disponible: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed) # Set the random seed of numpy for the data split.\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "\n",
    "print(\"Version de torch: \", torch.__version__)\n",
    "print(\"GPU disponible: {}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKzgFV9Favkt",
    "lines_to_next_cell": 0
   },
   "source": [
    "## PyTorch en quelques mots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vrus_-F0avkt",
    "lines_to_next_cell": 0
   },
   "source": [
    "*PyTorch* est une bibliothèque Python qui soutien un écosystème dynamique d'outils et de bibliothèques pour l’AA en vision, TLN, et plus encore. Elle offre deux fonctionnalités de haut niveau :\n",
    "\n",
    "<ul>\n",
    "<li> opérations sur des <a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\">tenseurs</a> (tels que NumPy) avec soutien pour GPU,</li>\n",
    "<li> des opérations de création et d'optimisation de graphes de calcul avec un système de dérivation automatique appelé <a href=\"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py\">Autograd</a>.</li>\n",
    "</ul>\n",
    "<a href=\"https://pytorch.org/docs/stable/torch.html\">Les documents PyTorch</a> contiennent la documentation API et <a href=\"https://pytorch.org/tutorials/\">de nombreux tutoriels</a>. De plus, PyTorch offre plusieurs fonctionnalités de traitement de données. L'une de ces fonctionnalités est la classe <a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.Dataset`</a> qui offre une interface facile à utiliser pour gérer un ensemble de données. Pour plus d'informations, référez-vous aux url suivantes :\n",
    "\n",
    "<ul>\n",
    "<li>Ensembles de données PyTorch: <a href=\"http://pytorch.org/docs/master/data.html\"> PyTorch - datasets</a>.</li>\n",
    "<li>Un tutoriel de téléchargement de données: <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"> PyTorch - data loading tutorial</a>.</li>\n",
    "</ul>\n",
    "<a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> Est une bibliothèque qui fournit les mêmes fonctions que les tenseurs de CPU mais pour les tenseurs CUDA, qui sont utilisés pour le calcul sur GPU. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> Retourne une valeur booléenne indiquant si CUDA est actuellement disponible. Enfin, nous vous recommandons d'utiliser une variable `device` qui identifie le périphérique sur lequel vous souhaitez effectuer des calculs. Nous pouvons affecter un tenseur à un périphérique avec la méthode `.to(device)`. Par défaut, les tenseurs sont des tenseurs de CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm122vNmq92L",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ingrédients pour une preuve de concept (POC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqvhR0ebavmE",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour réaliser un POC en AA, vous avez besoin de :\n",
    "\n",
    "<ul>\n",
    "<li>une description de la tâche ainsi que des données à l'appui,</li>\n",
    "<li>une mesure d'évaluation pour évaluer la performance d'un modèle,</li>\n",
    "<li>une description du modèle, </li>\n",
    "<li>une fonction de coût à optimiser,</li>\n",
    "<li>un optimiseur qui ajuste les paramètres du modèle.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8_pfpu2f6AO",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment préparer l’ensemble de données ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5piZxYUhSzq",
    "lines_to_next_cell": 0
   },
   "source": [
    "Notre tâche est de prédire si un passager a survécu ou non au naufrage du Titanic seulement en fonction de la base des données des passagers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4GuYNDFavlU",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ensemble de données Titanic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiOJx2ytavlU",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous pouvons télécharger le jeu de données Titanic à l'adresse suivante : https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/> Cet ensemble de données fournit des informations sur le sort de 1309 passagers du premier et unique voyage du bateau \"RMS Titanic\", résumé par le statut économique (classe), sexe, âge, informations familiales et survie. La plate-forme Kaggle utilise également cet ensemble de données comme une introduction à l'apprentissage automatique classique. Ici, nous l'utilisons pour introduire des concepts plus avancés liés à PyTorch et à l'apprentissage profond.\n",
    "\n",
    "Nous utilisons la bibliothèque <a href=\"https://pandas.pydata.org/\">Pandas</a> pour stocker le jeu de données en mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "bX_RSiffavlW",
    "outputId": "65feb3e0-c4e7-4812-e918-3767946f865d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true', \n",
    "    sep='\\t', \n",
    "    index_col=None, \n",
    "    na_values=['NA']\n",
    ")\n",
    "\n",
    "# un aperçu des 5 premiers points de données\n",
    "titanic_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj88WmCmavlf",
    "lines_to_next_cell": 0
   },
   "source": [
    "**La signification des différentes colonnes (caractéristiques) est la suivante**:\n",
    "\n",
    "<ol>\n",
    "  <li> <b>pclass</b>: Classe du passager (1 = première; 2 = deuxième; 3 = troisième) </li>\n",
    "  <li> <b>survived</b>: Survécu? (0 = non; 1 = oui) </li>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, soeurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou d'enfants à bord </li>\n",
    "  <li> <b>ticket</b>: Numéro de ticket </li>\n",
    "  <li> <b>fare</b>: Tarif du passager </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n",
    "  <li> <b>boat</b>: Bateau de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro du corps (si le passager n'a pas survécu et que le corps a été retrouvé) </li>\n",
    "  <li> <b>home.dest</b>: Destination du passager </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2ed5fozqjce",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Pré-traitement des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__vcZhPnavlg",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Sélection de caractéristique\n",
    "\n",
    "Certaines caractéristiques ne sont pas pertinentes pour la tâche, par exemple :\n",
    "\n",
    "<ol>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>ticket</b>: Numéro du ticket </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>home.dest</b>: Destination du passager </li>\n",
    " </ol>\n",
    " \n",
    "D'autres caractéristiques dévoilent la cible à prédire et les inclure serait de la triche:\n",
    "<ol>\n",
    "  <li> <b>boat</b>: Bateau de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro du corps (si le passager n'a pas survécu et que le corps a été retrouvé)  </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "JJ0--SDpavlg",
    "outputId": "bb15e866-2779-4e6f-9deb-4eedf70248ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass_1  pclass_2  pclass_3  sex_female  sex_male      age  \\\n",
       "0         1         1         0         0           1         0  29.0000   \n",
       "1         1         1         0         0           0         1   0.9167   \n",
       "2         0         1         0         0           1         0   2.0000   \n",
       "3         0         1         0         0           0         1  30.0000   \n",
       "4         0         1         0         0           1         0  25.0000   \n",
       "\n",
       "   sibsp  parch      fare  embarked_C  embarked_Q  embarked_S  \n",
       "0      0      0  211.3375           0           0           1  \n",
       "1      1      2  151.5500           0           0           1  \n",
       "2      1      2  151.5500           0           0           1  \n",
       "3      1      2  151.5500           0           0           1  \n",
       "4      1      2  151.5500           0           0           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_preprocess_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true', \n",
    "    sep=',', \n",
    "    index_col=None\n",
    ")\n",
    "\n",
    "titanic_preprocess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MckYm0M_xhR",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Encodage de Caractéristiques\n",
    "\n",
    "Certaines caractéristiques sont des **variables catégorielles**, ce qui signifie qu'elles peuvent prendre un nombre fini de valeurs.\n",
    "\n",
    " <ol>\n",
    "  <li> <b>pclass</b>: Classe du passager </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement </li>\n",
    " </ol>\n",
    "Pour traiter les variables catégorielles, nous devons les encoder d'une manière qui n'implique pas un ordre arbitraire, comme l'utilisation de nombres naturels (par exemple, 1, 2, 3). <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">L’ encodage one-hot (1 parmi n)</a> est un moyen de le réaliser. Nous pouvons télécharger le jeu de données pré-traité à l'adresse suivante : https://github.com/afansi/winterschool18/blob/master/titanic\\_prepocess.csv?raw=true . <br>La signification des variables encodées est la suivante :\n",
    "\n",
    "<ol>\n",
    "  <li> <b>survived</b>: Survécu? (0 = non; 1 = oui) </li>\n",
    "  <li> <b>pclass_1</b>: (1 si passager en première classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_2</b>: (1 si passager en deuxième classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_3</b>: (1 si passager en troisième classe; 0 sinon) </li>\n",
    "  <li> <b>sex_female</b>: (1 si passager est une femme; 0 sinon) </li>\n",
    "  <li> <b>sex_male</b>: (1 si passager est un homme ; 0 sinon) </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, soeurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou d'enfants à bord </li>\n",
    "  <li> <b>fare</b>: Tarif du passager </li>\n",
    "  <li> <b>embarked_C</b>: (1 si Port d'embarquement = Cherbourg (C); 0 sinon) </li> \n",
    "  <li> <b>embarked_Q</b>: (1 si Port d'embarquement = Queenstown (Q); 0 sinon) </li> \n",
    "  <li> <b>embarked_S</b>: (1 si Port d'embarquement = Southampton (S); 0 sinon)</li> \n",
    " </ol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJcs6PUTavlm",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Partition Entraînement / validation / évaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bjbgvffmavlo",
    "lines_to_next_cell": 0
   },
   "source": [
    "À ce stade, nous devons diviser l'ensemble de données en trois sous-ensembles:\n",
    "\n",
    "<ol>\n",
    "<li> <b> Train</b> (généralement 60% de l'ensemble de données): utilisé pour entraîner le modèle de classification. </li>   \n",
    "<li> <b> Validation</b> (généralement 20% de l'ensemble de données): utilisé pour évaluer les hyper-paramètres sur un ensemble de données différent. </li>   \n",
    "<li> <b> Test</b> (généralement 20% de l'ensemble de données): utilisé pour évaluer la performance de généralisation du modèle choisi sur un ensemble de données différent. </li>\n",
    "</ol>\n",
    "Nous utilisons la <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.split.html\">fonction numpy.split</a> pour séparer notre ensemble de données en sous-ensembles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBmL8VBOavlo"
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(\n",
    "    titanic_preprocess_df.sample(frac=1, random_state=seed), \n",
    "    [int(.6*len(titanic_preprocess_df)), int(.8*len(titanic_preprocess_df))])\n",
    "\n",
    "# Retirez la colonne d'étiquettes de X et créez un vecteur d'étiquettes.\n",
    "X_train = train.drop(['survived'], axis=1).values\n",
    "y_train = train['survived'].values\n",
    "\n",
    "X_val = validate.drop(['survived'], axis=1).values\n",
    "y_val = validate['survived'].values\n",
    "\n",
    "X_test = test.drop(['survived'], axis=1).values\n",
    "y_test = test['survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv74TbIWavlr",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ensemble de données dans PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_LJtG-Xavlt",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous utiliserons la sous-classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.TensorDataset`</a> </b> pour manipuler ensemble les caractéristiques et les cibles d'un ensemble de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JtT4tV7avlt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obEPHnlTavkc",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment définir l'algorithme d'apprentissage ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhN5GL6Gavks",
    "lines_to_next_cell": 0
   },
   "source": [
    "Un perceptron multicouche (MLP/PMC) est un simple graphe de calcul composé de \"couches cachées\", qui sont définies par deux modules: Une *transformation linéaire* suivie d'une *non-linéarité*. Le résultat d'une couche cachée est un vecteur appelé *représentation distribuée* où chaque composant est associé à plusieurs unités cachées.\n",
    "\n",
    "Pour entraîner ce modèle, nous devons définir :\n",
    "\n",
    "<ul>\n",
    "<li>l'architecture du réseau en choisissant la fonction non linéaire et le nombre d'unités cachées par couche, </li>\n",
    "<li>la fonction de coût et l'optimiseur.  </li>\n",
    "</ul>\n",
    "Pour résoudre notre tâche, nous allons utiliser un MLP avec les propriétés suivantes :\n",
    "\n",
    " <ul>\n",
    " <li> la dimension d'entrée du modèle est de 12,</li>\n",
    " <li> la dimension de sortie du modèle est de 2,</li>\n",
    " <li> la première dimension de la sortie est la probabilité de décès et la deuxième dimension est la probabilité de survie,</li>\n",
    "  <li> le nombre de couches cachées est de 3, </li>\n",
    " <li> les dimensions des couches cachées sont respectivement de 20, 40, 20, </li>\n",
    " <li> la fonction d'activation est une ReLu pour toutes les couches cachées. </li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "701t0e-ravkr",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Comment définir un modèle dans PyTorch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4F5cyijavkv",
    "lines_to_next_cell": 0
   },
   "source": [
    "La <a href=\"https://pytorch.org/docs/stable/nn.html\">bibliothèque PyTorch NN</a> contient de nombreuses classes utiles pour la création de graphes de calcul.\n",
    "\n",
    "<ul>\n",
    "<li> La classe <a href=\"http://pytorch.org/docs/master/nn.html#module\">torch.nn.Module</a>: \n",
    "tout nouveau module doit hériter de cette classe ou de ses descendants (sous-classes).\n",
    "</li>   \n",
    "<li> La méthode `forward` : toute classe définissant un module doit implémenter la méthode `forward(...)`, qui définit la transformation des entrées en sorties.</li>  \n",
    "<li> La classe <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a>: cette classe implémente une transformation linéaire. Par défaut, elle prend deux paramètres : \n",
    "    <ul>\n",
    "    <li>`in_features`: la taille des données à l'entrée du module. </li>\n",
    "    <li>`out_features`: la taille des données à la sortie du module. </li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li> Le module <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">`torch.nn.functional`</a>: \n",
    "elle définit un ensemble de fonctions qui peuvent être appliquées directement à n'importe quel tenseur. À titre d'exemple, nous avons :\n",
    "    <ul>\n",
    "    <li> les fonctions non-linéaires: sigmoid(...), tanh(...), relu(...), etc...</li> \n",
    "    <li> les fonctions de coût : mse_loss(...), nll(...., cross_entropy(...), etc ...</li> \n",
    "    <li> les fonctions de régularisation: droupout(...), etc ... </li> \n",
    "    <li> ...</li> \n",
    "    </ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tscha6S-KIBB",
    "lines_to_next_cell": 0
   },
   "source": [
    "Vous devez compléter les méthodes suivantes :\n",
    "\n",
    "<ul>\n",
    "<li>La méthode `__init__` qui définit les couches. </li>\n",
    "<li>La méthode `forward(input)` qui retourne le `output` (sortie). </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NyQGwC-avkw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR5eBfIbavk0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 20)\n",
    "        self.fc2 = nn.Linear(20, 40)\n",
    "        self.fc3 = nn.Linear(40, 20)\n",
    "        self.fc4 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        out = self.fc4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvLnHRZ5avk2",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Faire des prédictions avec un réseau de neurones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEXgJMDDavk3",
    "lines_to_next_cell": 0
   },
   "source": [
    "Maintenant, nous sommes prêts à tester notre réseau de neurones sur des données choisies au hasard.\n",
    "\n",
    "Dans PyTorch, un modèle a deux modes différents : <ul> <li> <b>train</b>: utilisé pendant l’entraînement, </li> <li> <b>eval</b>: utilisé pendant l'inférence pour l'évaluation du modèle. </li> </ul> La distinction est importante car certains modules se comportent différemment selon ce mode. Nous utiliserons le mode <b>évaluation</b> dans cette section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "gzcABMezavk6",
    "outputId": "d65d2777-ee2a-4f9d-9259-edb76428ad6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5093, 0.4907],\n",
      "        [0.5069, 0.4931],\n",
      "        [0.5129, 0.4871],\n",
      "        [0.5022, 0.4978],\n",
      "        [0.4427, 0.5573]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Définition du modèle\n",
    "neural_net = NeuralNet()\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "# Activation du mode d'évaluation\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Sélectionner les 5 premiers points de données\n",
    "data, target = val_dataset[0:5]\n",
    "data = data.to(device)\n",
    "target = target.to(device)\n",
    "\n",
    "# Propagation avant des données à travers le modèle\n",
    "output = neural_net(data)   # équivalent à neural_net.forward(data)\n",
    "\n",
    "# Convertir les logits en probabilités avec la fonction softmax\n",
    "output_proba = F.softmax(output, dim=1)\n",
    "\n",
    "# Imprimer la probabilité\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVep0BElavlS",
    "lines_to_next_cell": 0
   },
   "source": [
    "Les rangées définissent la sortie du réseau, en termes de probabilités sur deux classes : <b>deceased</b> (première colonne) ou <b>survived</b> (deuxième colonne), pour chacun des cinq points de données d'entrée. Prenons l'étiquette avec la probabilité maximale comme étiquette prédite et comparons-la à l'étiquette correcte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "_jV4No36qjdU",
    "outputId": "995f5958-ab4d-4c8a-e486-f303405e1e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction du modèle\n",
      "tensor([0, 0, 0, 0, 1])\n",
      "Données réelles\n",
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Impression des prédictions (classe avec la plus grande probabilité)\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print('Prédiction du modèle')\n",
    "print(prediction)\n",
    "\n",
    "# Impression des vraies étiquettes\n",
    "print(\"Données réelles\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEIIjqOuqjdc",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**\n",
    "\n",
    "1. Quelle serait une façon simple de mesurer la performance du modèle ?\n",
    "2. Comment notre modèle performe-t-il ?\n",
    "3. Étant donné que le modèle n'est pas entraîné sur l’ensemble de données, constatez-vous un problème avec la mesure sélectionnée ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTTlBikYwb-w",
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "**Réponses possibles** :\n",
    "\n",
    "\n",
    "1.   Une mesure simple de la performance est l'exactitude, le nombre de prévisions correctes sur le nombre total d'exemples.\n",
    "2.   Ce modèle a une exactitude de 4/5 = 80%.\n",
    "3.   Avec l'exactitude, nous avons déjà un score de 80% avec un poids aléatoire, ce qui se produit lorsque les étiquettes sont déséquilibrées, et le modèle prédit la classe dominante par hasard. Dans cette section, nous n'utilisons que cinq exemples pour évaluer le modèle, ce qui n'est pas suffisant. Toutefois, si nous observons ce comportement sur tout l'ensemble de validation, nous pouvons alors considérer une autre mesure de performance (par exemple, la précision/le rappel ou le score F1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uySA2TCavmD",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Définir la fonction de coût et l'optimiseur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkoobCLMavmE",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Fonction de coût\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7uSXQavmF",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons la fonction de coût en fonction de la tâche que nous voulons réaliser.\n",
    "\n",
    "PyTorch offre <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">de nombreuses fonctions de coût prêtes à utiliser</a>.\n",
    "\n",
    "Pour les problèmes de classification, la fonction de coût habituelle est <b>l'entropie croisée</b>, et c'est celle que nous utiliserons dans ce tutoriel. Dans PyTorch, elle est définie par la fonction <a href=\"https://pytorch.org/docs/master/nn.functional.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a>.  L'entropie croisée permet de comparer une distribution $p$ avec une distribution de référence $t$. Elle atteint son minimum lorsque $t=p$. La formule pour la calculer avec la prédiction et la cible est la suivante : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHnfYeS5avmF"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def cost_function(prediction, target):\n",
    "    loss = F.cross_entropy(prediction, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vsx_cv9Wqjdj",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Rétropropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hcZaIKtavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "Dans PyTorch, grâce au mécanisme de dérivation automatique <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, il est possible de calculer automatiquement le gradient de la fonction de coût et de la rétropropager à travers le graphe de calcul.\n",
    "\n",
    "Pour ce faire, il suffit d'appeler la méthode `backward()` sur la variable retournée par la fonction de coût, par exemple, avec\n",
    "\n",
    "`loss = cost_function(....)` <br> `loss.backward()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YNo_ymYavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Optimisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4AlX9TwavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "PyTorch fournit un <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">ensemble de méthodes d'optimisation (`torch.optim`)</a> couramment utilisées par la communauté d'apprentissage profond. Ces méthodes incluent les suivantes :\n",
    "\n",
    "<ul>\n",
    "<li><b>SGD</b> (Descente de gradient stochastique) <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a></li>\n",
    "<li><b>Adam</b> (Adaptive Moment Estimation) : une variante de la méthode de descente de gradient dans laquelle le taux d'apprentissage est ajusté pour chaque paramètre. Cet ajustement est basé sur l'estimation des premier et deuxième moments des gradients. Cet optimiseur a démontré d'excellentes performances par rapport à la méthode SGD sur de nombreuses tâches de référence. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uam-a0_0qjdl",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour pouvoir utiliser un optimiseur dans PyTorch, nous devons l'instancier en passant les éléments suivants :\n",
    "\n",
    "<ul>\n",
    "<li><b>Les paramètres du modèle</b> : ils sont obtenus en utilisant la méthode <b>parameters()</b> sur le modèle instancié.</li>\n",
    "    <li><b>Le taux d'apprentissage / <i>learning rate (lr)</i> </b>: c'est le taux d'apprentissage qui doit être utilisé pour mettre à jour les paramètres pendant le processus d'optimisation. </li>\n",
    "<li>Il peut y avoir d'autres paramètres spécifiques à l'optimiseur choisi.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jt6_Qr6ravmI",
    "lines_to_next_cell": 0
   },
   "source": [
    "PyTorch offre une interface simplifiée pour interagir avec n'importe quel optimiseur :\n",
    "\n",
    "<ul>\n",
    "<li><b>zero_grad()</b>: Permet de réinitialiser les gradients à zéro au début d'une étape d'optimisation.</li>\n",
    "<li><b>step()</b>: Permet d'effectuer une étape d'optimisation après une étape de rétropropagation de gradient.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZ-lKExqavmI",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous utiliserons Adam avec un taux d’apprentissage *(lr)* de 0.001.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDMOziJTavmI"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnFOAfdGqjdr",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment entraîner un modèle?\n",
    "\n",
    "Tout d'abord, nous avons besoin de définitions :\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "<b>Époque / Epoch</b>:  un passage complet sur l'ensemble des données d'entraînement.\n",
    "</li>\n",
    "<li>\n",
    "<b>Itération / Iteration</b>: une mise à jour des paramètres du modèle. De nombreuses itérations peuvent se produire avant la fin d'une époque.\n",
    "</li>\n",
    "<li>\n",
    "<b>Mini-lot / Mini-batch</b>:  Un sous-ensemble de données d'entraînement utilisé pour estimer la moyenne des gradients. En d'autres termes, à chaque itération, un mini-lot est utilisé.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLXjNiDTavmK",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Création des mini-lots\n",
    "\n",
    "PyTorch offre une fonction appelée <b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> pour charger n'importe quel ensemble de données et le diviser automatiquement en mini-lots. Pendant l’entraînement, les données présentées au réseau doivent apparaître dans un ordre différent d'une époque à l'autre. Nous préparerons le `DataLoader` pour nos trois ensembles de données (entraînement, validation et évaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGoQZSdqavmM"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32  # nombre de données dans un lot d'entraînement.\n",
    "eval_batch_size = 32   # nombre de données dans un lot d'évaluation.\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=False)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=eval_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia3ai-GvavmP",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Boucle d'entraînement simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9wNZrTnavmQ",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons ici notre procédure d’entraînement pour une époque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyK9xCsZavmR"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, optimizer, device):\n",
    "    \n",
    "    # activer le mode d'entraînement\n",
    "    model.train()\n",
    "    \n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # itération sur les mini-lots\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # transférer les données sur l'appareil choisi\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # réinitialiser les gradients à zéro\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # propagation avant sur les données\n",
    "        prediction = model(data)\n",
    "        \n",
    "        # calculer la fonction de coût en fonction des objectifs\n",
    "        loss = cost_function(prediction, target)\n",
    "        \n",
    "        # exécuter la rétropropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # exécuter une étape d'optimisation\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumuler les pertes\n",
    "        total_loss += loss.item()*len(data)\n",
    "        \n",
    "        # calculer le nombre de prédictions correctes\n",
    "        _, pred_classes = torch.max(prediction, dim=1)        \n",
    "        correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()\n",
    "         \n",
    "        \n",
    "    # calculer le coût moyen par époque\n",
    "    mean_loss = total_loss/len(train_loader.dataset)\n",
    "    \n",
    "    # calculer l'exactitude\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "        \n",
    "    print(\"Époque d'entraînement: {}   Perte moyenne: {:.5f}   Exac: {}/{} ({:.3f}%)\".format(\n",
    "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
    "        100. * acc))   \n",
    "    \n",
    "    # retourner la perte moyenne et l'exactitude\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxG666rmavmU",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Procédure d'évaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGexbWaHavmU",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons ici notre procédure d'évaluation du modèle. <br/> Outre le passage du modèle en mode **eval**, il est essentiel de désactiver le calcul du gradient. <br/> Pour ce faire, PyTorch offre un ensemble de gestionnaires de contexte pour <a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">désactiver/activer localement le calcul de gradient </a>:\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "`torch.no_grad()`: désactiver le calcul du gradient.\n",
    "</li>\n",
    "<li>\n",
    "`torch.enable_grad()`: activer le calcul du gradient.\n",
    "</li>\n",
    "<li>\n",
    "`torch.set_grad_enabled(bool)`: activer/désactiver le calcul du gradient.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gQj9W5LavmU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, device):\n",
    "    \n",
    "    # activer le mode d'évaluation\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # itération sur les lots\n",
    "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
    "\n",
    "            # transférer les données sur l'appareil choisi\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # propagation avant sur les données\n",
    "            prediction = model(data)\n",
    "\n",
    "            # calculer la fonction de coût en fonction des objectifs\n",
    "            loss = cost_function(prediction, target)           \n",
    "\n",
    "\n",
    "            # accumuler les pertes\n",
    "            total_loss += loss.item()*len(data)\n",
    "\n",
    "            # calculer le nombre de prédictions correctes\n",
    "            _, pred_classes = torch.max(prediction, dim=1) \n",
    "            correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()         \n",
    "          \n",
    "    \n",
    "    # calculer le coût moyen par époque\n",
    "    mean_loss = total_loss/len(eval_loader.dataset)\n",
    "    \n",
    "    # calculer l'exactitude\n",
    "    acc = correct / len(eval_loader.dataset)\n",
    "        \n",
    "    print('Eval:  Perte moyenne: {:.5f}   Exac: {}/{} ({:.3f}%)'.format(\n",
    "        mean_loss, correct, len(eval_loader.dataset),\n",
    "        100. * acc)) \n",
    "    \n",
    "    # retourner la perte moyenne et l'exactitude\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMUyZNxdavmW",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Attribution de points de contrôle (*checkpointing*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQLklQXAavmW",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour les phases d’entraînement qui nécessitent beaucoup de temps, il est recommandé d'enregistrer périodiquement les paramètres du modèle. Cette étape est communément appelée <b>attribution de points de contrôle (checkpointing)</b>.\n",
    "\n",
    "PyTorch offre <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">un mécanisme simple</a> pour effectuer cette opération.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ld-Y2gF-avmX",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous implémentons deux méthodes ici :\n",
    "\n",
    "<ul>\n",
    "<li> la première pour <b> sauvegarder </b> un modèle,</li>\n",
    "<li> la deuxième pour <b> charger </b> un point de contrôle d'un modèle.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMmNpma2avmX"
   },
   "outputs": [],
   "source": [
    "def save_model(epoch, model, path='./'):\n",
    "    \n",
    "    # créer le nom du fichier indexé par la valeur d'époque\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # sauvegarder les paramètres du modèle\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZptgqQRavmZ"
   },
   "outputs": [],
   "source": [
    "def load_model(epoch, model, path='./'):\n",
    "    \n",
    "    # créer le nom du fichier indexé par la valeur d'époque\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # charger les paramètres du modèle sauvegardé\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ve8sOocWavma",
    "lines_to_next_cell": 0
   },
   "source": [
    "Il est également possible d'enregistrer l'état de l'optimiseur dans PyTorch, ce qui est très important lorsque nous voulons reprendre l’entraînement du modèle à partir d'une certaine sauvegarde. Pour plus d'informations, veuillez consulter <a href='https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3'>l'URL suivant</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lcAP8-1avma",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Rassembler le tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "keMpyePsavmb",
    "outputId": "638ef04a-0f0e-4e8a-8b50-23884324a79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque d'entraînement: 1   Perte moyenne: 0.82669   Exac: 275/625 (44.000%)\n",
      "Eval:  Perte moyenne: 0.69597   Exac: 99/209 (47.368%)\n",
      "Époque d'entraînement: 2   Perte moyenne: 0.66111   Exac: 397/625 (63.520%)\n",
      "Eval:  Perte moyenne: 0.65175   Exac: 144/209 (68.900%)\n",
      "Époque d'entraînement: 3   Perte moyenne: 0.63141   Exac: 421/625 (67.360%)\n",
      "Eval:  Perte moyenne: 0.62352   Exac: 145/209 (69.378%)\n",
      "Époque d'entraînement: 4   Perte moyenne: 0.61599   Exac: 423/625 (67.680%)\n",
      "Eval:  Perte moyenne: 0.61681   Exac: 142/209 (67.943%)\n",
      "Époque d'entraînement: 5   Perte moyenne: 0.61261   Exac: 431/625 (68.960%)\n",
      "Eval:  Perte moyenne: 0.60453   Exac: 142/209 (67.943%)\n",
      "Époque d'entraînement: 6   Perte moyenne: 0.61117   Exac: 426/625 (68.160%)\n",
      "Eval:  Perte moyenne: 0.60108   Exac: 144/209 (68.900%)\n",
      "Époque d'entraînement: 7   Perte moyenne: 0.60210   Exac: 427/625 (68.320%)\n",
      "Eval:  Perte moyenne: 0.59878   Exac: 143/209 (68.421%)\n",
      "Époque d'entraînement: 8   Perte moyenne: 0.60072   Exac: 427/625 (68.320%)\n",
      "Eval:  Perte moyenne: 0.59606   Exac: 144/209 (68.900%)\n",
      "Époque d'entraînement: 9   Perte moyenne: 0.59455   Exac: 429/625 (68.640%)\n",
      "Eval:  Perte moyenne: 0.58268   Exac: 145/209 (69.378%)\n",
      "Époque d'entraînement: 10   Perte moyenne: 0.58700   Exac: 429/625 (68.640%)\n",
      "Eval:  Perte moyenne: 0.57752   Exac: 146/209 (69.856%)\n",
      "Époque d'entraînement: 11   Perte moyenne: 0.57737   Exac: 435/625 (69.600%)\n",
      "Eval:  Perte moyenne: 0.56965   Exac: 146/209 (69.856%)\n",
      "Époque d'entraînement: 12   Perte moyenne: 0.56613   Exac: 445/625 (71.200%)\n",
      "Eval:  Perte moyenne: 0.56516   Exac: 146/209 (69.856%)\n",
      "Époque d'entraînement: 13   Perte moyenne: 0.55887   Exac: 454/625 (72.640%)\n",
      "Eval:  Perte moyenne: 0.55602   Exac: 151/209 (72.249%)\n",
      "Époque d'entraînement: 14   Perte moyenne: 0.55907   Exac: 456/625 (72.960%)\n",
      "Eval:  Perte moyenne: 0.56250   Exac: 147/209 (70.335%)\n",
      "Époque d'entraînement: 15   Perte moyenne: 0.54461   Exac: 462/625 (73.920%)\n",
      "Eval:  Perte moyenne: 0.53498   Exac: 152/209 (72.727%)\n",
      "Époque d'entraînement: 16   Perte moyenne: 0.52883   Exac: 471/625 (75.360%)\n",
      "Eval:  Perte moyenne: 0.52431   Exac: 156/209 (74.641%)\n",
      "Époque d'entraînement: 17   Perte moyenne: 0.50891   Exac: 478/625 (76.480%)\n",
      "Eval:  Perte moyenne: 0.52312   Exac: 157/209 (75.120%)\n",
      "Époque d'entraînement: 18   Perte moyenne: 0.49627   Exac: 483/625 (77.280%)\n",
      "Eval:  Perte moyenne: 0.50566   Exac: 161/209 (77.033%)\n",
      "Époque d'entraînement: 19   Perte moyenne: 0.48700   Exac: 485/625 (77.600%)\n",
      "Eval:  Perte moyenne: 0.51311   Exac: 165/209 (78.947%)\n",
      "Époque d'entraînement: 20   Perte moyenne: 0.49819   Exac: 480/625 (76.800%)\n",
      "Eval:  Perte moyenne: 0.50521   Exac: 163/209 (77.990%)\n",
      "Époque d'entraînement: 21   Perte moyenne: 0.46607   Exac: 498/625 (79.680%)\n",
      "Eval:  Perte moyenne: 0.50268   Exac: 158/209 (75.598%)\n",
      "Époque d'entraînement: 22   Perte moyenne: 0.48540   Exac: 484/625 (77.440%)\n",
      "Eval:  Perte moyenne: 0.50149   Exac: 163/209 (77.990%)\n",
      "Époque d'entraînement: 23   Perte moyenne: 0.47134   Exac: 483/625 (77.280%)\n",
      "Eval:  Perte moyenne: 0.50674   Exac: 164/209 (78.469%)\n",
      "Époque d'entraînement: 24   Perte moyenne: 0.46481   Exac: 492/625 (78.720%)\n",
      "Eval:  Perte moyenne: 0.50154   Exac: 164/209 (78.469%)\n",
      "Époque d'entraînement: 25   Perte moyenne: 0.46043   Exac: 494/625 (79.040%)\n",
      "Eval:  Perte moyenne: 0.49345   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 26   Perte moyenne: 0.44816   Exac: 496/625 (79.360%)\n",
      "Eval:  Perte moyenne: 0.49766   Exac: 165/209 (78.947%)\n",
      "Époque d'entraînement: 27   Perte moyenne: 0.44127   Exac: 498/625 (79.680%)\n",
      "Eval:  Perte moyenne: 0.50072   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 28   Perte moyenne: 0.44017   Exac: 507/625 (81.120%)\n",
      "Eval:  Perte moyenne: 0.49737   Exac: 163/209 (77.990%)\n",
      "Époque d'entraînement: 29   Perte moyenne: 0.43723   Exac: 502/625 (80.320%)\n",
      "Eval:  Perte moyenne: 0.51149   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 30   Perte moyenne: 0.43729   Exac: 506/625 (80.960%)\n",
      "Eval:  Perte moyenne: 0.50325   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 31   Perte moyenne: 0.44262   Exac: 501/625 (80.160%)\n",
      "Eval:  Perte moyenne: 0.51388   Exac: 164/209 (78.469%)\n",
      "Époque d'entraînement: 32   Perte moyenne: 0.45369   Exac: 500/625 (80.000%)\n",
      "Eval:  Perte moyenne: 0.50466   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 33   Perte moyenne: 0.45676   Exac: 497/625 (79.520%)\n",
      "Eval:  Perte moyenne: 0.51477   Exac: 160/209 (76.555%)\n",
      "Époque d'entraînement: 34   Perte moyenne: 0.45612   Exac: 497/625 (79.520%)\n",
      "Eval:  Perte moyenne: 0.50982   Exac: 163/209 (77.990%)\n",
      "Époque d'entraînement: 35   Perte moyenne: 0.43095   Exac: 507/625 (81.120%)\n",
      "Eval:  Perte moyenne: 0.50017   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 36   Perte moyenne: 0.42578   Exac: 508/625 (81.280%)\n",
      "Eval:  Perte moyenne: 0.49845   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 37   Perte moyenne: 0.42918   Exac: 507/625 (81.120%)\n",
      "Eval:  Perte moyenne: 0.51367   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 38   Perte moyenne: 0.43003   Exac: 504/625 (80.640%)\n",
      "Eval:  Perte moyenne: 0.51591   Exac: 162/209 (77.512%)\n",
      "Époque d'entraînement: 39   Perte moyenne: 0.43331   Exac: 504/625 (80.640%)\n",
      "Eval:  Perte moyenne: 0.52294   Exac: 162/209 (77.512%)\n",
      "Époque d'entraînement: 40   Perte moyenne: 0.42899   Exac: 504/625 (80.640%)\n",
      "Eval:  Perte moyenne: 0.50765   Exac: 163/209 (77.990%)\n",
      "Époque d'entraînement: 41   Perte moyenne: 0.42353   Exac: 511/625 (81.760%)\n",
      "Eval:  Perte moyenne: 0.53098   Exac: 160/209 (76.555%)\n",
      "Époque d'entraînement: 42   Perte moyenne: 0.43162   Exac: 510/625 (81.600%)\n",
      "Eval:  Perte moyenne: 0.51242   Exac: 165/209 (78.947%)\n",
      "Époque d'entraînement: 43   Perte moyenne: 0.42274   Exac: 508/625 (81.280%)\n",
      "Eval:  Perte moyenne: 0.52351   Exac: 161/209 (77.033%)\n",
      "Époque d'entraînement: 44   Perte moyenne: 0.41901   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.51061   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 45   Perte moyenne: 0.41774   Exac: 508/625 (81.280%)\n",
      "Eval:  Perte moyenne: 0.51765   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 46   Perte moyenne: 0.42539   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.49882   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 47   Perte moyenne: 0.42986   Exac: 510/625 (81.600%)\n",
      "Eval:  Perte moyenne: 0.52549   Exac: 161/209 (77.033%)\n",
      "Époque d'entraînement: 48   Perte moyenne: 0.42133   Exac: 510/625 (81.600%)\n",
      "Eval:  Perte moyenne: 0.51714   Exac: 165/209 (78.947%)\n",
      "Époque d'entraînement: 49   Perte moyenne: 0.42430   Exac: 511/625 (81.760%)\n",
      "Eval:  Perte moyenne: 0.51036   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 50   Perte moyenne: 0.41490   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.49750   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 51   Perte moyenne: 0.40705   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.51579   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 52   Perte moyenne: 0.41079   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.51171   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 53   Perte moyenne: 0.40665   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.51348   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 54   Perte moyenne: 0.40773   Exac: 510/625 (81.600%)\n",
      "Eval:  Perte moyenne: 0.50584   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 55   Perte moyenne: 0.40528   Exac: 514/625 (82.240%)\n",
      "Eval:  Perte moyenne: 0.51098   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 56   Perte moyenne: 0.40169   Exac: 516/625 (82.560%)\n",
      "Eval:  Perte moyenne: 0.51603   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 57   Perte moyenne: 0.40443   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.51208   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 58   Perte moyenne: 0.40677   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.51689   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 59   Perte moyenne: 0.40295   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.50207   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 60   Perte moyenne: 0.41354   Exac: 513/625 (82.080%)\n",
      "Eval:  Perte moyenne: 0.51340   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 61   Perte moyenne: 0.40447   Exac: 517/625 (82.720%)\n",
      "Eval:  Perte moyenne: 0.51662   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 62   Perte moyenne: 0.40276   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.51596   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 63   Perte moyenne: 0.40671   Exac: 509/625 (81.440%)\n",
      "Eval:  Perte moyenne: 0.52560   Exac: 164/209 (78.469%)\n",
      "Époque d'entraînement: 64   Perte moyenne: 0.40590   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.54552   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 65   Perte moyenne: 0.41163   Exac: 514/625 (82.240%)\n",
      "Eval:  Perte moyenne: 0.50450   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 66   Perte moyenne: 0.40486   Exac: 510/625 (81.600%)\n",
      "Eval:  Perte moyenne: 0.51603   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 67   Perte moyenne: 0.40354   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.53236   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 68   Perte moyenne: 0.40674   Exac: 517/625 (82.720%)\n",
      "Eval:  Perte moyenne: 0.52243   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 69   Perte moyenne: 0.39861   Exac: 514/625 (82.240%)\n",
      "Eval:  Perte moyenne: 0.51513   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 70   Perte moyenne: 0.39501   Exac: 516/625 (82.560%)\n",
      "Eval:  Perte moyenne: 0.51965   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 71   Perte moyenne: 0.40384   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.53967   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 72   Perte moyenne: 0.39575   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.54079   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 73   Perte moyenne: 0.41207   Exac: 503/625 (80.480%)\n",
      "Eval:  Perte moyenne: 0.51060   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 74   Perte moyenne: 0.39802   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.50302   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 75   Perte moyenne: 0.39220   Exac: 518/625 (82.880%)\n",
      "Eval:  Perte moyenne: 0.52859   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 76   Perte moyenne: 0.39656   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.51436   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 77   Perte moyenne: 0.39145   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.53645   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 78   Perte moyenne: 0.39334   Exac: 517/625 (82.720%)\n",
      "Eval:  Perte moyenne: 0.53281   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 79   Perte moyenne: 0.39815   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.53625   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 80   Perte moyenne: 0.39783   Exac: 516/625 (82.560%)\n",
      "Eval:  Perte moyenne: 0.55439   Exac: 165/209 (78.947%)\n",
      "Époque d'entraînement: 81   Perte moyenne: 0.42876   Exac: 504/625 (80.640%)\n",
      "Eval:  Perte moyenne: 0.55882   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 82   Perte moyenne: 0.43476   Exac: 497/625 (79.520%)\n",
      "Eval:  Perte moyenne: 0.53700   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 83   Perte moyenne: 0.40508   Exac: 512/625 (81.920%)\n",
      "Eval:  Perte moyenne: 0.54264   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 84   Perte moyenne: 0.40325   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.54721   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 85   Perte moyenne: 0.40475   Exac: 513/625 (82.080%)\n",
      "Eval:  Perte moyenne: 0.52622   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 86   Perte moyenne: 0.39416   Exac: 518/625 (82.880%)\n",
      "Eval:  Perte moyenne: 0.53282   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 87   Perte moyenne: 0.39871   Exac: 516/625 (82.560%)\n",
      "Eval:  Perte moyenne: 0.51514   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 88   Perte moyenne: 0.39338   Exac: 513/625 (82.080%)\n",
      "Eval:  Perte moyenne: 0.53511   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 89   Perte moyenne: 0.38846   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.52646   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 90   Perte moyenne: 0.38506   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.53982   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 91   Perte moyenne: 0.39396   Exac: 514/625 (82.240%)\n",
      "Eval:  Perte moyenne: 0.53156   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 92   Perte moyenne: 0.39150   Exac: 511/625 (81.760%)\n",
      "Eval:  Perte moyenne: 0.52424   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 93   Perte moyenne: 0.38880   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.53259   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 94   Perte moyenne: 0.38527   Exac: 516/625 (82.560%)\n",
      "Eval:  Perte moyenne: 0.54343   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 95   Perte moyenne: 0.38233   Exac: 521/625 (83.360%)\n",
      "Eval:  Perte moyenne: 0.55508   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 96   Perte moyenne: 0.38985   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.52917   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 97   Perte moyenne: 0.38830   Exac: 517/625 (82.720%)\n",
      "Eval:  Perte moyenne: 0.54741   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 98   Perte moyenne: 0.38575   Exac: 517/625 (82.720%)\n",
      "Eval:  Perte moyenne: 0.53059   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 99   Perte moyenne: 0.38476   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.54084   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 100   Perte moyenne: 0.38348   Exac: 521/625 (83.360%)\n",
      "Eval:  Perte moyenne: 0.55011   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 101   Perte moyenne: 0.39069   Exac: 514/625 (82.240%)\n",
      "Eval:  Perte moyenne: 0.54557   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 102   Perte moyenne: 0.38530   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.55731   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 103   Perte moyenne: 0.38386   Exac: 514/625 (82.240%)\n",
      "Eval:  Perte moyenne: 0.55117   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 104   Perte moyenne: 0.38128   Exac: 518/625 (82.880%)\n",
      "Eval:  Perte moyenne: 0.53140   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 105   Perte moyenne: 0.39057   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.52422   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 106   Perte moyenne: 0.38181   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.54568   Exac: 174/209 (83.254%)\n",
      "Époque d'entraînement: 107   Perte moyenne: 0.37953   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.55121   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 108   Perte moyenne: 0.37725   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.55389   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 109   Perte moyenne: 0.37980   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.54617   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 110   Perte moyenne: 0.38019   Exac: 517/625 (82.720%)\n",
      "Eval:  Perte moyenne: 0.55920   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 111   Perte moyenne: 0.37404   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.54398   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 112   Perte moyenne: 0.38093   Exac: 521/625 (83.360%)\n",
      "Eval:  Perte moyenne: 0.55697   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 113   Perte moyenne: 0.37959   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.55691   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 114   Perte moyenne: 0.38245   Exac: 523/625 (83.680%)\n",
      "Eval:  Perte moyenne: 0.55407   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 115   Perte moyenne: 0.38065   Exac: 523/625 (83.680%)\n",
      "Eval:  Perte moyenne: 0.55903   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 116   Perte moyenne: 0.37243   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.57284   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 117   Perte moyenne: 0.37707   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.58426   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 118   Perte moyenne: 0.37513   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.55882   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 119   Perte moyenne: 0.37400   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.58551   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 120   Perte moyenne: 0.39284   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.58440   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 121   Perte moyenne: 0.39802   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.57077   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 122   Perte moyenne: 0.37712   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.57876   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 123   Perte moyenne: 0.37784   Exac: 528/625 (84.480%)\n",
      "Eval:  Perte moyenne: 0.56752   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 124   Perte moyenne: 0.37189   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.58487   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 125   Perte moyenne: 0.37070   Exac: 530/625 (84.800%)\n",
      "Eval:  Perte moyenne: 0.54698   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 126   Perte moyenne: 0.37901   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.58905   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 127   Perte moyenne: 0.37216   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.55117   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 128   Perte moyenne: 0.37411   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.58049   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 129   Perte moyenne: 0.37149   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.57903   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 130   Perte moyenne: 0.37098   Exac: 528/625 (84.480%)\n",
      "Eval:  Perte moyenne: 0.59163   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 131   Perte moyenne: 0.38007   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.58830   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 132   Perte moyenne: 0.37207   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.56079   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 133   Perte moyenne: 0.38987   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.58726   Exac: 175/209 (83.732%)\n",
      "Époque d'entraînement: 134   Perte moyenne: 0.37068   Exac: 518/625 (82.880%)\n",
      "Eval:  Perte moyenne: 0.57925   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 135   Perte moyenne: 0.37191   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.58491   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 136   Perte moyenne: 0.37213   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.57920   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 137   Perte moyenne: 0.37479   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.60298   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 138   Perte moyenne: 0.36875   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.56671   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 139   Perte moyenne: 0.37568   Exac: 520/625 (83.200%)\n",
      "Eval:  Perte moyenne: 0.60353   Exac: 174/209 (83.254%)\n",
      "Époque d'entraînement: 140   Perte moyenne: 0.39557   Exac: 519/625 (83.040%)\n",
      "Eval:  Perte moyenne: 0.57456   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 141   Perte moyenne: 0.37618   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.58931   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 142   Perte moyenne: 0.37337   Exac: 523/625 (83.680%)\n",
      "Eval:  Perte moyenne: 0.56702   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 143   Perte moyenne: 0.36795   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.57470   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 144   Perte moyenne: 0.36902   Exac: 532/625 (85.120%)\n",
      "Eval:  Perte moyenne: 0.58266   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 145   Perte moyenne: 0.36944   Exac: 526/625 (84.160%)\n",
      "Eval:  Perte moyenne: 0.59510   Exac: 167/209 (79.904%)\n",
      "Époque d'entraînement: 146   Perte moyenne: 0.37183   Exac: 522/625 (83.520%)\n",
      "Eval:  Perte moyenne: 0.59384   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 147   Perte moyenne: 0.36679   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.59910   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 148   Perte moyenne: 0.36909   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.58857   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 149   Perte moyenne: 0.36735   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.60124   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 150   Perte moyenne: 0.36595   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.59212   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 151   Perte moyenne: 0.36658   Exac: 530/625 (84.800%)\n",
      "Eval:  Perte moyenne: 0.57765   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 152   Perte moyenne: 0.36406   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.61539   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 153   Perte moyenne: 0.36377   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.57781   Exac: 174/209 (83.254%)\n",
      "Époque d'entraînement: 154   Perte moyenne: 0.35754   Exac: 533/625 (85.280%)\n",
      "Eval:  Perte moyenne: 0.62580   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 155   Perte moyenne: 0.37638   Exac: 528/625 (84.480%)\n",
      "Eval:  Perte moyenne: 0.65680   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 156   Perte moyenne: 0.38740   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.60651   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 157   Perte moyenne: 0.36717   Exac: 523/625 (83.680%)\n",
      "Eval:  Perte moyenne: 0.62615   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 158   Perte moyenne: 0.36532   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.56922   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 159   Perte moyenne: 0.36538   Exac: 518/625 (82.880%)\n",
      "Eval:  Perte moyenne: 0.59799   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 160   Perte moyenne: 0.37126   Exac: 518/625 (82.880%)\n",
      "Eval:  Perte moyenne: 0.60070   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 161   Perte moyenne: 0.36846   Exac: 523/625 (83.680%)\n",
      "Eval:  Perte moyenne: 0.61783   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 162   Perte moyenne: 0.36910   Exac: 528/625 (84.480%)\n",
      "Eval:  Perte moyenne: 0.57509   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 163   Perte moyenne: 0.36566   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.58777   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 164   Perte moyenne: 0.36287   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.64361   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 165   Perte moyenne: 0.38015   Exac: 515/625 (82.400%)\n",
      "Eval:  Perte moyenne: 0.61008   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 166   Perte moyenne: 0.36384   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.60025   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 167   Perte moyenne: 0.36353   Exac: 528/625 (84.480%)\n",
      "Eval:  Perte moyenne: 0.61918   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 168   Perte moyenne: 0.35849   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.62625   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 169   Perte moyenne: 0.36186   Exac: 526/625 (84.160%)\n",
      "Eval:  Perte moyenne: 0.60303   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 170   Perte moyenne: 0.37087   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.60207   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 171   Perte moyenne: 0.36295   Exac: 523/625 (83.680%)\n",
      "Eval:  Perte moyenne: 0.57974   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 172   Perte moyenne: 0.36285   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.62233   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 173   Perte moyenne: 0.35624   Exac: 530/625 (84.800%)\n",
      "Eval:  Perte moyenne: 0.58499   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 174   Perte moyenne: 0.35677   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.62142   Exac: 174/209 (83.254%)\n",
      "Époque d'entraînement: 175   Perte moyenne: 0.36560   Exac: 530/625 (84.800%)\n",
      "Eval:  Perte moyenne: 0.61107   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 176   Perte moyenne: 0.35917   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.62744   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 177   Perte moyenne: 0.35540   Exac: 532/625 (85.120%)\n",
      "Eval:  Perte moyenne: 0.59999   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 178   Perte moyenne: 0.35736   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.61432   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 179   Perte moyenne: 0.35977   Exac: 530/625 (84.800%)\n",
      "Eval:  Perte moyenne: 0.63158   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 180   Perte moyenne: 0.35196   Exac: 531/625 (84.960%)\n",
      "Eval:  Perte moyenne: 0.62966   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 181   Perte moyenne: 0.35920   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.62455   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 182   Perte moyenne: 0.35606   Exac: 532/625 (85.120%)\n",
      "Eval:  Perte moyenne: 0.60746   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 183   Perte moyenne: 0.35499   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.61403   Exac: 170/209 (81.340%)\n",
      "Époque d'entraînement: 184   Perte moyenne: 0.35468   Exac: 532/625 (85.120%)\n",
      "Eval:  Perte moyenne: 0.59984   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 185   Perte moyenne: 0.35638   Exac: 530/625 (84.800%)\n",
      "Eval:  Perte moyenne: 0.65437   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 186   Perte moyenne: 0.35103   Exac: 531/625 (84.960%)\n",
      "Eval:  Perte moyenne: 0.64567   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 187   Perte moyenne: 0.36452   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.64006   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 188   Perte moyenne: 0.35943   Exac: 532/625 (85.120%)\n",
      "Eval:  Perte moyenne: 0.61513   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 189   Perte moyenne: 0.36313   Exac: 526/625 (84.160%)\n",
      "Eval:  Perte moyenne: 0.64500   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 190   Perte moyenne: 0.35237   Exac: 532/625 (85.120%)\n",
      "Eval:  Perte moyenne: 0.63239   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 191   Perte moyenne: 0.35721   Exac: 526/625 (84.160%)\n",
      "Eval:  Perte moyenne: 0.65140   Exac: 172/209 (82.297%)\n",
      "Époque d'entraînement: 192   Perte moyenne: 0.35550   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.63104   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 193   Perte moyenne: 0.35371   Exac: 533/625 (85.280%)\n",
      "Eval:  Perte moyenne: 0.62307   Exac: 173/209 (82.775%)\n",
      "Époque d'entraînement: 194   Perte moyenne: 0.35159   Exac: 531/625 (84.960%)\n",
      "Eval:  Perte moyenne: 0.61827   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 195   Perte moyenne: 0.39451   Exac: 521/625 (83.360%)\n",
      "Eval:  Perte moyenne: 0.67327   Exac: 166/209 (79.426%)\n",
      "Époque d'entraînement: 196   Perte moyenne: 0.38654   Exac: 524/625 (83.840%)\n",
      "Eval:  Perte moyenne: 0.70690   Exac: 168/209 (80.383%)\n",
      "Époque d'entraînement: 197   Perte moyenne: 0.35953   Exac: 527/625 (84.320%)\n",
      "Eval:  Perte moyenne: 0.65103   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 198   Perte moyenne: 0.35620   Exac: 525/625 (84.000%)\n",
      "Eval:  Perte moyenne: 0.64331   Exac: 171/209 (81.818%)\n",
      "Époque d'entraînement: 199   Perte moyenne: 0.35209   Exac: 533/625 (85.280%)\n",
      "Eval:  Perte moyenne: 0.65693   Exac: 169/209 (80.861%)\n",
      "Époque d'entraînement: 200   Perte moyenne: 0.35662   Exac: 529/625 (84.640%)\n",
      "Eval:  Perte moyenne: 0.66904   Exac: 170/209 (81.340%)\n",
      "\n",
      "\n",
      "\n",
      "Optimisation finie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Maximum d'époques\n",
    "numEpochs = 200\n",
    "\n",
    "# Fréquence de sauvegarde\n",
    "checkpoint_freq = 10\n",
    "\n",
    "# Répertoire pour la sauvegarde des données\n",
    "path = './'\n",
    "\n",
    "# Accumulateurs de coûts moyens obtenus par époque\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Accumulateurs de performance par époque\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Définition du modèle\n",
    "neural_net = NeuralNet()\n",
    "\n",
    "# Charger le modèle sur l'appareil choisi\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "# Définition de l'optimiseur\n",
    "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
    "# optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n",
    "\n",
    "\n",
    "# Boucle d'apprentissage\n",
    "for epoch in range(1, numEpochs + 1):\n",
    "    \n",
    "    # entraîner le modèle avec l'ensemble des données d'entraînement\n",
    "    train_loss, train_acc = train(epoch, neural_net, train_loader, optimizer, device)   \n",
    "    \n",
    "    # évaluer le modèle avec l'ensemble des données de validation\n",
    "    val_loss, val_acc = evaluate(neural_net, val_loader, device)       \n",
    "    \n",
    "    # Sauvegarder les coûts obtenus\n",
    "    train_losses.append(train_loss)    \n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Sauvegarder les performances\n",
    "    train_accuracies.append(train_acc)    \n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Point de contrôle\n",
    "    if epoch % checkpoint_freq ==0:\n",
    "        save_model(epoch, neural_net, path)\n",
    "\n",
    "# Sauvegarder le modèle à la fin de l'entraînement\n",
    "save_model(numEpochs, neural_net, path)\n",
    "    \n",
    "print(\"\\n\\n\\nOptimisation finie.\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86OZRLrjavmd",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Interpréter la sortie du réseau de neurones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mklvQruYavme",
    "outputId": "193eeca0-db5e-477b-818d-7b5e6d883848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9435, 0.0565],\n",
      "        [0.6777, 0.3223],\n",
      "        [0.5894, 0.4106],\n",
      "        [0.5691, 0.4309],\n",
      "        [0.8601, 0.1399],\n",
      "        [0.9518, 0.0482],\n",
      "        [0.8308, 0.1692],\n",
      "        [0.8338, 0.1662],\n",
      "        [0.0085, 0.9915],\n",
      "        [0.0123, 0.9877]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Activer le mode d'évaluation\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Sélectionner les 10 premiers points de données de l'ensemble de validation\n",
    "data, target = val_dataset[0:10]\n",
    "data = data.to(device)\n",
    "\n",
    "# Exécution du réseau de neurones\n",
    "output = neural_net(data)   # équivalent à neural_net.forward(data)\n",
    "\n",
    "# Transformer la sortie en une distribution de probabilité avec une fonction softmax\n",
    "output_proba = F.softmax(output, dim=1)\n",
    "\n",
    "# Imprimer la probabilité\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "RvIEqKt0qjeT",
    "outputId": "f1c4e779-e9e1-4873-be1e-1366fb515836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions du modèle\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "Cibles\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Pour chaque exemple, récupérez la classe avec la plus grande probabilité.\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print(\"Prédictions du modèle\")\n",
    "print(prediction)\n",
    "\n",
    "print(\"Cibles\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V11J3Jihavmy",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualisation de la courbe d'apprentissage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9_9C_tXavmz",
    "lines_to_next_cell": 0
   },
   "source": [
    "La visualisation de la courbe d'apprentissage permet de détecter des problèmes potentiels qui se sont produits pendant l'apprentissage, par exemple, du surapprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "iNcbpl0tavm0",
    "outputId": "fa201aa2-5e25-4701-c0a9-33415773d68b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = list(range(len(train_losses)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_losses, 'r', label=\"Entraînement\")\n",
    "plt.plot(x, val_losses, 'g', label=\"Validation\")\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte entropie croisée')\n",
    "plt.grid()\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "g-VGQ2pMavm4",
    "outputId": "267e91d4-48e3-413d-e2e2-0feac7335035"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(len(train_accuracies)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_accuracies, 'r', label=\"Entraînement\")\n",
    "plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Exactitude')\n",
    "plt.grid()\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oktkpkuqjet",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "* Qu'observez-vous dans les graphiques précédents ?\n",
    "* À quelle époque est-il intéressant d'extraire les paramètres du modèle pour l'inférence ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwhRt39yzug-",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Réponses possibles:**\n",
    "\n",
    "* Le modèle apprend puisque la perte d'entraînement diminue. Cependant, nous pouvons observer en comparant les deux courbes de perte ( entraînement et validation) que le modèle commence à surapprendre à l'époque 25 par rapport à l'entropie croisée. Néanmoins, l'exactitude continue à augmenter jusqu'à l'époque 100.\n",
    "* Autour de l'époque 125 où l'exactitude sur l'ensemble de validation est maximale. La mesure de performance est plus importante que la perte car c'est la mesure utilisée pour déterminer le meilleur modèle (c'est-à-dire la sélection du modèle). La perte d'entraînement n'est qu'un substitut nécessaire pour générer la rétroaction pour un modèle particulier. Un autre modèle pourrait utiliser une autre fonction de perte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XK_eUsq3avm8",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment évaluer un modèle sur l'ensemble d’évaluation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UREO5elavm8",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous pouvons enfin évaluer notre modèle sur notre ensemble de données d'évaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pPWvDM-qavm8",
    "outputId": "b39e294a-47fb-401a-ffa4-5d2a407f0980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval:  Perte moyenne: 0.53942   Exac: 164/209 (78.469%)\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(neural_net, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvP_-KUwqjez",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "A) Comparer les métriques de validation et d’évaluation. <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov4CKUFh5tun",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Réponse possible** : On observe un écart entre les deux mesures (validation : 81,8%, évaluation: 78,5%). Nous expliquons cette différence par le petit nombre d'exemples utilisés dans les deux ensembles (~ 209 exemples). Cela signifie que nos estimations actuelles peuvent présenter une variance de quelques pourcents. Pour l'évaluer plus précisément, nous pourrions utiliser une validation croisée k-fois.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "id,colab_type,outputId,colab,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
