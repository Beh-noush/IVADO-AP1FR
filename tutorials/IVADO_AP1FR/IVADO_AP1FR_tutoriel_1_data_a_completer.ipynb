{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IVADO AP1FR tutoriel 1 data - exercise",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCQs5y60YyRv",
        "colab_type": "text"
      },
      "source": [
        "# IVADO/Mila École d'apprentissage profond\n",
        "# 4e édition (automne 2019)\n",
        "# Tutoriel: Data\n",
        "\n",
        "## Auteurs: \n",
        "\n",
        "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
        "\n",
        "Francis Grégoire <francis.gregoire@mila.quebec>\n",
        "\n",
        "## Traducteur:\n",
        "\n",
        "Andrew Williams <andrew.williams@umontreal.ca>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fsFqgdJZ2Mh",
        "colab_type": "text"
      },
      "source": [
        "# Préface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGZRSQojc5zc",
        "colab_type": "text"
      },
      "source": [
        "L'objectif de ce tutoriel est de souligner l'importance de comprendre les données sur lesquelles un projet d'apprentissage automatique (AA) est défini. Cette compréhension vous aidera à envisager les actions utiles à réaliser avant d'entraîner vos modèles d'apprentissage automatique. Ce tutoriel sert d'introduction douce à l'exploration des données et couvre les choses de base que tout praticien de l'apprentissage automatique devrait savoir.\n",
        "\n",
        "**Note: le but de ce tutoriel est d'être une introduction. Ainsi, nous proposons des solutions simples à nos exercices. En pratique, vous devriez utiliser des techniques plus avancées pour entraîner vos modèles.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn7fGc3PgWUy",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8dhsflQg4MB",
        "colab_type": "text"
      },
      "source": [
        "Dans ce tutoriel, nous utiliserons l'ensemble de données [CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10). Il s'agit d'une collection d'images en couleurs 32 x 32 réparties dans 10 classes différentes. Les 10 classes (indexées) différentes sont les suivantes :\n",
        "0. avion ;\n",
        "1. automobile ;\n",
        "2. oiseau ;\n",
        "3. chat ;\n",
        "4. cerf ;\n",
        "5. chien ;\n",
        "6. grenouille ;\n",
        "7. cheval ;\n",
        "8. bateau ;\n",
        "9. camion.\n",
        "\n",
        "La tâche qui nous intéresse dans ce tutoriel est une tâche de classification d'images. C'est-à-dire que nous sommes intéressés à trouver, pour une image donnée, la classe à laquelle elle appartient. Nous utiliserons [PyTorch](https://pytorch.org/) comme cadre d'apprentissage automatique.\n",
        "\n",
        "À ce stade, toutes les fonctions et les méthodes PyTorch connexes seront fournies et utilisées telles quelles. Ceci est parce que ce tutoriel n'est pas conçu pour apprendre PyTorch, mais plutôt pour se concentrer sur la compréhension des données et des concepts de base de l'apprentissage automatique. Dans les tutoriels suivants, vous apprendrez comment développer, entraîner et évaluer des modèles sur différents types de données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUgpszup1kCy",
        "colab_type": "text"
      },
      "source": [
        "# Téléchargement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjpnx7t81vKD",
        "colab_type": "text"
      },
      "source": [
        "Dans cette section, nous fournissons une fonction permettant de télécharger l'ensemble de données CIFAR-10. Elle prend en entrée deux arguments :\n",
        "- **path** : répertoire dans lequel l'ensemble de données téléchargées sera sauvegardé.\n",
        "- **train_flag** : indicateur booléen précisant s'il faut télécharger les données de l'ensemble d'entraînement (`train_flag=True`) ou de l'ensemble d'évaluation (`train_flag=False`).\n",
        "\n",
        "Il retourne deux éléments:\n",
        "- **imgs** : tableau numpy représentant les images téléchargées de taille N x 32 x 32 x 3 où N est le nombre d'images.\n",
        "- **labels** : liste de N classes (indexées), chacune étant associée à une seule image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KctjRqgm2Fze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "\n",
        "def download_CIFAR10(path, train_flag):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     path: directory where the dowloaded dataset will be saved.\n",
        "     train_flag: if `True`, download data from training set, otherwise\n",
        "        download from test set.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of two elements (imgs, labels) where\n",
        "        imgs: a numpy array of shape N x 32 x 32 x 3 where N is the number of images.\n",
        "        labels: list of N (indexed-)classes, each one associated with a single image.\n",
        "  \n",
        "  \"\"\"\n",
        "  dataset = torchvision.datasets.CIFAR10(\n",
        "      root=path, train=train_flag, download=True\n",
        "  )\n",
        "  imgs, labels = dataset.data, dataset.targets\n",
        "  return imgs, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRY0tkh79h48",
        "colab_type": "text"
      },
      "source": [
        "## Exercice\n",
        "\n",
        "Téléchargez l'ensemble de données d'entraînement de CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30NO1znU3eDK",
        "colab_type": "code",
        "outputId": "17ddefc8-9e76-43a6-ba98-d949dc9d76b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "imgs, labels = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E9RrkHB3-anO"
      },
      "source": [
        "## Exercice\n",
        "\n",
        "Téléchargez l'ensemble de données d'évaluation de CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPQBZhzl3qZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs, test_labels = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nbcM9SC-8MX",
        "colab_type": "text"
      },
      "source": [
        "# ensemble de données de validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY2fanet_dMf",
        "colab_type": "text"
      },
      "source": [
        "Dans la section précédente, des fonctions ont été fournies pour télécharger les ensembles de données **d'entraînement** et **de d'évaluation**. Comme vous l'avez peut-être appris dans cette école, nous avons normalement besoin de trois ensembles de données dans un projet d'apprentissage automatique, à savoir les ensembles d'entraînement, de **validation** et d'évaluation. Malheureusement, l'ensemble de données CIFAR-10 ne contient pas d'ensemble de données de validation prétraitées natif, nous devons donc en **créer** un par échantillonnage à partir de l'ensemble de données **d'entraînement**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLxTIkNeCHA3",
        "colab_type": "text"
      },
      "source": [
        "Dans cette section, nous fournissons une fonction permettant de créer un ensemble de données de validation à partir de l'ensemble de données d'entraînement original. Elle prend en entrée cinq arguments :\n",
        "- **imgs** : tableau numpy représentant l'ensemble d'images à partir duquel le partitionnement est effectué.\n",
        "- **labels** : étiquettes associées à l'ensemble d'images fourni.\n",
        "- **valid_ratio** (facultatif) : partie des données qui seront utilisées pour l'ensemble de validation. Valeur par défaut : `0.1`.\n",
        "- **shuffle** ( facultatif ) : si les données doivent être mélangées ou non avant que le partitionnement ne soit effectué. Valeur par défaut : \"True\".\n",
        "- **seed** ( facultatif ) : graine du générateur aléatoire. Valeur par défaut : `1234`.\n",
        "\n",
        "Il fournit en sortie 4 éléments, qui sont :\n",
        "- **train_imgs** : tableau numpy représentant les images de l'ensemble d'entraînement après que le partitionnement soit fait.\n",
        "- **train_labels** : étiquettes associées aux images de l'ensemble d'entraînement.\n",
        "- **valid_imgs** : tableau numpy représentant les images de l'ensemble de validation après que le partitionnement soit fait.\n",
        "- **valid_labels** : étiquettes associées aux images de l'ensemble de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_LYjCXrEql1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def partition_dataset(imgs, labels, valid_ratio=0.1, shuffle=True, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     imgs: numpy array representing the image set from which \n",
        "        the partitioning is made.\n",
        "     labels: the labels associated with the provided images.\n",
        "     valid_ratio (optional): the portion of the data that will be used in\n",
        "        the validation set. Default: 0.1.\n",
        "     shuffle (optional): whether or not to shuffle the data. Default: True.\n",
        "     seed (optional): the seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of 4 elements (train_imgs, train_labels, valid_imgs, valid_labels)\n",
        "     where:\n",
        "        train_imgs: a numpy array of images for the training set.\n",
        "        train_labels: labels associated with the images in the training set.\n",
        "        valid_imgs: a numpy array of images for the validation set.\n",
        "        valid_labels: labels associated with the images in the validation set.\n",
        "  \n",
        "  \"\"\"\n",
        "  if shuffle:\n",
        "    np.random.seed(seed)  # Set the random seed of numpy.\n",
        "    indices = np.random.permutation(imgs.shape[0])\n",
        "  else:\n",
        "    indices = np.arange(imgs.shape[0])\n",
        "  \n",
        "  train_idx, valid_idx = np.split(\n",
        "      indices, \n",
        "      [int((1.0 - valid_ratio)*len(indices))]\n",
        "  )\n",
        "  train_imgs, valid_imgs = imgs[train_idx], imgs[valid_idx]\n",
        "  tgt = np.array(labels)\n",
        "  train_labels, valid_labels = tgt[train_idx].tolist(), tgt[valid_idx].tolist()\n",
        "  return train_imgs, train_labels, valid_imgs, valid_labels\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uZ-K7scKNWo0"
      },
      "source": [
        "## Exercice\n",
        "\n",
        "En utilisant les paramètres par défaut, générer les ensembles de données d'entraînement et de validation sur mesure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYhh6Cb9ILc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "47f5194a-2e3e-438f-f5c2-22e947617545"
      },
      "source": [
        "train_imgs, train_labels, valid_imgs, valid_labels = ... # à compléter.\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-31531a750daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# à compléter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d3B5YMVNucn",
        "colab_type": "text"
      },
      "source": [
        "# Visualisation de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgUkFNKcPS8I",
        "colab_type": "text"
      },
      "source": [
        "C'est toujours une bonne pratique de visualiser les données avec lesquelles nous travaillons. En particulier, la visualisation de la distribution des données fournira des indications précieuses sur les données en question.\n",
        "\n",
        "Dans cette section, nous fournissons quelques fonctions permettant de visualiser les données d'images et de calculer la distribution des étiquettes au sein d'un ensemble de données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac8QuRoHhGql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "  \"\"\"\n",
        "  Plot a single image.\n",
        "  \n",
        "  Args:\n",
        "     image: image to be plotted.\n",
        "     \n",
        "  \"\"\"\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "def plot_random_images_from_dataset(images, n):  \n",
        "  \"\"\"\n",
        "  Randomly sample n images from an image set and plot them in a grid.\n",
        "  \n",
        "  Args:\n",
        "     images: collection of images from which sampling will be made.\n",
        "     n: the number of images to be sampled.\n",
        "     \n",
        "  \"\"\"\n",
        "  sampled_indices = np.random.choice(images.shape[0], n, False)\n",
        "  sampled_images = images[sampled_indices]\n",
        "  \n",
        "  sampled_images = np.transpose(sampled_images, (0, 3, 1, 2))\n",
        "  sampled_tensor = torch.Tensor(sampled_images)\n",
        "  \n",
        "  grid_tensor = torchvision.utils.make_grid(\n",
        "      sampled_tensor, normalize=True, range=(0, 255)\n",
        "  )\n",
        "  grid_tensor = np.transpose(grid_tensor.numpy(), (1, 2, 0))\n",
        "  \n",
        "  plot_image(grid_tensor)\n",
        "  \n",
        "  \n",
        "def plot_dataset_histogram(labels, title='Label distribution'):\n",
        "  \"\"\"\n",
        "  Plot the histogram/distribution of the labels within a dataset.\n",
        "  \n",
        "  Args:\n",
        "     labels: collection of labels from which the distribution is computed.\n",
        "     \n",
        "  \"\"\"\n",
        "  _ = plt.hist(labels, bins=np.arange(11)-0.5, rwidth=0.85)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Label')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.xticks(np.arange(10))\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kVKSaRGphrBS"
      },
      "source": [
        "## Exercice\n",
        "\n",
        "Utilisez les fonctions définies précédemment pour visualiser des échantillons provenant d'ensembles de données d'entraînement et de validation. Calculez également la distribution des étiquettes dans ces deux ensembles de données. Quelles conclusions pouvez-vous en tirer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cHN_c43Uu6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tracer un échantillon donné à partir de l'ensemble des données d'entraînement et récupérer son étiquette\n",
        "... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVSI7FQozT7Y",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Y3if2UaZxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tracer des échantillons aléatoires (par exemple, 16) à partir de l'ensemble des données d'entraînement\n",
        "... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4MtyWh_0hPl",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZJ_maHlITUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tracer la distribution des étiquettes de l'ensemble des données d'entraînement\n",
        "... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whIHwKKB2FW_",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Ygn8fsjXho",
        "colab_type": "text"
      },
      "source": [
        "# Mélanger les données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWmG02g-GrZF",
        "colab_type": "text"
      },
      "source": [
        "Lorsque vous créez vos propres ensembles d'entraînement, de validation et d'évaluation, il est essentiel de **mélanger** l'ensemble de données d'origine pour répartir les données entre les ensembles d'entraînement, de validation et d'évaluation afin de s'assurer qu'elles sont plus représentatives de la **distribution globale des données**. Le brassage de votre ensemble de données réduira également les biais si vos données proviennent de sources différentes.\n",
        "\n",
        "Les ensembles de données CIFAR-10 téléchargés au début de ce tutoriel ont déjà été mélangés. Pour visualiser l'efficacité du brassage, supposons que vous receviez un ensemble de données et qu'après la division, vous observiez les distributions d'étiquettes suivantes.\n",
        "\n",
        "Quelles seront les conséquences de l'utilisation de ce fractionnement sur vos mesures de performance ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqPnb5avjXzA",
        "colab_type": "code",
        "outputId": "4f619282-b862-493f-a2b2-caf0d2eb2ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "sorted_idx = np.argsort(labels)\n",
        "sorted_imgs = imgs[sorted_idx]\n",
        "sorted_labels = [labels[i] for i in sorted_idx]\n",
        "\n",
        "_, sorted_train_labels, _, sorted_valid_labels = partition_dataset(sorted_imgs, sorted_labels,\n",
        "                                                                   valid_ratio=0.5, shuffle=False)\n",
        "plot_dataset_histogram(sorted_train_labels, 'Train set label distribution')\n",
        "plot_dataset_histogram(sorted_valid_labels, 'Valid set label distribution')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2b07d26c4ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msorted_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msorted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m _, sorted_train_labels, _, sorted_valid_labels = partition_dataset(sorted_imgs, sorted_labels,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N75a0RHI3OkF",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES-dzdF8jfaW",
        "colab_type": "text"
      },
      "source": [
        "Ci-dessous, nous mélangeons les données et observons que les étiquettes sont uniformément réparties dans les ensembles d'entraînement/validation, ce qui est une propriété nécessaire pour effectuer un réglage précis sur un ensemble de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwcyQ7zJja0x",
        "colab_type": "code",
        "outputId": "fede2a2c-d189-44e7-8279-09d374ab8170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "_, shuffled_train_labels, _, shuffled_valid_labels = partition_dataset(\n",
        "    sorted_imgs, sorted_labels, valid_ratio=0.5, shuffle=True\n",
        ")\n",
        "\n",
        "plot_dataset_histogram(shuffled_train_labels, 'Train set label distribution')\n",
        "plot_dataset_histogram(shuffled_valid_labels, 'Valid set label distribution')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-50ccd40c5a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m _, shuffled_train_labels, _, shuffled_valid_labels = partition_dataset(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msorted_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_dataset_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train set label distribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sorted_imgs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU25Ban6jiWe",
        "colab_type": "text"
      },
      "source": [
        "# Lecteurs de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D0nw531G1wn",
        "colab_type": "text"
      },
      "source": [
        "Comme vous le verrez dans les prochains tutoriels, pour entraîner et évaluer les modèles d'apprentissage automatique, nous utilisons des **lecteurs de données**. Comme l'apprentissage automatique nécessite une utilisation intensive de la transformation des données, nous voulons des outils qui **transforment**, **mélangent** et **partitionnent** efficacement nos ensembles de données avec la possibilité d'utiliser des travailleurs multiprocesseurs. Un lecteur de données est un itérateur de données optimisé qui offre toutes ces fonctionnalités.\n",
        "\n",
        "Il y a quelques années, pour entraîner un modèle d'apprentissage profond sur une tâche donnée, nous avions besoin de coder notre propre lecteur de données. Heureusement, les cadres modernes d'apprentissage profond, tels que PyTorch et TensorFlow, ont introduit des lecteurs de données très efficaces dans leurs dernières versions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK1zZ2qanmol",
        "colab_type": "text"
      },
      "source": [
        "## Exercice\n",
        "Nous présentons un exemple simple de préparation d'un lecteur de données à l'aide d'un petit sous-ensemble de notre ensemble d'entraînement. Pendant l'entraînement, la meilleure pratique consiste à mélanger les données au début de chaque **époque** (chaque répétition sur un ensemble de données entier est généralement appelée une époque). Ainsi, nous définissons normalement \"shuffle=True\" pour l'entraînement et \"shuffle=False\" pour l'évaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOrqUB8Fjif-",
        "colab_type": "code",
        "outputId": "c39e9f23-0df9-419b-9ab4-0025ac7295fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def create_dataset(images, labels, n):\n",
        "  \"\"\"\n",
        "  Slice the first n images/labels and create a torch.utils.data.DataLoader.\n",
        "  \n",
        "  Args:\n",
        "     images: numpy array of images.\n",
        "     labels: list of labels associated with the images.\n",
        "     n: the number of images/labels to slice.\n",
        "        \n",
        "  Return:\n",
        "     A torch.utils.data.TensorDataset to be used with a torch.utils.data.DataLoader.\n",
        "     \n",
        "  \"\"\"\n",
        "  imgs = torch.tensor(images[:n], dtype=torch.float)\n",
        "  labels = torch.tensor(labels[:n], dtype=torch.long)\n",
        "  dataset = TensorDataset(imgs, labels)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "n = 100\n",
        "batch_size = 32\n",
        "train_dataset = create_dataset(train_imgs, train_labels, n)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch {}/{}:'.format(epoch+1, epochs))\n",
        "  for i, (x, y) in enumerate(train_dataloader):\n",
        "    print('   batch {}/{} of {} examples.'.format(i+1, int(np.ceil(n/batch_size)), y.size(0)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f77e7ddfd653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_imgs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7p5cEgevRLi",
        "colab_type": "text"
      },
      "source": [
        "Nous voyons que nous pouvons facilement itérer sur l'ensemble de données créé pour un certain nombre d'époques avec une simple boucle `for`. A chaque itération, le lecteur de données retourne un mini lot de paires d'étiquettes d'entrée `(x, y)` de taile `batch_size`.\n",
        "\n",
        "En réglant `drop_last=False`, le dernier lot incomplet est conservé si la taille de l'ensemble de données n'est pas divisible par `batch_size`. Lors de l'entraînement d'un modèle, pour calculer la perte, nous faisons normalement la moyenne des pertes des exemples d'un mini lot. Ainsi, en ayant un mini lot de 4 exemples au lieu de 32, les exemples du dernier mini lot ont plus d'importance que les autres exemples de l'ensemble de données. En pratique, cela n'est pas préjudiciable car les exemples sont mélangés au début d'une époque. Par conséquent, à chaque époque, nous devrions avoir des exemples différents dans le dernier mini lot. Plus de détails sur ce sujet seront fournis dans les prochains jours.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwpEr_1iers",
        "colab_type": "text"
      },
      "source": [
        "# Training with neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e32z51jvlgRJ",
        "colab_type": "text"
      },
      "source": [
        "Dans cette section, nous fournissons des méthodes basées sur les réseaux de neurones qui seront utilisées par la suite comme des boîtes noires à des fins d'entraînement et d'évaluation. Ne vous inquiétez pas, dans les prochains tutoriels, vous apprendrez comment écrire de tels morceaux de code.\n",
        "\n",
        "Deux méthodes seront utilisées de manière intensive dans les sections suivantes. \n",
        "\n",
        "La première est la `training_on_dataset`, qui consiste à entraîner un modèle sur un ensemble de données donné. Elle prend en entrée les arguments suivants et retourne un **modèle entraîné** :\n",
        "- **imgs** : images sur lesquelles le modèle sera entraîné.\n",
        "- **labels** : étiquettes associées aux images fournies.\n",
        "- **eval_imgs** : images pour évaluer le modèle.\n",
        "- **eval_labels** : étiquettes associées aux images utilisées pour évaluer le modèle.\n",
        "- **epochs** : nombre d'époques pendant l'entraînement (nombre de fois à boucler sur l'ensemble des images/étiquettes).\n",
        "- **batch_size** (facultatif) : taille d'un mini-batch. Par défaut : `8`.\n",
        "- **lr** ( facultatif ) : taux d'apprentissage. Valeur par défaut : `1e-3`.\n",
        "- **seed** ( facultatif) : graine du générateur aléatoire. Valeur par défaut : `1234`.\n",
        "- **transformations** ( facultatif ) : transformations à appliquer sur les images pendant le processus d'entraînement. Valeur par défaut : `None`.\n",
        "- **label_weights** ( facultatif ) : poids d'importance associés à chaque étiquette. Valeur par défaut : `None` (tous les étiquettes sont traitées de la même manière).\n",
        "- **metrics** (facultatif) : métriques à surveiller pendant l'entraînement. Valeur par défaut : `None`.\n",
        "\n",
        "\n",
        "Dans cette section, nous fournissons des méthodes basées sur les réseaux de neurones qui seront utilisées par la suite comme des boîtes noires à des fins d'entraînement et d'évaluation. Ne vous inquiétez pas, dans les prochains tutoriels, vous apprendrez comment écrire de tels morceaux de code.\n",
        "\n",
        "Deux méthodes seront utilisées de manière intensive dans les sections suivantes. \n",
        "\n",
        "La première est la `training_on_dataset`, qui consiste à entraîner un modèle sur un ensemble de données donné. Elle prend en entrée les arguments suivants et retourne un **modèle entraîné** :\n",
        "- **imgs** : images sur lesquelles le modèle sera entraîné.\n",
        "- **labels** : étiquettes associées aux images fournies.\n",
        "- **eval_imgs** : images pour évaluer le modèle.\n",
        "- **eval_labels** : étiquettes associées aux images utilisées pour évaluer le modèle.\n",
        "- **epochs** : nombre d'époques pendant l'entraînement (nombre de fois à boucler sur l'ensemble des images/étiquettes).\n",
        "- **batch_size** (facultatif) : taille d'un mini-batch. Par défaut : `8`.\n",
        "- **lr** ( facultatif ) : taux d'apprentissage. Valeur par défaut : `1e-3`.\n",
        "- **seed** ( facultatif) : graine du générateur aléatoire. Valeur par défaut : `1234`.\n",
        "- **transformations** ( facultatif ) : transformations à appliquer sur les images pendant le processus d'entraînement. Valeur par défaut : `None`.\n",
        "- **label_weights** ( facultatif ) : poids d'importance associés à chaque étiquette. Valeur par défaut : `None` (tous les étiquettes sont traitées de la même manière).\n",
        "- **metrics** (facultatif) : métriques à surveiller pendant l'entraînement. Valeur par défaut : `None`.\n",
        "\n",
        "\n",
        "La deuxième est `evaluate_classes`, qui évalue un modèle entraîné sur un ensemble de données donné. Elle prend en entrée les arguments suivants et retourne la **performance d'évaluation** :\n",
        "- **net** : le modèle entraîné à évaluer.\n",
        "- **imgs** : images sur lesquelles le modèle sera évalué.\n",
        "- **labels** : étiquettes de vérité fondamentale associées aux images fournies pour le calcul des performances.\n",
        "- **batch_size** ( facultatif ) : taille d'un mini-batch. Valeur par défaut : `8`.\n",
        "- **metrics** ( facultatif ) : mesures de performance à calculer. Valeur par défaut : `None`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWaFOMsdo4Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "classe_names = (\n",
        "    'plane', 'car', 'bird', 'cat', 'deer', \n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        ")\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Compute the accuracy score.\n",
        "  \n",
        "  Args:\n",
        "     y_true: ground truth labels.\n",
        "     y_pred: predicted labels by a classifier.\n",
        "     \n",
        "  Return:\n",
        "     Accuracy score.\n",
        "     \n",
        "  \"\"\"\n",
        "  return metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Compute the F1 score.\n",
        "  \n",
        "  Args:\n",
        "     y_true: ground truth labels.\n",
        "     y_pred: predicted labels by a classifier.\n",
        "     \n",
        "  Return:\n",
        "     F1 score.\n",
        "     \n",
        "  \"\"\"\n",
        "  return metrics.f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "\n",
        "def plot_metric(train_values, valid_values, name=''):\n",
        "  \"\"\"\n",
        "  Plot the values of a given metric on training and validation sets.\n",
        "  \n",
        "  Args:\n",
        "     train_values: values of the metric on the training set. \n",
        "     valid_values: values of the metric on the validation set.\n",
        "     name: name of the metric.\n",
        "  \"\"\"\n",
        "  x = range(len(train_values))\n",
        "  plt.plot(x, train_values, label='train')\n",
        "  plt.plot(x, valid_values, label='valid')\n",
        "  plt.title(name)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "class AugmentBasedDataset(Dataset):\n",
        "  \"\"\"Encapsulated dataset for data augmentation.\"\"\"\n",
        "\n",
        "  def __init__(self, dataset, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        dataset: dataset on which to perform data augmentation.\n",
        "        transform (callable, optional): optional transform to be applied\n",
        "            on a sample.\n",
        "\n",
        "    \"\"\"\n",
        "    self.dataset = dataset\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img, label = self.dataset[idx]\n",
        "    if self.transform:\n",
        "        img = self.transform(img)\n",
        "    return img, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKCGEYWIpW3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"Basic CNN used for image classification.\"\"\"\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm19z0tk1j8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_on_dataset(imgs, labels, eval_imgs, eval_labels,\n",
        "                        epochs, batch_size=8, lr=1e-3,\n",
        "                        seed=1234, transformations=None, label_weights=None,\n",
        "                        metrics=None, verbose=True):\n",
        "  \"\"\"Black box function to train a neural network on CIFAR-10 dataset.\"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  \n",
        "  # Train data.\n",
        "  train_imgs = ((imgs/255.0) - 0.5) * 2.0  # Normalize to [-1, 1].\n",
        "  train_imgs = np.transpose(train_imgs, (0, 3, 1, 2))\n",
        "  train_labels = np.array(labels)\n",
        "  \n",
        "  train_dataset = TensorDataset(\n",
        "      torch.from_numpy(train_imgs).float(), \n",
        "      torch.from_numpy(train_labels).long()\n",
        "  )\n",
        "  train_dataset = AugmentBasedDataset(train_dataset, transformations)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # Eval data.\n",
        "  eval_imgs = ((eval_imgs/255.0) - 0.5) * 2.0 # Normalize to [-1, 1]\n",
        "  eval_imgs = np.transpose(eval_imgs, (0, 3, 1, 2))\n",
        "  eval_labels = np.array(eval_labels)\n",
        "  \n",
        "  eval_dataset = TensorDataset(\n",
        "      torch.from_numpy(eval_imgs).float(), \n",
        "      torch.from_numpy(eval_labels).long()\n",
        "  )\n",
        "  eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  net = Net()\n",
        "  net = net.to(device)\n",
        "  if label_weights is not None:\n",
        "    label_weights = torch.tensor(label_weights).float()\n",
        "    label_weights = label_weights.to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weight=label_weights)\n",
        "  optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "  \n",
        "  train_loss_values = []\n",
        "  eval_loss_values = []\n",
        "  train_metric_values = None\n",
        "  eval_metric_values = None\n",
        "  \n",
        "  if metrics is not None:\n",
        "    if isinstance(metrics, dict):\n",
        "      train_metric_values = {metric: [] for metric in metrics.keys()}\n",
        "      eval_metric_values = {metric: [] for metric in metrics.keys()}\n",
        "    elif isinstance(metrics, (list, tuple)):\n",
        "      train_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "      eval_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "    else:\n",
        "      metrics = [metrics]\n",
        "      train_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "      eval_metric_values = {metric: [] for metric in range(len(metrics))}\n",
        "\n",
        "  for epoch in range(epochs):  # Loop over the dataset.\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    n_update = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data in train_dataloader:\n",
        "      # data is a tuple of (inputs, targets).\n",
        "      inputs, targets = data\n",
        "      \n",
        "      if targets.numel() > 1:\n",
        "        y_true.extend(targets.flatten().tolist())\n",
        "      else:\n",
        "        y_true.append(targets.flatten().tolist())\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)       \n",
        "\n",
        "      # Reset the parameter gradients.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward + backward + optimize.\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Predict label.\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      if predicted.numel() > 1:\n",
        "        y_pred.extend(predicted.flatten().tolist())\n",
        "      else:\n",
        "        y_pred.append(predicted.flatten().tolist())\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      n_update += 1\n",
        "\n",
        "    # Save and print statistics at the end of each training epoch.\n",
        "    train_loss = running_loss / n_update\n",
        "    train_loss_values.append(train_loss)\n",
        "    eval_loss, eval_true, eval_pred = evaluate_during_training(net, criterion, eval_dataloader)\n",
        "    eval_loss_values.append(eval_loss)\n",
        "    \n",
        "    if metrics is not None:\n",
        "      for metric in metrics.keys():\n",
        "        train_metric_values[metric].append(metrics[metric](y_true, y_pred))\n",
        "        eval_metric_values[metric].append(metrics[metric](eval_true, eval_pred))\n",
        "  \n",
        "    if verbose:\n",
        "      print('[Epoch {}/{}] Training loss: {:.3f} | Validation loss: {:.3f}' \n",
        "            .format(epoch + 1, epochs, train_loss, eval_loss)\n",
        "      )\n",
        "    running_loss = 0.0\n",
        "    n_update = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "  \n",
        "  if verbose:\n",
        "    plot_metric(train_loss_values, eval_loss_values, 'Loss')\n",
        "    if metrics is not None:\n",
        "      for metric in metrics.keys():\n",
        "        plot_metric(train_metric_values[metric], eval_metric_values[metric], metric)\n",
        "  \n",
        "  return net\n",
        "\n",
        "\n",
        "def evaluate_during_training(net, criterion, dataloader):\n",
        "  net.eval()\n",
        "  running_loss = 0.0\n",
        "  n_update = 0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  for data in dataloader:\n",
        "    inputs, targets = data\n",
        "    if targets.numel() > 1:\n",
        "      y_true.extend(targets.flatten().tolist())\n",
        "    else:\n",
        "      y_true.append(targets.flatten().tolist())\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device) \n",
        "    with torch.no_grad():\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)  \n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      if predicted.numel() > 1:\n",
        "        y_pred.extend(predicted.flatten().tolist())\n",
        "      else:\n",
        "        y_pred.append(predicted.flatten().tolist())\n",
        "      running_loss += loss.item()\n",
        "      n_update += 1\n",
        "  eval_loss = running_loss / n_update\n",
        "  return eval_loss, y_true, y_pred\n",
        "\n",
        "\n",
        "def evaluate_classes(net, imgs, labels, batch_size=8, metrics=None, verbose=True):\n",
        "  \"\"\"Black box function to evaluate a neural network on CIFAR-10 dataset.\"\"\"\n",
        "  normalized_imgs = ((imgs/255.0) - 0.5) * 2.0 # Normalize to [-1, 1]\n",
        "  normalized_imgs = np.transpose(normalized_imgs, (0, 3, 1, 2))\n",
        "  arr_labels = np.array(labels)\n",
        "  \n",
        "  dataset = TensorDataset(\n",
        "      torch.from_numpy(normalized_imgs).float(), \n",
        "      torch.from_numpy(arr_labels).long()\n",
        "  )\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "  \n",
        "  net = net.to(device)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  class_correct = [0.0] * 10\n",
        "  class_total = [0.0] * 10\n",
        "  class_acc = [0.0] * 10\n",
        "  \n",
        "  metric_values = None\n",
        "  if not (metrics is None):\n",
        "    if isinstance(metrics, dict):\n",
        "      metric_values = {a: 0.0 for a in metrics.keys()}\n",
        "    elif isinstance(metrics, (list, tuple)):\n",
        "      metric_values = {a: 0.0 for a in range(len(metrics))}\n",
        "    else:\n",
        "      metrics = [metrics]\n",
        "      metric_values = {a: 0.0 for a in range(len(metrics))}\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data in dataloader:\n",
        "      inputs, targets = data\n",
        "      \n",
        "      if targets.numel() > 1:\n",
        "        y_true.extend(targets.flatten().tolist())\n",
        "      else:\n",
        "        y_true.append(targets.flatten().tolist())\n",
        "        \n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      \n",
        "      if predicted.numel()>1:\n",
        "        y_pred.extend(predicted.flatten().tolist())\n",
        "      else:\n",
        "        y_pred.append(predicted.flatten().tolist())\n",
        "      \n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "      \n",
        "      c = (predicted == targets).squeeze()\n",
        "      for i in range(targets.size(0)):\n",
        "        label = targets[i]\n",
        "        class_correct[label] += c[i].item()\n",
        "        class_total[label] += 1\n",
        "            \n",
        "    if not (metric_values is None):\n",
        "      for a in metric_values.keys():\n",
        "        metric_values[a] = metrics[a](y_true, y_pred)\n",
        "            \n",
        "  global_acc = correct / max(total, 1.0)\n",
        "  \n",
        "  if verbose:\n",
        "    if metrics is not None:\n",
        "      print('Evaluation on the validation dataset:')\n",
        "      for a in metric_values.keys():\n",
        "        print('Metric {}: {:.0%}'.format(a, metric_values[a]))\n",
        "\n",
        "  for i in range(10):\n",
        "    class_acc[i] = class_correct[i] / max(class_total[i], 1.0)\n",
        "    if verbose:\n",
        "      print('Accuracy of {:<5s} ({}): {:.0%}'\n",
        "            .format(classe_names[i], i, class_acc[i])\n",
        "           )\n",
        "    \n",
        "  return global_acc, class_acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbYLAX2Ktt7H",
        "colab_type": "text"
      },
      "source": [
        "# Quelle est la quantité de données nécessaires à l'entraînement ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txSjlglLvaC_",
        "colab_type": "text"
      },
      "source": [
        "Dans cette section, nous étudions l'effet de la taille des données d'entraînement sur la performance finale de la tâche considérée. Nous explorons également une technique, appelée **augmentation des données**, pour augmenter artificiellement la taille d'un ensemble de données donné pendant le processus d'entraînement.\n",
        "\n",
        "Notez que nous gardons l'ensemble de données de validation fixe tout au long de ce tutoriel. C'est juste pour le but de ce tutoriel, car nous voulons que les différentes évaluations soient comparables. Dans les scénarios de la vie réelle, l'ensemble de données de validation ne doit jamais être plus grand que l'ensemble de données d'entraînement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MKcpyiQxl-6",
        "colab_type": "text"
      },
      "source": [
        "## Entraînement avec seulement 1% des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOm2bCVxy5mc",
        "colab_type": "text"
      },
      "source": [
        "Commençons par considérer seulement 1% de nos données d'entraînement. La méthode suivante permet de sélectionner une partie des données d'un ensemble de données donné. Elle prend en entrée cinq arguments :\n",
        "- **imgs** : tableau numérique représentant l'ensemble d'images à partir duquel la sélection est effectuée.\n",
        "- **labels** : étiquettes associées à l'ensemble d'images fourni.\n",
        "- **ratio** (facultatif) : partie des données qui seront sélectionnées. Valeur par défaut : `0.1`.\n",
        "- **shuffle** ( facultatif ) : si les données doivent être mélangées ou non avant que la sélection ne soit effectuée. Valeur par défaut : `True`.\n",
        "- **seed** ( facultatif ) : graine du générateur aléatoire : Valeur par défaut : `1234`.\n",
        "\n",
        "Il fournit en sortie 2 éléments :\n",
        "- **select_imgs** : tableau numpy des images sélectionnées.\n",
        "- **select_labels** : étiquettes associées aux images sélectionnées.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKQZqtge0QoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "59aa3d6c-2514-46fa-82a3-7a2470f77c17"
      },
      "source": [
        "def select_subset_from_dataset(imgs, labels, ratio=0.1, shuffle=True, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     imgs: numpy array representing the image set from which \n",
        "        the selection is made.\n",
        "     labels: the labels associated with the provided images.\n",
        "     ratio (optional): portion of the data to be selected. Default: 0.1.\n",
        "     shuffle (optional): Whether or not to shuffle the data. Default: True.\n",
        "     seed (optional): seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of 2 elements (select_imgs, select_labels)\n",
        "     where:\n",
        "        select_imgs: a numpy array of the selected images.\n",
        "        select_labels: labels associated with the selected images.\n",
        "      \n",
        "  \"\"\"\n",
        "  if shuffle:\n",
        "    np.random.seed(seed)  # Set the random seed of numpy.\n",
        "    indices = np.random.permutation(imgs.shape[0])\n",
        "  else:\n",
        "    indices = np.arange(imgs.shape[0])\n",
        "  idx, _ = np.split(indices, [int(ratio*len(indices))])\n",
        "  select_imgs = imgs[idx]\n",
        "  tgt = np.array(labels)\n",
        "  select_labels = tgt[idx].tolist()\n",
        "  return select_imgs, select_labels\n",
        "\n",
        "\n",
        "select_imgs, select_labels = select_subset_from_dataset(\n",
        "    train_imgs, train_labels, 0.01\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-168971a31db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m select_imgs, select_labels = select_subset_from_dataset(\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_imgs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rfbVmI7V4dxF"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "Entraîner un modèle en utilisant les données sélectionnées et évaluer sa performance sur l'ensemble de données de validation. Les arguments suivants doivent être utilisés :\n",
        "- **epochs** : `5`.\n",
        "- **batch_size** : `32`.\n",
        "- **metrics** : `{'Accuracy' : accuracy}`.\n",
        "\n",
        "Qu'observez-vous ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UglqJKbYvdpY",
        "colab_type": "code",
        "outputId": "9ca664d7-7fb6-492f-c3c2-2ee3086686ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "source": [
        "# Entraîner sur les données sélectionnées\n",
        "model = ... # à compléter.\n",
        "\n",
        "# Évaluer de modèle entraîné sur l'ensemble de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1/5] Training loss: 2.287 | Validation loss: 2.269\n",
            "[Epoch 2/5] Training loss: 2.224 | Validation loss: 2.203\n",
            "[Epoch 3/5] Training loss: 2.118 | Validation loss: 2.162\n",
            "[Epoch 4/5] Training loss: 2.041 | Validation loss: 2.117\n",
            "[Epoch 5/5] Training loss: 2.001 | Validation loss: 2.124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation on validataion dataset:\n",
            "Metric Accuracy: 22%\n",
            "Accuracy of plane (0): 50%\n",
            "Accuracy of car   (1): 37%\n",
            "Accuracy of bird  (2): 0%\n",
            "Accuracy of cat   (3): 6%\n",
            "Accuracy of deer  (4): 0%\n",
            "Accuracy of dog   (5): 5%\n",
            "Accuracy of frog  (6): 88%\n",
            "Accuracy of horse (7): 0%\n",
            "Accuracy of ship  (8): 9%\n",
            "Accuracy of truck (9): 21%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dcves3L8_nE",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wExcwcMc7c7_"
      },
      "source": [
        "### Exercice\n",
        "Dans l'exercice précédent, nous avons limité le nombre d'époques à \"5\". Dans cette section, nous vous demandons d'entraîner votre modèle en utilisant un nombre d'époques plus élevé (par exemple, `50`, `100`). Pour une comparaison équitable, vous devez conserver les arguments suivants :\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy}`.\n",
        "- **eval_imgs**: `valid_imgs`.\n",
        "- **eval_labels**: `eval_labels`.\n",
        "\n",
        "Qu'observez-vous ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBVuYOZ58VkD",
        "colab_type": "code",
        "outputId": "88becb60-1daa-4b88-d549-26635a8704ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Entraîner sur les données sélectionnées\n",
        "model = ... # à compléter.\n",
        "\n",
        "# Évaluer de modèle entraîné sur l'ensemble de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1/50] Training loss: 2.287 | Validation loss: 2.269\n",
            "[Epoch 2/50] Training loss: 2.224 | Validation loss: 2.203\n",
            "[Epoch 3/50] Training loss: 2.118 | Validation loss: 2.163\n",
            "[Epoch 4/50] Training loss: 2.043 | Validation loss: 2.112\n",
            "[Epoch 5/50] Training loss: 1.997 | Validation loss: 2.115\n",
            "[Epoch 6/50] Training loss: 1.911 | Validation loss: 2.049\n",
            "[Epoch 7/50] Training loss: 1.861 | Validation loss: 2.032\n",
            "[Epoch 8/50] Training loss: 1.818 | Validation loss: 2.039\n",
            "[Epoch 9/50] Training loss: 1.738 | Validation loss: 2.044\n",
            "[Epoch 10/50] Training loss: 1.663 | Validation loss: 2.054\n",
            "[Epoch 11/50] Training loss: 1.578 | Validation loss: 2.139\n",
            "[Epoch 12/50] Training loss: 1.586 | Validation loss: 2.085\n",
            "[Epoch 13/50] Training loss: 1.561 | Validation loss: 2.163\n",
            "[Epoch 14/50] Training loss: 1.513 | Validation loss: 2.057\n",
            "[Epoch 15/50] Training loss: 1.458 | Validation loss: 2.114\n",
            "[Epoch 16/50] Training loss: 1.312 | Validation loss: 2.145\n",
            "[Epoch 17/50] Training loss: 1.273 | Validation loss: 2.196\n",
            "[Epoch 18/50] Training loss: 1.329 | Validation loss: 2.243\n",
            "[Epoch 19/50] Training loss: 1.262 | Validation loss: 2.197\n",
            "[Epoch 20/50] Training loss: 1.199 | Validation loss: 2.388\n",
            "[Epoch 21/50] Training loss: 1.112 | Validation loss: 2.292\n",
            "[Epoch 22/50] Training loss: 1.104 | Validation loss: 2.488\n",
            "[Epoch 23/50] Training loss: 1.043 | Validation loss: 2.389\n",
            "[Epoch 24/50] Training loss: 0.891 | Validation loss: 2.443\n",
            "[Epoch 25/50] Training loss: 0.828 | Validation loss: 2.513\n",
            "[Epoch 26/50] Training loss: 0.837 | Validation loss: 2.579\n",
            "[Epoch 27/50] Training loss: 0.849 | Validation loss: 2.718\n",
            "[Epoch 28/50] Training loss: 0.928 | Validation loss: 2.640\n",
            "[Epoch 29/50] Training loss: 0.949 | Validation loss: 2.386\n",
            "[Epoch 30/50] Training loss: 0.808 | Validation loss: 2.502\n",
            "[Epoch 31/50] Training loss: 0.566 | Validation loss: 2.774\n",
            "[Epoch 32/50] Training loss: 0.474 | Validation loss: 3.117\n",
            "[Epoch 33/50] Training loss: 0.466 | Validation loss: 3.177\n",
            "[Epoch 34/50] Training loss: 0.424 | Validation loss: 3.134\n",
            "[Epoch 35/50] Training loss: 0.325 | Validation loss: 3.410\n",
            "[Epoch 36/50] Training loss: 0.326 | Validation loss: 3.753\n",
            "[Epoch 37/50] Training loss: 0.239 | Validation loss: 3.721\n",
            "[Epoch 38/50] Training loss: 0.207 | Validation loss: 3.914\n",
            "[Epoch 39/50] Training loss: 0.161 | Validation loss: 4.016\n",
            "[Epoch 40/50] Training loss: 0.122 | Validation loss: 4.349\n",
            "[Epoch 41/50] Training loss: 0.096 | Validation loss: 4.440\n",
            "[Epoch 42/50] Training loss: 0.093 | Validation loss: 4.590\n",
            "[Epoch 43/50] Training loss: 0.083 | Validation loss: 4.711\n",
            "[Epoch 44/50] Training loss: 0.095 | Validation loss: 4.834\n",
            "[Epoch 45/50] Training loss: 0.058 | Validation loss: 4.808\n",
            "[Epoch 46/50] Training loss: 0.042 | Validation loss: 5.076\n",
            "[Epoch 47/50] Training loss: 0.033 | Validation loss: 5.168\n",
            "[Epoch 48/50] Training loss: 0.028 | Validation loss: 5.318\n",
            "[Epoch 49/50] Training loss: 0.028 | Validation loss: 5.414\n",
            "[Epoch 50/50] Training loss: 0.029 | Validation loss: 5.551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/8BlISqqB8ia5kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmKsg6gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation on validataion dataset:\n",
            "Metric Accuracy: 29%\n",
            "Accuracy of plane (0): 40%\n",
            "Accuracy of car   (1): 31%\n",
            "Accuracy of bird  (2): 31%\n",
            "Accuracy of cat   (3): 19%\n",
            "Accuracy of deer  (4): 18%\n",
            "Accuracy of dog   (5): 29%\n",
            "Accuracy of frog  (6): 35%\n",
            "Accuracy of horse (7): 18%\n",
            "Accuracy of ship  (8): 39%\n",
            "Accuracy of truck (9): 27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEMYRMeR8gA8",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRPF8m5Ps7p",
        "colab_type": "text"
      },
      "source": [
        "## Performance en fonction de la taille de l'ensemble de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ILOZAvjPzhB",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, nous entraînons le même modèle sur différents ratios de l'ensemble des données d'entraînement (par exemple, 10 % de l'ensemble des données d'entraînement) tout en gardant l'ensemble des données de validation fixe. Nous voulons observer l'impact de l'utilisation d'un ensemble de données d'entraînement plus important.\n",
        "\n",
        "La fonction suivante réalise cette étude à partir d'une liste de valeurs de ratios. Elle prend comme arguments :\n",
        "- **ratio_list** : liste des ratios à prendre en compte dans l'étude.\n",
        "- **epochs** (facultatif) : nombre d'époques d'entraînement. Par défaut : `5`.\n",
        "- **seed** (facultatif) : graine du générateur aléatoire : Valeur par défaut : `1234`.\n",
        "\n",
        "Cette fonction génère un graphique montrant la performance (en termes de précision) en fonction du ratio des données utilisées pour l'entraînement du modèle.\n",
        "\n",
        "Il est important de noter qu'en fixant le nombre d'époques, plus la taille de l'ensemble d'entraînement augmente, plus nous effectuons de mises à jour des paramètres. Par conséquent, l'étude globale n'est pas tout à fait juste puisque nous n'entraînons pas le modèle sur un nombre fixe d'itérations. Cependant, notre objectif ici est d'évaluer la relation entre la performance d'un modèle et le nombre d'exemples dans l'ensemble d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPD0is-Q7ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_study(ratio_list, epochs=5, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     ratio_list: list of ratio numbers to be considered.\n",
        "     epochs (optional): number of training epochs. Default: 5.\n",
        "     seed (optional): seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     This method does not return anything, but it generates a plot.\n",
        "      \n",
        "  \"\"\"\n",
        "  results = []\n",
        "  for ratio in ratio_list:\n",
        "    select_imgs, select_labels = select_subset_from_dataset(\n",
        "        train_imgs, train_labels, ratio\n",
        "    )\n",
        "    trained_model = training_on_dataset(\n",
        "        select_imgs, select_labels, valid_imgs, valid_labels,\n",
        "        epochs=epochs, batch_size=32,\n",
        "        seed=seed, verbose=False\n",
        "    )\n",
        "    acc, _ = evaluate_classes(\n",
        "        trained_model, valid_imgs, valid_labels, batch_size=32,\n",
        "        verbose=False\n",
        "    )\n",
        "    results.append(acc)\n",
        "  \n",
        "  print('Best accuracy: {:.0%}'.format(max(results)))\n",
        "  plt.plot(ratio_list, results)\n",
        "  plt.title('Model performance on validation set')\n",
        "  plt.xlabel('Training set ratio')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RDZLShKzgUMV"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "Évaluez la performance en utilisant les ratios suivants : `0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0`. \n",
        "\n",
        "Vous pouvez choisir le nombre d'époques que vous souhaitez pour cette étude. Gardez simplement à l'esprit que plus le nombre est élevé, plus le temps nécessaire à l'entraînement/étude est long. Par conséquent, il est recommandé de ne pas dépasser `epochs=20` pour les besoins de ce tutoriel. Par défaut, il est fixé à `epochs=5`.\n",
        "\n",
        "Encore une fois, en ayant un nombre fixe d'époques, plus l'ensemble d'entraînement est grand, plus nous mettons à jour les paramètres du modèle.\n",
        "\n",
        "Quelle est votre conclusion ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jS-MkJ_rprdH",
        "colab": {}
      },
      "source": [
        "ratio_list = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
        "... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hOajcWPAxrC",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrrNv7Adnj27",
        "colab_type": "text"
      },
      "source": [
        "Les paramètres des réseaux de neurones sont initialisés à des valeurs aléatoires. Si nous ne fixons pas une graine de modèle, les nombres aléatoires générés utilisés pour initialiser ces paramètres seront différents. Essayez de faire la même expérience avec une graine différente (par exemple, `graine=8761`) en utilisant le même nombre d'époques que dans l'exercice précédent. Obtenez-vous le même résultat ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accW_kKt5TEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2b94f44e-8243-4621-d418-96b59b50dfb0"
      },
      "source": [
        "... # à compléter.\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dFQG5ViqzM1",
        "colab_type": "text"
      },
      "source": [
        "## Augmentation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnD2tCAv2QWZ",
        "colab_type": "text"
      },
      "source": [
        "Très souvent, on nous fournit un ensemble de données et il n'y a pas moyen d'en collecter davantage. Dans cette section, nous explorons rapidement la technique d'augmentation des données, qui consiste à modifier les images dans le jeu de données d'entraînement sans changer les étiquettes associées. Ce faisant, il est possible d'augmenter artificiellement le nombre d'images dans notre ensemble de données d'entraînement. Par exemple, nous pouvons penser aux opérations de renversement ou de recadrage/redimensionnement pour modifier une image dans l'ensemble de données sans modifier l'étiquette qui lui est associée. Par conséquent, en apprenant sur un plus grand nombre d'images, nous pouvons observer certains gains de performance et/ou une meilleure généralisation du modèle. Cependant, comme l'augmentation des données crée artificiellement de nouveaux exemples à partir de ceux qui existent déjà, l'hypothèse d'indépendance n'est pas respectée. Ainsi, nous ne devrions pas utiliser l'augmentation des données pour les ensemble de données de validation et d'évaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PKpTId_3lGI",
        "colab_type": "text"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "Supposons que nous n'ayons accès qu'à 30 % de l'ensemble des données d'entraînement d'origine. Entraînez un modèle avec cette portion de données et évaluez-le sur l'ensemble de données de validation. À mesure que le nombre d'exemples augmente dans l'ensemble d'entraînement, nous pouvons envisager d'augmenter le nombre d'époques tout en gardant à l'esprit le problème du surapprentissage. Pour cet exercice, nous utiliserons les arguments suivants :\n",
        "- **epochs**: `15`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy}`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pBFLLmxrCC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "68cc7581-42b0-4464-e765-92cbabc1f36a"
      },
      "source": [
        "# sélectionnez les données\n",
        "select_imgs, select_labels = ... # à compléter.\n",
        "\n",
        "# Entraînez sur les données sélectionnées\n",
        "model50 = ... # à compléter.\n",
        "\n",
        "# Évaluez sur l'ensemble de données de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d864b207588c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sélectionnez les données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mselect_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# à compléter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Entraînez sur les données sélectionnées\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# à compléter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdeKH-JsrcPl",
        "colab_type": "text"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "Le code suivant définit une transformation, en utilisant le cadre PyTorch. Avec l'opération de recadrage aléatoire, un recadrage de taille aléatoire (0,7 à 1,0) de l'image originale est effectué et celle-ci est redimensionnée en une image 32 x 32. Les opérations de \"transformation\" sont appliquées aux images originales à chaque génération de mini lots. Cela laisse les images de votre ensemble de données inchangées, seules les images des mini lots sont copiées et transformées à chaque itération."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5h0bzG9rh_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Normalize((-1., -1., -1.), (2., 2., 2.)),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop((32, 32), scale=(0.7, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "110l_poa5AUi",
        "colab_type": "text"
      },
      "source": [
        "Cette fois, entraînez un nouveau modèle en utilisant la même architecture en appliquant une augmentation des données sur les 30% extraits de l'ensemble de données d'entraînement. Évaluez votre modèle et comparez vos résultats avec ceux de l'exercice précédent. Utilisez les arguments suivants :\n",
        "- **epochs**: `15`.\n",
        "- **batch_size**: `32`.\n",
        "- **metrics**: `{'Accuracy': accuracy}`.\n",
        "\n",
        "Notez que vous pouvez utiliser l'argument `transformations` de la méthode `training_on_dataset` pour effectuer une augmentation des données pendant l'entraînement.\n",
        "\n",
        "Qu'observez-vous ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JHCgdzprnG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entraînement sur les données sélectionnées avec augmentation de données\n",
        "model50A = ... # à compléter.\n",
        "\n",
        "# Évaluez sur l'ensemble de données de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP24gLYYIia_",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRbANE0mjLY",
        "colab_type": "text"
      },
      "source": [
        "# Ensembles de données non équilibrés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfpH0Cx1NA-z",
        "colab_type": "text"
      },
      "source": [
        "## Qu'est-ce qu'un ensemble de données déséquilibré ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDuyTs_smng1",
        "colab_type": "text"
      },
      "source": [
        "Jusqu'à présent, l'ensemble des données d'entraînement contenait à peu près le même nombre d'images pour chaque étiquette. Dans cette section, nous examinons l'impact d'entraîner des modèles sur un ensemble de données déséquilibré, ce qui se produit lorsque chaque classe ne constitue pas une portion égale de votre ensemble de données. \n",
        "\n",
        "La fonction suivante sélectionne une partie des données d'un ensemble de données donné tout en fournissant une distribution d'étiquettes définie. Elle prend en entrée six arguments :\n",
        "- **imgs** : tableau numpy représentant l'ensemble d'images à partir duquel la sélection est effectuée.\n",
        "- **labels** : étiquettes associées à l'ensemble d'images fourni.\n",
        "- **label_dist** : la distribution des étiquettes à sélectionner, représentée par un dict de `{label : value}`.\n",
        "- **ratio** (facultatif) : partie des données qui seront sélectionnées. Valeur par défaut : `0.1`.\n",
        "- **shuffle** ( facultatif ) : si les données doivent être mélangées ou non avant que la sélection ne soit effectuée. Valeur par défaut : `True`.\n",
        "- **seed** ( facultatif ) : graine du générateur aléatoire : Valeur par défaut : `1234`.\n",
        "\n",
        "Il fournit en sortie 2 éléments :\n",
        "- **select_imgs** : un tableau numpy des images sélectionnées.\n",
        "- **select_labels** : étiquettes associées aux images sélectionnées.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx4E8E5TLr2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_subset_from_dataset_with_label_dist(\n",
        "    imgs, labels, label_dist, ratio=0.1, shuffle=True, seed=1234):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     imgs: numpy array representing the image set from which \n",
        "        the selection is made.\n",
        "     labels: the labels associated with the provided images.\n",
        "     label_dist: the distribution of labels to select.\n",
        "     ratio (optional): portion of the data to be selected. Default: 0.1.\n",
        "     shuffle (optional): Whether or not to shuffle the data. Default: True.\n",
        "     seed (optional): seed of the numpy random generator: Default: 1234.\n",
        "        \n",
        "  Return:\n",
        "     A tuple of 2 elements (select_imgs, select_labels)\n",
        "     where:\n",
        "        select_imgs: a numpy array of the selected images.\n",
        "        select_labels: labels associated with the selected images.\n",
        "      \n",
        "  \"\"\"\n",
        "  if isinstance(label_dist, (list, tuple)):\n",
        "    label_dist = {a:v for a,v in enumerate(label_dist)}\n",
        "  sum_dist = sum(label_dist.values())\n",
        "  for lab in label_dist.keys():\n",
        "    label_dist[lab] /= sum_dist\n",
        "    \n",
        "  tgts = np.array(labels)\n",
        "  num_indices = int(ratio*len(labels))\n",
        "  num_idx_lab = {a: int(label_dist[a]*num_indices) for a in label_dist.keys()}\n",
        "  \n",
        "  sel_ind = []\n",
        "  \n",
        "  if shuffle:\n",
        "    np.random.seed(seed)  # Set the random seed of numpy.\n",
        "\n",
        "  for a in num_idx_lab.keys():\n",
        "    idx = np.where(tgts==a)\n",
        "    idx = idx[0]\n",
        "    if shuffle:\n",
        "      idx = np.random.permutation(idx)\n",
        "    num = min(num_idx_lab[a], len(idx))\n",
        "    idx = idx[0:num]\n",
        "    sel_ind.extend(idx)\n",
        "    \n",
        "  if shuffle:\n",
        "    sel_ind = np.random.permutation(sel_ind)\n",
        "  else:\n",
        "    sel_ind.sort()\n",
        "    sel_ind = np.array(sel_ind)\n",
        "    \n",
        "  select_imgs = imgs[sel_ind, :]\n",
        "  select_labels = tgts[sel_ind].tolist()\n",
        "  \n",
        "  return select_imgs, select_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQO9ejo57_G1"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "En utilisant la fonction définie ci-dessus avec ses paramètres par défaut, extraire 30 % des données de l'ensemble de données d'entraînement original tout en fournissant la distribution d'étiquettes suivante :\n",
        "- **0**: `0.4`.\n",
        "- **1**: `0.1`.\n",
        "- **2**: `0.05`.\n",
        "- **3**: `0.01`.\n",
        "- **4**: `0.2`.\n",
        "- **5**: `0.14`.\n",
        "- **6**: `0.02`.\n",
        "- **7**: `0.005`.\n",
        "- **8**: `0.045`.\n",
        "- **9**: `0.03`.\n",
        "\n",
        "De plus, calculez l'histogramme de l'ensemble de données résultant.\n",
        "\n",
        "Notez que nous allons d'abord entraîner notre modèle sur un ensemble de données d'entraînement non équilibré, mais évaluez-le sur l'ensemble de validation équilibré que nous utilisons depuis le début de ce tutoriel. Nous construirons ensuite un ensemble de validation avec une distribution qui correspond à celle de l'ensemble d'entraînement.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-irncrQq4MD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "f6cbe23a-3a3f-494c-b8e1-98f2a81d905f"
      },
      "source": [
        "label_distribution = {\n",
        "    0: 0.4,\n",
        "    1: 0.1,\n",
        "    2: 0.05,\n",
        "    3: 0.01,\n",
        "    4: 0.2, \n",
        "    5: 0.14,\n",
        "    6: 0.02,\n",
        "    7: 0.005,\n",
        "    8: 0.045,\n",
        "    9: 0.03\n",
        "}\n",
        "\n",
        "# choisissez les données selon la distribution donnée\n",
        "select_imgs, select_labels = ... # à compléter.\n",
        "\n",
        "# tracer l'histogramme des étiquettes correspondantes\n",
        "... # à compléter.\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6689ea43a75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# choisissez les données selon la distribution donnée\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mselect_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# à compléter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# tracer l'histogramme des étiquettes correspondantes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Z9BMTZN36h",
        "colab_type": "text"
      },
      "source": [
        "## La précision est-elle une bonne mesure pour un ensemble de données déséquilibré ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "47WPFK9zOaxz"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "Entraînez un modèle en utilisant votre nouvel ensemble de données d'entraînement extraites et évaluez sa performance sur l'ensemble de données de validation. Utilisez les arguments suivants :\n",
        "- **epochs** : `15`.\n",
        "- **batch_size** : `32`.\n",
        "- **metrics** : `{'Accuracy': accuracy} `.\n",
        "\n",
        "Qu'observez-vous en termes de différences entre la précision d'entraînement et la précision de validation? Qu'observez-vous en ce qui concerne la précision des étiquettes moins fréquentes ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxnLmJWo-Xze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entraînement sur les données sélectionnées\n",
        "modelUnbal = ... # à compléter.\n",
        "\n",
        "# Évaluation sur l'ensemble de données de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NruL0f6L-Ps",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6XexaV-HRfqC"
      },
      "source": [
        "### Exercice\n",
        "Lorsque nous disposons d'un ensemble de données déséquilibré, le score F1 est généralement une mesure de performance recommandée car il peut être interprété comme une moyenne pondérée des [scores de précision et de rappel] (https://en.wikipedia.org/wiki/Precision_and_recall).\n",
        "\n",
        "Entraînez un modèle en utilisant l'ensemble de données d'entraînement extraites et évaluez ses performances sur l'ensemble de données de validation. Utilisez les mêmes arguments que pour le dernier exercice, mais ajoutez le score F1 :\n",
        "- **epochs** : `15`.\n",
        "- **batch_size** : `32`.\n",
        "- **metrics** : `{'Accuracy': accuracy, 'F1' : f1_score}`.\n",
        "\n",
        "Quelles différences observez-vous en termes de mesure des performances entre les ensembles de données d'entraînement et de validation ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z44t-ro_Df0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entraînement sur les données sélectionnées\n",
        "modelUnbal = ... # à compléter.\n",
        "\n",
        "# Évaluation sur l'ensemble de données de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q7fPgwjmGWi",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7-qY_oH23sh",
        "colab_type": "text"
      },
      "source": [
        "### Exercice\n",
        "Imaginez maintenant que l'ensemble de validation soit aussi déséquilibré que l'ensemble d'entraînement. L'observation faite précédemment est-elle toujours valable ?\n",
        "\n",
        "Pour répondre à cette question, extrayez 30 % de l'ensemble de données de validation original avec la distribution d'étiquettes ci-dessus et utilisez-le comme nouvel ensemble de validation pour cet exercice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOAV8z1y7vqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "20bb3970-1f9f-4713-e401-b70c38bd86b8"
      },
      "source": [
        "# sélectionner 30 % de l'ensemble de validation avec la distribution fournie\n",
        "# des étiquettes\n",
        "unb_valid_imgs, unb_valid_labels = ... # à compléter.\n",
        "\n",
        "\n",
        "# entraînement avec des ensembles d'entraînement et de validation non équilibrés\n",
        "modelUnbal = ... # à compléter.\n",
        "\n",
        "# Évaluer sur l'ensemble de validation non-équilibré\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-04eed78b58b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sélectionner 30 % de l'ensemble des données de validation avec la distribution des étiquettes fournie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munb_valid_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munb_valid_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# à compléter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# training on using the unbalanced training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3CbcmNLO4mQ",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdwjfGNmTST_",
        "colab_type": "text"
      },
      "source": [
        "## Gestion des ensembles de données déséquilibrés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz8TGOohTcJ_",
        "colab_type": "text"
      },
      "source": [
        "Une façon d'atténuer l'effet d'un ensemble de données déséquilibré pendant le processus d'entraînement est de pénaliser le modèle lorsqu'il fait des erreurs de classification sur des classes moins fréquentes. Un moyen d'y parvenir est d'attribuer des poids d'importance aux étiquettes qui sont inversement proportionnels à leur densité dans l'ensemble de données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E3iJ_-vWVG9Y"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "Calculez les poids d'importance de chaque étiquette en utilisant la distribution des étiquettes fournie à la section précédente.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiS2HFH9IbNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_weights = ... # à compléter.\n",
        "\n",
        "for i, w in enumerate(label_weights):\n",
        "  print('Importance weight for {:<5s} ({}): {:.1f}'.format(classe_names[i], i, w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ntkItzYLVN8I"
      },
      "source": [
        "### Exercice\n",
        "\n",
        "En utilisant les poids d'importance calculés ci-dessus, entraînez un modèle en utilisant l'ensemble de données d'entraînement extraites et évaluez sa performance sur l'ensemble de données de validation d'origine. Afin d'obtenir des comparaisons équitables, utilisez les mêmes arguments que dans l'exercice précédent :\n",
        "- **epochs** : `15`.\n",
        "- **batch_size** : `32`.\n",
        "- **metrics** : `{'Accuracy': accuracy, 'F1': f1_score}`.\n",
        "\n",
        "Notez que les poids d'importance peuvent être transmis à la méthode d'entraînement en utilisant l'argument `label_weights`.\n",
        "\n",
        "Qu'observez-vous ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACbafl1BGgTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entraînement sur les données sélectionnées\n",
        "modelUnbal2 = ... # à compléter.\n",
        "\n",
        "# Évaluation sur l'ensemble de données de validation\n",
        "_ = ... # à compléter.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5w8vbPPmaV6",
        "colab_type": "text"
      },
      "source": [
        "... # à compléter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4QJ0cBCe483",
        "colab_type": "text"
      },
      "source": [
        "# Reproductibilité"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfk8gF1pG8oo",
        "colab_type": "text"
      },
      "source": [
        "Nous avons vu qu'il y a place pour beaucoup de hasard dans les expériences d'apprentissage automatique, en particulier durant:\n",
        "- la division d'un ensemble de données original en ensembles d'entraînement/validation/évaluation.\n",
        "- l'initialisation des paramètres d'un modèle.\n",
        "- la division d'un ensemble d'entraînement en lots pour entraîner un modèle.\n",
        "\n",
        "Par conséquent, nous obtenons normalement des résultats différents chaque fois que nous menons la même expérience. Pour permettre la reproductibilité de vos résultats, il est nécessaire de fixer la **graine aléatoire** avant de créer chaque ensemble de données et chaque modèle. Par conséquent, pour être reproductible, il est préférable de fixer manuellement :\n",
        "\n",
        "1. Générateur de nombres pseudo-aléatoires en python à une valeur fixe :\n",
        "```\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "```\n",
        "\n",
        "2. Générateur de nombres pseudo-aléatoires NumPy à une valeur fixe :\n",
        "```\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "```\n",
        "\n",
        "3. Générateur de nombres pseudo-aléatoires PyTorch à une valeur fixe pour tous les appareils (CPU et GPU) :\n",
        "```\n",
        "import torch\n",
        "torch.manual_seed(seed_value)\n",
        "```\n",
        "\n",
        "4. Générateur de nombres pseudo-aléatoires PyTorch à une valeur fixe pour le(s) GPU :\n",
        "```\n",
        "import torch\n",
        "torch.cuda.manual_seed(seed_value)  # Current GPU.\n",
        "torch.cuda.manual_seed_all(seed_value)  # All GPUs.\n",
        "```\n",
        "\n",
        "5. Algorithmes CuDNN (une extension de CUDA pour l'apprentissage profond) pour être déterministe dans PyTorch:\n",
        "```\n",
        "import torch\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "```\n",
        "\n",
        "Notez que les algorithmes déterministes peuvent rendre les calculs considérablement plus lents. Bien que la fixation manuelle des graines aléatoires aide à la reproductibilité, des résultats complètement reproductibles ne sont pas garantis pour toutes les versions de PyTorch et les différentes plateformes, dispositifs ou drivers.\n",
        "\n",
        "De plus, il y a plus de hasard lors du réglage des hyperparamètres ou de l'utilisation de plusieurs GPU en parallèle, mais cela dépasse la portée de ce tutoriel.\n",
        "\n",
        "Enfin, une bonne pratique, mise en œuvre dans Scikit-Learn, consiste à créer un objet RandomState local au lieu d'utiliser l'objet RandomState global et de le passer à chaque module en utilisant le caractère aléatoire. Cependant, l'API Pytorch ne le permet pas, et pour l'instant, il est recommandé d'utiliser des générateur de nombres pseudo-aléatoires globaux.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxB2LMKP2zXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
