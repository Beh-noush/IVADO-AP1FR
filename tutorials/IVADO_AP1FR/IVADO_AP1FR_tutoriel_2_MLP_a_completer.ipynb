{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mipSoOVlavkb",
    "lines_to_next_cell": 0
   },
   "source": [
    "# IVADO/MILA ÉCOLE D'APPRENTISSAGE PROFOND\n",
    "\n",
    "# 4e édition (automne 2019)\n",
    "\n",
    "# Tutoriel sur les données catégorielles avec perceptron multicouche (MLP)\n",
    "\n",
    "## Auteurs :\n",
    "\n",
    "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
    "\n",
    "Gaétan Marceau Caron <gaetan.marceau.caron@mila.quebec>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLHwvggEZERd",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Préface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKNGtQkkohiM",
    "lines_to_next_cell": 0
   },
   "source": [
    "Ce tutoriel présente les aspects pratiques de l'apprentissage profond par la réalisation d'un projet simple de bout en bout. Nous utiliserons la bibliothèque d'apprentissage profond <a href=\"https://pytorch.org/\"> `PyTorch`</a>, qui est bien connue pour sa facilité d'utilisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOD70vdvvtin",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nq9FwFVnQihX",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Chargement de bibliothèques et utilisation de GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reCpBfp1Qcrt",
    "lines_to_next_cell": 0
   },
   "source": [
    "Avant de commencer, nous installons les bibliothèques nécessaires pour le tutoriel à l'aide de pip. Pour ce faire, exécutez la cellule suivante en la sélectionnant et en utilisant `shift+Enter`. Cette étape peut prendre quelques minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "c5AlBPjnvzNh",
    "outputId": "48285c9a-dbd0-4585-e493-c089116ae91e"
   },
   "outputs": [],
   "source": [
    "!pip3 install 'torch==1.1.0' 'torchvision==0.3.0' 'Pillow==4.3.0' 'matplotlib==3.0.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djF9gjzLwsDB",
    "lines_to_next_cell": 0
   },
   "source": [
    "Maintenant, importez tous les modules que nous allons utiliser pour ce tutoriel en exécutant la cellule suivante :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "w9LnNnxBw0wC",
    "outputId": "2423e91f-ab6a-4ad2-db83-948e14bf0f89"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed) # Set the random seed of numpy for the data split.\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"GPU Available: {}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKzgFV9Favkt",
    "lines_to_next_cell": 0
   },
   "source": [
    "## PyTorch en quelques mots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vrus_-F0avkt",
    "lines_to_next_cell": 0
   },
   "source": [
    "*PyTorch* est une bibliothèque Python qui soutien un écosystème dynamique d'outils et de bibliothèques pour l’AA en vision, TLN, et plus encore. Il offre deux fonctionnalités de haut niveau :\n",
    "\n",
    "<ul>\n",
    "<li> operations on <a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\">tensors</a> (such as NumPy) with GPU support,</li>\n",
    "<li> operations for creating and optimizing computational graphs with an automatic differentiation system called <a href=\"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py\">Autograd</a>.</li>\n",
    "</ul>\n",
    "<a href=\"https://pytorch.org/docs/stable/torch.html\">Les documents PyTorch</a> contiennent la documentation API et <a href=\"https://pytorch.org/tutorials/\">de nombreux tutoriels</a>. De plus, PyTorch offre plusieurs fonctionnalités de traitement de données. L'une de ces fonctionnalités est la classe <a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.Dataset`</a> qui offre une interface facile à utiliser pour gérer un ensemble de données. Pour plus d'informations, référez-vous aux url suivantes :\n",
    "\n",
    "<ul>\n",
    "<li>PyTorch data sets: <a href=\"http://pytorch.org/docs/master/data.html\"> PyTorch - datasets</a>.</li>\n",
    "<li>A tutorial for loading data: <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"> PyTorch - data loading tutorial</a>.</li>\n",
    "</ul>\n",
    "<a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> Est une bibliothèque qui fournit les mêmes fonctions que les tenseurs de CPU mais pour les tenseurs CUDA, qui sont utilisés pour le calcul sur GPU. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> Retourne une valeur booléenne indiquant si CUDA est actuellement disponible. Enfin, nous vous recommandons d'utiliser une variable `device` qui identifie le périphérique sur lequel vous souhaitez effectuer des calculs. Nous pouvons affecter un tenseur à un périphérique avec la méthode `.to(device)`. Par défaut, les tenseurs sont des tenseurs de CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm122vNmq92L",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ingrédients pour une preuve de concept (POC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqvhR0ebavmE",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour réaliser un POC en AA, vous avez besoin de :\n",
    "\n",
    "<ul>\n",
    "<li>a task description as well as data to support it,</li>\n",
    "<li>an evaluation metric to assess the performance of a model,</li>\n",
    "<li>a model description,</li>\n",
    "<li>a cost function to be optimized,</li>\n",
    "<li>an optimizer that adjusts the parameters of the model.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8_pfpu2f6AO",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment préparer l’ensemble de données ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5piZxYUhSzq",
    "lines_to_next_cell": 0
   },
   "source": [
    "Notre tâche est de prédire si un passager a survécu ou non au naufrage du Titanic seulement en fonction de la base des données des passagers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4GuYNDFavlU",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ensemble de données Titanic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiOJx2ytavlU",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous pouvons télécharger le jeu de données Titanic à l'adresse suivante : https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/> Cet ensemble de données fournit des informations sur le sort de 1309 passagers du premier et unique voyage du bateau \"RMS Titanic\", résumé par le statut économique (classe), sexe, âge, informations familiales et survie. La plate-forme Kaggle utilise également cet ensemble de données comme une introduction à l'apprentissage automatique classique. Ici, nous l'utilisons pour introduire des concepts plus avancés liés à PyTorch et à l'apprentissage profond.\n",
    "\n",
    "Nous utilisons la bibliothèque <a href=\"https://pandas.pydata.org/\">Pandas</a> pour stocker le jeu de données en mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "bX_RSiffavlW",
    "outputId": "65feb3e0-c4e7-4812-e918-3767946f865d"
   },
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true', \n",
    "    sep='\\t', \n",
    "    index_col=None, \n",
    "    na_values=['NA']\n",
    ")\n",
    "\n",
    "# a snapshot of the first 5 data points\n",
    "titanic_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj88WmCmavlf",
    "lines_to_next_cell": 0
   },
   "source": [
    "**La signification des différentes colonnes (caractéristiques) est la suivante**:\n",
    "\n",
    "<ol>\n",
    "  <li> <b>pclass</b>: Classe du passager (1 = première; 2 = deuxième; 3 = troisième) </li>\n",
    "  <li> <b>survived</b>: Survécu? (0 = non; 1 = oui) </li>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, soeurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou d'enfants à bord </li>\n",
    "  <li> <b>ticket</b>: Numéro de ticket </li>\n",
    "  <li> <b>fare</b>: Tarif du passager </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n",
    "  <li> <b>boat</b>: Bateau de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro du corps (si le passager n'a pas survécu et que le corps a été retrouvé) </li>\n",
    "  <li> <b>home.dest</b>: Destination du passager </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2ed5fozqjce",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Pré-traitement des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__vcZhPnavlg",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Sélection de caractéristique\n",
    "\n",
    "Certaines caractéristiques ne sont pas pertinentes pour la tâche, par exemple :\n",
    "\n",
    "<ol>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>ticket</b>: Numéro du ticket </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>home.dest</b>: Destination du passager </li>\n",
    " </ol>\n",
    " \n",
    "D'autres caractéristiques dévoilent la cible à prédire et les inclure serait de la triche:\n",
    "<ol>\n",
    "  <li> <b>boat</b>: Bateau de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro du corps (si le passager n'a pas survécu et que le corps a été retrouvé)  </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "JJ0--SDpavlg",
    "outputId": "bb15e866-2779-4e6f-9deb-4eedf70248ad"
   },
   "outputs": [],
   "source": [
    "titanic_preprocess_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true', \n",
    "    sep=',', \n",
    "    index_col=None\n",
    ")\n",
    "\n",
    "titanic_preprocess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MckYm0M_xhR",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Encodage de Caractéristiques\n",
    "\n",
    "Certaines caractéristiques sont **des variables catégorielles**, ce qui signifie qu'elles peuvent prendre un nombre fini de valeurs.\n",
    "\n",
    " <ol>\n",
    "  <li> <b>pclass</b>: Classe du passager </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement </li>\n",
    " </ol>\n",
    "Pour traiter les variables catégorielles, nous devons les encoder d'une manière qui n'implique pas un ordre arbitraire, comme l'utilisation de nombres naturels (par exemple, 1, 2, 3). <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">L’ encodage one-hot</a> est un moyen de le réaliser. Nous pouvons télécharger le jeu de données pré-traité à l'adresse suivante : https://github.com/afansi/winterschool18/blob/master/titanic\\_prepocess.csv?raw=true. <br>La signification des variables encodées est la suivante :\n",
    "\n",
    "<ol>\n",
    "  <li> <b>survived</b>: Survécu? (0 = non; 1 = oui) </li>\n",
    "  <li> <b>pclass_1</b>: (1 si passager en première classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_2</b>: (1 si passager en deuxième classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_3</b>: (1 si passager en troisième classe; 0 sinon) </li>\n",
    "  <li> <b>sex_female</b>: (1 si passager est une femme; 0 sinon) </li>\n",
    "  <li> <b>sex_male</b>: (1 si passager est un homme ; 0 sinon) </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, soeurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou d'enfants à bord </li>\n",
    "  <li> <b>fare</b>: Tarif du passager </li>\n",
    "  <li> <b>embarked_C</b>: (1 si Port d'embarquement = Cherbourg (C); 0 sinon) </li> \n",
    "  <li> <b>embarked_Q</b>: (1 si Port d'embarquement = Queenstown (Q); 0 sinon) </li> \n",
    "  <li> <b>embarked_S</b>: (1 si Port d'embarquement = Southampton (S); 0 sinon)</li> \n",
    " </ol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJcs6PUTavlm",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Partition Entraînement / validation / évaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bjbgvffmavlo",
    "lines_to_next_cell": 0
   },
   "source": [
    "À ce stade, nous devons diviser l'ensemble de données en trois sous-ensembles :\n",
    "\n",
    "<ol>\n",
    "<li> <b> Train</b> (généralement 60% de l'ensemble de données): utilisé pour entraîner le modèle de classification. </li>   \n",
    "<li> <b> Validation</b> (généralement 20% de l'ensemble de données): utilisé pour évaluer les hyper-paramètres sur un ensemble de données différent. </li>   \n",
    "<li> <b> Test</b> (généralement 20% de l'ensemble de données): utilisé pour évaluer la performance de généralisation du modèle choisi sur un ensemble de données différent. </li>\n",
    "</ol>\n",
    "Nous utilisons la <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.split.html\">fonction numpy.split</a> pour séparer notre ensemble de données en sous-ensembles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBmL8VBOavlo"
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(\n",
    "    titanic_preprocess_df.sample(frac=1, random_state=seed), \n",
    "    [int(.6*len(titanic_preprocess_df)), int(.8*len(titanic_preprocess_df))])\n",
    "\n",
    "# Remove the label column from X and create a label vectors.\n",
    "X_train = train.drop(['survived'], axis=1).values\n",
    "y_train = train['survived'].values\n",
    "\n",
    "X_val = ... # À compléter.\n",
    "y_val = ... # À compléter.\n",
    "\n",
    "X_test = ... # À compléter.\n",
    "y_test = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv74TbIWavlr",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ensemble de données dans PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_LJtG-Xavlt",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous utiliserons la sous-classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.TensorDataset`</a> </b> pour manipuler ensemble les caractéristiques et les cibles d'un ensemble de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JtT4tV7avlt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "\n",
    "val_dataset = ... # À compléter.\n",
    "\n",
    "test_dataset = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obEPHnlTavkc",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment définir l'algorithme d'apprentissage ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhN5GL6Gavks",
    "lines_to_next_cell": 0
   },
   "source": [
    "Un perceptron multicouche (MLP) est un simple graphe de calcul composé de \"couches cachées\", qui sont définies par deux modules: Une *transformation linéaire* suivie d'une *non-linéarité*. Le résultat d'une couche cachée est un vecteur appelé *représentation distribuée* où chaque composant est associé à une unité cachée.\n",
    "\n",
    "Pour entraîner ce modèle, nous devons définir :\n",
    "\n",
    "<ul>\n",
    "<li>l'architecture du réseau en choisissant la fonction non linéaire et le nombre d'unités cachées par couche, </li>\n",
    "<li>la fonction de coût et l'optimiseur.  </li>\n",
    "</ul>\n",
    "Pour résoudre notre tâche, nous allons utiliser un MLP avec les propriétés suivantes :\n",
    "\n",
    " <ul>\n",
    " <li> la dimension d'entrée du modèle est de 12,</li>\n",
    " <li> la dimension de sortie du modèle est de 2,</li>\n",
    " <li> la première dimension de la sortie est la probabilité de décès et la deuxième dimension est la probabilité de survie,</li>\n",
    "  <li> le nombre de couches cachées est de 3, </li>\n",
    " <li> les dimensions des couches cachées sont respectivement de 20, 40, 20, </li>\n",
    " <li> la fonction d'activation est un ReLu pour toutes les couches cachées. </li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "701t0e-ravkr",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Comment définir un modèle dans PyTorch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4F5cyijavkv",
    "lines_to_next_cell": 0
   },
   "source": [
    "La <a href=\"https://pytorch.org/docs/stable/nn.html\">bibliothèque PyTorch NN</a> contient de nombreuses classes utiles pour la création de graphes de calcul.\n",
    "\n",
    "<ul>\n",
    "<li> La classe <a href=\"http://pytorch.org/docs/master/nn.html#module\">torch.nn.Module</a>: \n",
    "tout nouveau module doit hériter de cette classe ou de ses descendants (sous-classes).\n",
    "</li>   \n",
    "<li> La méthode `forward` : toute classe définissant un module doit implémenter la méthode `forward(...)`, qui définit la transformation des entrées en sorties.</li>  \n",
    "<li> La classe <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a>: cette classe implémente une transformation linéaire. Par défaut, elle prend deux paramètres : \n",
    "    <ul>\n",
    "    <li>`in_features`: la taille des données à l'entrée du module. </li>\n",
    "    <li>`out_features`: la taille des données à la sortie du module. </li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li> Le module <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">`torch.nn.functional`</a>: \n",
    "elle définit un ensemble de fonctions qui peuvent être appliquées directement à n'importe quel tenseur. À titre d'exemple, nous avons :\n",
    "    <ul>\n",
    "    <li> les fonctions non-linéaires: sigmoid(...), tanh(...), relu(...), etc...</li> \n",
    "    <li> les fonctions de coût : mse_loss(...), nll(...., cross_entropy(...), etc ...</li> \n",
    "    <li> les fonctions de régularisation: droupout(...), etc ... </li> \n",
    "    <li> ...</li> \n",
    "    </ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tscha6S-KIBB",
    "lines_to_next_cell": 0
   },
   "source": [
    "Vous devez compléter les méthodes suivantes :\n",
    "\n",
    "<ul>\n",
    "<li>La méthode `__init__` qui définit les couches. </li>\n",
    "<li>La méthode `forward(input)` qui retourne le `output`. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NyQGwC-avkw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR5eBfIbavk0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 20)\n",
    "        ... # À compléter.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        ... # À compléter.\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvLnHRZ5avk2",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Faire des prédictions avec un réseau de neurones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEXgJMDDavk3",
    "lines_to_next_cell": 0
   },
   "source": [
    "Maintenant, nous sommes prêts à tester notre réseau de neurones sur des données choisies au hasard.\n",
    "\n",
    "Dans PyTorch, un modèle a deux modes différents : <ul> <li> <b>train</b>: utilisé pendant l’entraînement, </li> <li> <b>eval</b>: utilisé pendant l'inférence pour l'évaluation du modèle. </li> </ul> La distinction est importante car certains modules se comportent différemment selon ce mode. Nous utiliserons le mode <b>évaluation</b> dans cette section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "gzcABMezavk6",
    "outputId": "d65d2777-ee2a-4f9d-9259-edb76428ad6f"
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "neural_net = NeuralNet()\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "# Eval mode activation\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Select the first 5 data points\n",
    "data, target = val_dataset[0:5]\n",
    "data = data.to(device)\n",
    "target = target.to(device)\n",
    "\n",
    "# Forward propagation of the data through the model\n",
    "output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
    "\n",
    "# Convert the logits into probabilities with softmax function\n",
    "output_proba = ... # À compléter.\n",
    "\n",
    "# Printing the probability\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVep0BElavlS",
    "lines_to_next_cell": 0
   },
   "source": [
    "Les rangées définissent la sortie du réseau, en termes de probabilités sur deux classes : <b>deceased</b> (première colonne) ou <b>survived</b> (deuxième colonne), pour chacun des cinq points de données d'entrée. Prenons l'étiquette avec la probabilité maximale comme étiquette prédite et comparons-la à l'étiquette correcte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "_jV4No36qjdU",
    "outputId": "995f5958-ab4d-4c8a-e486-f303405e1e88"
   },
   "outputs": [],
   "source": [
    "# Printing predictions (class with the highest probability)\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print('Model prediction')\n",
    "print(prediction)\n",
    "\n",
    "# Printing the real labels\n",
    "print(\"Actual data\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEIIjqOuqjdc",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**\n",
    "\n",
    "1. Quelle serait une bonne façon de mesurer la performance du modèle ?\n",
    "2. Comment notre modèle fonctionne-t-il ?\n",
    "3. Étant donné que le modèle n'est pas entraîné sur l’ensemble de données, constatez-vous un problème avec la mesure sélectionnée ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTTlBikYwb-w",
    "lines_to_next_cell": 0
   },
   "source": [
    "... \\# à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uySA2TCavmD",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Définissez la fonction de coût et l'optimiseur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkoobCLMavmE",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Fonction de coût\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7uSXQavmF",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons la fonction de coût en fonction de la tâche que nous voulons réaliser.\n",
    "\n",
    "PyTorch offre <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">de nombreuses fonctions de coût prêtes à utiliser</a>.\n",
    "\n",
    "Pour les problèmes de classification, la fonction de coût habituelle est <b>l'entropie croisée</b>, et c'est celle que nous utiliserons dans ce tutoriel. Dans PyTorch, elle est définie par la fonction <a href=\"https://pytorch.org/docs/master/nn.functional.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a>.  L'entropie croisée permet de comparer une distribution $p$ avec une distribution de référence $t$. Elle atteint son minimum lorsque $t=p$. La formule pour la calculer avec la prédiction et la cible est la suivante : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHnfYeS5avmF"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def cost_function(prediction, target):\n",
    "    loss = ... # À compléter.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vsx_cv9Wqjdj",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Rétropropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hcZaIKtavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "Dans PyTorch, grâce au mécanisme de dérivation automatique <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, il est possible de calculer automatiquement le gradient de la fonction de coût et de la rétropropager à travers le graphe de calcul.\n",
    "\n",
    "Pour ce faire, il suffit d'appeler la méthode `backward()` sur la variable retournée par la fonction de coût, par exemple, avec\n",
    "\n",
    "`loss = cost_function(....)` <br> `loss.backward()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YNo_ymYavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Optimisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4AlX9TwavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "PyTorch fournit un <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">ensemble de méthodes d'optimisation (`torch.optim`)</a> couramment utilisées par la communauté d'apprentissage profond. Ces méthodes incluent les suivantes :\n",
    "\n",
    "<ul>\n",
    "<li><b>SGD</b> (Descente de gradient stochastique) <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a></li>\n",
    "<li><b>Adam</b> (Adaptive Moment Estimation) : une variante de la méthode de descente de gradient dans laquelle le taux d'apprentissage est ajusté pour chaque paramètre. Cet ajustement est basé sur l'estimation des premier et deuxième moments des gradients. Cet optimiseur a démontré d'excellentes performances par rapport à la méthode SGD sur de nombreuses tâches de référence. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uam-a0_0qjdl",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour pouvoir utiliser un optimiseur dans PyTorch, nous devons l'instancier en passant les éléments suivants :\n",
    "\n",
    "<ul>\n",
    "<li><b>Les paramètres du modèle</b> : ils sont obtenus en utilisant la méthode <b>parameters()</b> sur le modèle instancié.</li>\n",
    "<li><b>Le taux d'apprentissage / learning rate (lr)</b>: c'est le taux d'apprentissage qui doit être utilisé pour mettre à jour les paramètres pendant le processus d'optimisation. </li>\n",
    "<li>Il peut y avoir d'autres paramètres spécifiques à l'optimiseur choisi.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jt6_Qr6ravmI",
    "lines_to_next_cell": 0
   },
   "source": [
    "PyTorch offre une interface simplifiée pour interagir avec n'importe quel optimiseur :\n",
    "\n",
    "<ul>\n",
    "<li><b>zero_grad()</b>: Permet de réinitialiser les gradients à zéro au début d'une étape d'optimisation.</li>\n",
    "<li><b>step()</b>: Permet d'effectuer une étape d'optimisation après une étape de rétropropagation de gradient.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZ-lKExqavmI",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous utiliserons Adam avec un taux d’apprentissage (lr) de 0.001.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDMOziJTavmI"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnFOAfdGqjdr",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment entraîner un modèle?\n",
    "\n",
    "Tout d'abord, nous avons besoin de définitions :\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "<b>Époque / Epoch</b>:  un passage complet sur l'ensemble des données d'entraînement.\n",
    "</li>\n",
    "<li>\n",
    "<b>Itération / Iteration</b>: une mise à jour des paramètres du modèle. De nombreuses itérations peuvent se produire avant la fin d'une époque.\n",
    "</li>\n",
    "<li>\n",
    "<b>Mini-lot / Mini-batch</b>:  Un sous-ensemble de données d'entraînement utilisé pour estimer la moyenne des gradients. En d'autres termes, à chaque itération, un mini-lot est utilisé.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLXjNiDTavmK",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Création des mini-lots\n",
    "\n",
    "PyTorch offre une fonction appelée <b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> pour charger n'importe quel ensemble de données et le diviser automatiquement en mini-lots. Pendant l’entraînement, les données présentées au réseau doivent apparaître dans un ordre différent d'une époque à l'autre. Nous préparerons le `DataLoader` pour nos trois ensembles de données (entraînement, validation et évaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGoQZSdqavmM"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32  # number of data in a training batch.\n",
    "eval_batch_size = 32   # number of data in an batch.\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "val_loader   = ... # À compléter.\n",
    "test_loader  = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia3ai-GvavmP",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Boucle d'entraînement simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9wNZrTnavmQ",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons ici notre procédure d’entraînement pour une époque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyK9xCsZavmR"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, optimizer, device):\n",
    "    \n",
    "    # activate the training mode\n",
    "    model.train()\n",
    "    \n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # iteration over the mini-batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # transfer the data on the chosen device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # reinitialize the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward propagation on the data\n",
    "        prediction = model(data)\n",
    "        \n",
    "        # compute the cost function w.r.t. the targets\n",
    "        loss = cost_function(prediction, target)\n",
    "        \n",
    "        # execute the backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # execute an optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumulate the loss\n",
    "        total_loss += loss.item()*len(data)\n",
    "        \n",
    "        # compute the number of correct predictions\n",
    "        _, pred_classes = torch.max(prediction, dim=1)        \n",
    "        correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()\n",
    "         \n",
    "        \n",
    "    # compute the average cost per epoch\n",
    "    mean_loss = total_loss/len(train_loader.dataset)\n",
    "    \n",
    "    # compute the accuracy\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "        \n",
    "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
    "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
    "        100. * acc))   \n",
    "    \n",
    "    # return the average loss and the accuracy\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxG666rmavmU",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Procédure d'évaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGexbWaHavmU",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons ici notre procédure d'évaluation du modèle. <br/> Outre le passage du modèle en mode **eval**, il est essentiel de désactiver le calcul du gradient. <br/> Pour ce faire, PyTorch offre un ensemble de gestionnaires de contexte pour <a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">désactiver/activer localement le calcul de gradient </a>:\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "`torch.no_grad()`: désactiver le calcul du gradient.\n",
    "</li>\n",
    "<li>\n",
    "`torch.enable_grad()`: activer le calcul du gradient.\n",
    "</li>\n",
    "<li>\n",
    "`torch.set_grad_enabled(bool)`: activer/désactiver le calcul du gradient.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gQj9W5LavmU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, device):\n",
    "    \n",
    "    # activate the evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # iterate over the batches\n",
    "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
    "\n",
    "            # transfer the data on the chosen device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # forward propagation on the data\n",
    "            prediction = model(data)\n",
    "\n",
    "            # compute the cost function w.r.t. the targets\n",
    "            loss = cost_function(prediction, target)           \n",
    "\n",
    "\n",
    "            # accumulate the loss\n",
    "            total_loss += loss.item()*len(data)\n",
    "\n",
    "            # compute the number of correct predictions en sortie)\n",
    "            _, pred_classes = torch.max(prediction, dim=1) \n",
    "            correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()         \n",
    "          \n",
    "    \n",
    "    # compute the average cost per epoch\n",
    "    mean_loss = total_loss/len(eval_loader.dataset)\n",
    "    \n",
    "    # compute the accuracy\n",
    "    acc = correct / len(eval_loader.dataset)\n",
    "        \n",
    "    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
    "        mean_loss, correct, len(eval_loader.dataset),\n",
    "        100. * acc)) \n",
    "    \n",
    "    # return the average loss and the accuracy\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMUyZNxdavmW",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Attribution de points de contrôle (checkpointing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQLklQXAavmW",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour les phases d’entraînement qui nécessitent beaucoup de temps, il est recommandé d'enregistrer périodiquement les paramètres du modèle. Cette étape est communément appelée <b>attribution de points de contrôle (checkpointing)</b>.\n",
    "\n",
    "PyTorch offre <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">un mécanisme simple</a> pour effectuer cette opération.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ld-Y2gF-avmX",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous implémentons deux méthodes ici :\n",
    "\n",
    "<ul>\n",
    "<li> la première pour <b> sauvegarder </b> un modèle,</li>\n",
    "<li> la deuxième pour <b> charger </b> un point de contrôle d'un modèle.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMmNpma2avmX"
   },
   "outputs": [],
   "source": [
    "def save_model(epoch, model, path='./'):\n",
    "    \n",
    "    # creating the file name indexed by the epoch value\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # saving the model parameters\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZptgqQRavmZ"
   },
   "outputs": [],
   "source": [
    "def load_model(epoch, model, path='./'):\n",
    "    \n",
    "    # creating the file name indexed by the epoch value\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # loading the parameters of the saved model\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ve8sOocWavma",
    "lines_to_next_cell": 0
   },
   "source": [
    "Il est également possible d'enregistrer l'état de l'optimiseur dans PyTorch, ce qui est très important lorsque nous voulons reprendre l’entraînement du modèle à partir d'une certaine sauvegarde. Pour plus d'informations, veuillez consulter <a href='https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3'>l'URL suivant</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lcAP8-1avma",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Rassembler le tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "keMpyePsavmb",
    "outputId": "638ef04a-0f0e-4e8a-8b50-23884324a79b"
   },
   "outputs": [],
   "source": [
    "# maximum number of epoch\n",
    "numEpochs = 200\n",
    "\n",
    "# Saving frequency\n",
    "checkpoint_freq = 10\n",
    "\n",
    "# Directory for data backup\n",
    "path = './'\n",
    "\n",
    "# Accumulators of average costs obtained per epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Performance accumulators per epoch\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Model definition\n",
    "neural_net = NeuralNet()\n",
    "\n",
    "# Load the model on the chosen device\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "# Optimizer definition\n",
    "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
    "# optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n",
    "\n",
    "\n",
    "# Learning loop\n",
    "for epoch in range(1, numEpochs + 1):\n",
    "    \n",
    "    # train the model with the train dataset\n",
    "    train_loss, train_acc = train(epoch, neural_net, train_loader, optimizer, device)   \n",
    "    \n",
    "    # evaluate the model with the validation dataset\n",
    "    val_loss, val_acc = evaluate(neural_net, val_loader, device)       \n",
    "    \n",
    "    # Save the costs obtained\n",
    "    train_losses.append(train_loss)    \n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Save the performances\n",
    "    train_accuracies.append(train_acc)    \n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Checkpoint\n",
    "    if epoch % checkpoint_freq ==0:\n",
    "        save_model(epoch, neural_net, path)\n",
    "\n",
    "# Save the model at the end of the training\n",
    "save_model(numEpochs, neural_net, path)\n",
    "    \n",
    "print(\"\\n\\n\\nOptimization ended.\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86OZRLrjavmd",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Interpréter la sortie du réseau de neurones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mklvQruYavme",
    "outputId": "193eeca0-db5e-477b-818d-7b5e6d883848"
   },
   "outputs": [],
   "source": [
    "# Activate the evaluation mode\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Select the first 10 data points of the validation set\n",
    "data, target = val_dataset[0:10]\n",
    "data = data.to(device)\n",
    "\n",
    "# Executing the neural network\n",
    "output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
    "\n",
    "# Transform the output into a probability distribution with a softmax function\n",
    "output_proba = ... # À compléter.\n",
    "\n",
    "# Print the probability\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "RvIEqKt0qjeT",
    "outputId": "f1c4e779-e9e1-4873-be1e-1366fb515836"
   },
   "outputs": [],
   "source": [
    "# For each example, retrieve the class with the highest probability.\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print(\"Model predictions\")\n",
    "print(prediction)\n",
    "\n",
    "print(\"Targets\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V11J3Jihavmy",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualisation de la courbe d'apprentissage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9_9C_tXavmz",
    "lines_to_next_cell": 0
   },
   "source": [
    "La visualisation de la courbe d'apprentissage permet de détecter des problèmes potentiels qui se sont produits pendant l'apprentissage, par exemple, du surapprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "iNcbpl0tavm0",
    "outputId": "fa201aa2-5e25-4701-c0a9-33415773d68b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = list(range(len(train_losses)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_losses, 'r', label=\"Train\")\n",
    "plt.plot(x, val_losses, 'g', label=\"Validation\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cross-entropy loss')\n",
    "plt.grid()\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "g-VGQ2pMavm4",
    "outputId": "267e91d4-48e3-413d-e2e2-0feac7335035"
   },
   "outputs": [],
   "source": [
    "x = list(range(len(train_accuracies)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_accuracies, 'r', label=\"Train\")\n",
    "plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oktkpkuqjet",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "* Qu'observez-vous dans les graphiques précédents ?\n",
    "* À quelle époque est-il intéressant d'extraire les paramètres du modèle pour l'inférence ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwhRt39yzug-",
    "lines_to_next_cell": 0
   },
   "source": [
    "... \\# à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XK_eUsq3avm8",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment évaluer un modèle sur l'ensemble d’évaluation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UREO5elavm8",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous pouvons enfin évaluer notre modèle sur notre ensemble de données d'évaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pPWvDM-qavm8",
    "outputId": "b39e294a-47fb-401a-ffa4-5d2a407f0980"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(neural_net, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvP_-KUwqjez",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "A) Comparer les métriques de validation et d’évaluation. <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov4CKUFh5tun",
    "lines_to_next_cell": 0
   },
   "source": [
    "... \\# à compléter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfykotIrJV0Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "id,colab_type,outputId,colab,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
